<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Apache Mesos</title>
        
        <meta name="robots" content="noindex" />
        
        


        <!-- Custom HTML head -->
        


        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        
        <link rel="icon" href="favicon.svg">
        
        
        <link rel="shortcut icon" href="favicon.png">
        
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        
        <link rel="stylesheet" href="css/print.css" media="print">
        

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        
        <link rel="stylesheet" href="fonts/fonts.css">
        

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        

        
    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><li class="part-title">Fundamentals</li><li class="chapter-item expanded "><a href="architecture.html"><strong aria-hidden="true">1.</strong> Mesos Architecture providing an overview of Mesos concepts</a></li><li class="chapter-item expanded "><a href="presentations.html"><strong aria-hidden="true">2.</strong> Video and Slides of Mesos Presentations</a></li><li class="chapter-item expanded "><a href="versioning.html"><strong aria-hidden="true">3.</strong> Mesos Release and Support Policy</a></li><li class="chapter-item expanded affix "><li class="part-title">Build / Installation</li><li class="chapter-item expanded "><a href="building.html"><strong aria-hidden="true">4.</strong> Building for basic instructions on compiling and installing Mesos.</a></li><li class="chapter-item expanded "><a href="binary-packages.html"><strong aria-hidden="true">5.</strong> Binary Packages for how to use Mesos binary packages.</a></li><li class="chapter-item expanded "><a href="configuration.html"><strong aria-hidden="true">6.</strong> Configuration for build configuration options.</a></li><li class="chapter-item expanded "><a href="cmake.html"><strong aria-hidden="true">7.</strong> CMake for details about using the new CMake build system.</a></li><li class="chapter-item expanded "><a href="windows.html"><strong aria-hidden="true">8.</strong> Windows Support for the state of Windows support in Mesos.</a></li><li class="chapter-item expanded affix "><li class="part-title">Administration</li><li class="chapter-item expanded "><a href="configuration.html"><strong aria-hidden="true">9.</strong> Configuration for command-line arguments.</a></li><li class="chapter-item expanded "><a href="high-availability.html"><strong aria-hidden="true">10.</strong> High Availability Master Setup</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="replicated-log-internals.html"><strong aria-hidden="true">10.1.</strong> Replicated Log for information on the Mesos replicated log.</a></li></ol></li><li class="chapter-item expanded "><a href="agent-recovery.html"><strong aria-hidden="true">11.</strong> Fault Tolerant Agent Setup</a></li><li class="chapter-item expanded "><a href="framework-rate-limiting.html"><strong aria-hidden="true">12.</strong> Framework Rate Limiting</a></li><li class="chapter-item expanded "><a href="maintenance.html"><strong aria-hidden="true">13.</strong> Maintenance for performing maintenance on a Mesos cluster.</a></li><li class="chapter-item expanded "><a href="upgrades.html"><strong aria-hidden="true">14.</strong> Upgrades for upgrading a Mesos cluster.</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                        
                    </div>

                    <h1 class="menu-title">Apache Mesos</h1>

                    <div class="right-buttons">
                        
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        
                        
                        <a href="https://github.com/AVENTER-UG/mesos-docs/" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>
                        
                    </div>
                </div>

                
                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" name="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>
                

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="mesos-architecture"><a class="header" href="#mesos-architecture">Mesos Architecture</a></h1>
<p><img src="images/architecture3.jpg" alt="Mesos Architecture" /></p>
<p>The above figure shows the main components of Mesos.  Mesos consists of a <em>master</em> daemon that manages <em>agent</em> daemons running on each cluster node, and <em>Mesos frameworks</em> that run <em>tasks</em> on these agents.</p>
<p>The master enables fine-grained sharing of resources (CPU, RAM, ...) across
frameworks by making them <em>resource offers</em>. Each resource offer contains a list
of <code>&lt;agent ID, resource1: amount1, resource2: amount2, ...&gt;</code> (NOTE: as
keyword 'slave' is deprecated in favor of 'agent', driver-based frameworks will
still receive offers with slave ID, whereas frameworks using the v1 HTTP API receive offers with agent ID). The master decides <em>how many</em> resources to offer to each framework according to a given organizational policy, such as fair sharing or strict priority. To support a diverse set of policies, the master employs a modular architecture that makes it easy to add new allocation modules via a plugin mechanism.</p>
<p>A framework running on top of Mesos consists of two components: a <em>scheduler</em> that registers with the master to be offered resources, and an <em>executor</em> process that is launched on agent nodes to run the framework's tasks (see the <a href="app-framework-development-guide.html">App/Framework development guide</a> for more details about framework schedulers and executors). While the master determines <strong>how many</strong> resources are offered to each framework, the frameworks' schedulers select <strong>which</strong> of the offered resources to use. When a framework accepts offered resources, it passes to Mesos a description of the tasks it wants to run on them. In turn, Mesos launches the tasks on the corresponding agents.</p>
<h2 id="example-of-resource-offer"><a class="header" href="#example-of-resource-offer">Example of resource offer</a></h2>
<p>The figure below shows an example of how a framework gets scheduled to run a task.</p>
<p><img src="images/architecture-example.jpg" alt="Mesos Architecture" /></p>
<p>Let's walk through the events in the figure.</p>
<ol>
<li>Agent 1 reports to the master that it has 4 CPUs and 4 GB of memory free. The master then invokes the allocation policy module, which tells it that framework 1 should be offered all available resources.</li>
<li>The master sends a resource offer describing what is available on agent 1 to framework 1.</li>
<li>The framework's scheduler replies to the master with information about two tasks to run on the agent, using &lt;2 CPUs, 1 GB RAM&gt; for the first task, and &lt;1 CPUs, 2 GB RAM&gt; for the second task.</li>
<li>Finally, the master sends the tasks to the agent, which allocates appropriate resources to the framework's executor, which in turn launches the two tasks (depicted with dotted-line borders in the figure). Because 1 CPU and 1 GB of RAM are still unallocated, the allocation module may now offer them to framework 2.</li>
</ol>
<p>In addition, this resource offer process repeats when tasks finish and new resources become free.</p>
<p>While the thin interface provided by Mesos allows it to scale and allows the frameworks to evolve independently, one question remains: how can the constraints of a framework be satisfied without Mesos knowing about these constraints? For example, how can a framework achieve data locality without Mesos knowing which nodes store the data required by the framework? Mesos answers these questions by simply giving frameworks the ability to <strong>reject</strong> offers. A framework will reject the offers that do not satisfy its constraints and accept the ones that do.  In particular, we have found that a simple policy called delay scheduling, in which frameworks wait for a limited time to acquire nodes storing the input data, yields nearly optimal data locality.</p>
<p>You can also read much more about the Mesos architecture in this <a href="https://www.usenix.org/conference/nsdi11/mesos-platform-fine-grained-resource-sharing-data-center">technical paper</a>.</p>
<h1 id="video-and-slides-of-mesos-presentations"><a class="header" href="#video-and-slides-of-mesos-presentations">Video and Slides of Mesos Presentations</a></h1>
<p><em>(Listed in reverse chronological order)</em></p>
<h2 id="mesoscon-north-america-2018"><a class="header" href="#mesoscon-north-america-2018">MesosCon North America 2018</a></h2>
<p><a href="https://www.youtube.com/playlist?list=PL-cRvJ6sAbfjvQCLT3ktrpnVwrJKTodfm">Video playlist</a> + <a href="https://mesoscon18.sched.com/">Slides</a></p>
<h2 id="jolt-running-distributed-fault-tolerant-tests-at-scale-using-mesos"><a class="header" href="#jolt-running-distributed-fault-tolerant-tests-at-scale-using-mesos">Jolt: Running Distributed, Fault-Tolerant Tests at Scale using Mesos</a></h2>
<p><a href="https://www.youtube.com/watch?v=2uGwlVs8Cpw">Video</a>
Sunil Shah, Kyle Kelly, and Timmy Zhu Presented November 1, 2017 at <a href="https://www.meetup.com/Bay-Area-Mesos-User-Group/events/244469969/">Bay Area Mesos User Group Meetup</a></p>
<h2 id="mesoscon-europe-2017"><a class="header" href="#mesoscon-europe-2017">MesosCon Europe 2017</a></h2>
<p><a href="https://www.youtube.com/playlist?list=PLbzoR-pLrL6rSBqPhTh_lmeMmxn6AOSjf">Video playlist</a> + <a href="http://events17.linuxfoundation.org/events/archive/2017/mesoscon-europe/program/slides">Slides</a></p>
<h2 id="mesoscon-north-america-2017"><a class="header" href="#mesoscon-north-america-2017">MesosCon North America 2017</a></h2>
<p><a href="https://www.youtube.com/playlist?list=PLbzoR-pLrL6qAEnkhkh5tGI6oX_xXD3X4">Video playlist</a> + <a href="http://events17.linuxfoundation.org/events/archive/2017/mesoscon-north-america/program/slides">Slides</a></p>
<h2 id="mesoscon-asia-2017"><a class="header" href="#mesoscon-asia-2017">MesosCon Asia 2017</a></h2>
<p><a href="https://www.youtube.com/playlist?list=PLbzoR-pLrL6rZfzCL_b-W9yxcJQhZ0RUg">Video playlist</a> + <a href="http://events17.linuxfoundation.org/events/archive/2017/mesoscon-asia/program/slides">Slides</a></p>
<h2 id="mesoscon-asia-2016"><a class="header" href="#mesoscon-asia-2016">MesosCon Asia 2016</a></h2>
<p><a href="https://www.youtube.com/playlist?list=PLbzoR-pLrL6pLSHrXSg7IYgzSlkOh132K">Video playlist</a> + <a href="http://events17.linuxfoundation.org/events/archive/2016/mesoscon-asia/program/slides">Slides</a></p>
<h2 id="mesoscon-europe-2016"><a class="header" href="#mesoscon-europe-2016">MesosCon Europe 2016</a></h2>
<p><a href="http://events17.linuxfoundation.org/events/archive/2016/mesoscon-europe/program/slides">Slides</a></p>
<h2 id="mesoscon-north-america-2016"><a class="header" href="#mesoscon-north-america-2016">MesosCon North America 2016</a></h2>
<p><a href="https://www.youtube.com/playlist?list=PLGeM09tlguZQVL7ZsfNMffX9h1rGNVqnC">Video playlist</a> + <a href="http://events17.linuxfoundation.org/events/archive/2016/mesoscon-north-america/program/slides">Slides</a></p>
<h2 id="mesoscon-europe-2015"><a class="header" href="#mesoscon-europe-2015">MesosCon Europe 2015</a></h2>
<p><a href="https://www.youtube.com/watch?v=K-x7yOy8Ymk&amp;list=PLGeM09tlguZS6MhlSZDbf-gANWdKgje0I">Video playlist</a> + <a href="http://events17.linuxfoundation.org/events/archive/2015/mesoscon-europe/program/slides">Slides</a></p>
<h2 id="mesoscon-north-america-2015"><a class="header" href="#mesoscon-north-america-2015">MesosCon North America 2015</a></h2>
<p><a href="https://www.youtube.com/watch?v=aV6pdWveN7s&amp;list=PLVjgeV_avap2arug3vIz8c6l72rvh9poV">Video playlist</a> + <a href="http://events17.linuxfoundation.org/events/archive/2015/mesoscon-north-america/program/slides">Slides</a></p>
<h2 id="building-and-deploying-applications-to-apache-mesos"><a class="header" href="#building-and-deploying-applications-to-apache-mesos">Building and Deploying Applications to Apache Mesos</a></h2>
<p><a href="https://www.slideshare.net/charmalloc/buildingdeployingapplicationsmesos">Slides</a>
Joe Stein
Presented February 26, 2015 at <a href="http://www.meetup.com/DigitalOcean_Community/events/220580767/">DigitalOcean Community Meetup</a></p>
<h2 id="mesoscon-2014"><a class="header" href="#mesoscon-2014">MesosCon 2014</a></h2>
<p><a href="https://www.youtube.com/playlist?list=PLDVc2EaAVPg9kp8cFzjR1Yxj96I4U5EGN">Video playlist</a></p>
<h2 id="datacenter-computing-with-apache-mesos"><a class="header" href="#datacenter-computing-with-apache-mesos">Datacenter Computing with Apache Mesos</a></h2>
<p><a href="http://www.slideshare.net/pacoid/datacenter-computing-with-apache-mesos">Slides</a>
Paco Nathan
Presented April 15, 2014 at <a href="http://www.meetup.com/bigdatadc/events/172610652/">Big Data DC Meetup</a></p>
<h2 id="apache-spark-at-viadeo-running-on-mesos"><a class="header" href="#apache-spark-at-viadeo-running-on-mesos">Apache Spark at Viadeo (Running on Mesos)</a></h2>
<p><a href="http://www.youtube.com/watch?v=shaZslr49vQ&amp;t=16m55s">Video</a> + <a href="https://speakerdeck.com/ecepoi/apache-spark-at-viadeo">Slides</a>
Eugen Cepoi
Presented April 9, 2014 at Paris Hadoop User Group</p>
<h2 id="mesos-hubspot-and-singularity"><a class="header" href="#mesos-hubspot-and-singularity">Mesos, HubSpot, and Singularity</a></h2>
<p><a href="https://www.youtube.com/watch?v=ROn14csiikw">Video</a>
Tom Petr
Presented April 3rd, 2014 at @TwitterOSS #conf</p>
<h2 id="building-distributed-frameworks-on-mesos"><a class="header" href="#building-distributed-frameworks-on-mesos">Building Distributed Frameworks on Mesos</a></h2>
<p><a href="https://www.youtube.com/watch?v=n5GT7OFSh58">Video</a>
Benjamin Hindman
Presented March 25th, 2014 at <a href="https://www.eventbrite.com/e/aurora-and-mesosframeworksmeetup-tickets-10850994617">Aurora and Mesos Frameworks Meetup</a></p>
<h2 id="introduction-to-apache-aurora"><a class="header" href="#introduction-to-apache-aurora">Introduction to Apache Aurora</a></h2>
<p><a href="https://www.youtube.com/watch?v=asd_h6VzaJc">Video</a>
Bill Farner
Presented March 25th, 2014 at <a href="https://www.eventbrite.com/e/aurora-and-mesosframeworksmeetup-tickets-10850994617">Aurora and Mesos Frameworks Meetup</a></p>
<h2 id="improving-resource-efficiency-with-apache-mesos"><a class="header" href="#improving-resource-efficiency-with-apache-mesos">Improving Resource Efficiency with Apache Mesos</a></h2>
<p><a href="https://www.youtube.com/watch?v=YpmElyi94AA">Video</a>
Christina Delimitrou
Presented April 3rd, 2014 at @TwitterOSS #conf</p>
<h2 id="apache-mesos-as-an-sdk-for-building-distributed-frameworks"><a class="header" href="#apache-mesos-as-an-sdk-for-building-distributed-frameworks">Apache Mesos as an SDK for Building Distributed Frameworks</a></h2>
<p><a href="http://www.slideshare.net/pacoid/strata-sc-2014-apache-mesos-as-an-sdk-for-building-distributed-frameworks">Slides</a>
Paco Nathan
Presented February 13th, 2014 at <a href="http://strataconf.com/">Strata</a></p>
<h2 id="run-your-data-center-like-googles-with-apache-mesos"><a class="header" href="#run-your-data-center-like-googles-with-apache-mesos">Run your Data Center like Google's with Apache Mesos</a></h2>
<p><a href="https://www.youtube.com/watch?v=2YWVGMuMTrg">Video and Demo</a>
Abhishek Parolkar
Presented November 14th, 2013 at <a href="http://www.cloudexpoasia.com/">Cloud Expo Asia 2013</a></p>
<h2 id="datacenter-management-with-mesos"><a class="header" href="#datacenter-management-with-mesos">Datacenter Management with Mesos</a></h2>
<p><a href="http://www.youtube.com/watch?v=YB1VW0LKzJ4">Video</a>
Benjamin Hindman
Presented August 29th, 2013 at <a href="http://ampcamp.berkeley.edu/3/">AMP Camp</a></p>
<h2 id="building-a-framework-on-mesos-a-case-study-with-jenkins"><a class="header" href="#building-a-framework-on-mesos-a-case-study-with-jenkins">Building a Framework on Mesos: A Case Study with Jenkins</a></h2>
<p><a href="http://www.youtube.com/watch?v=TPXw_lMTJVk">Video</a>
Vinod Kone
Presented July 25, 2013 at <a href="http://www.meetup.com/Distributed-data-processing-with-Mesos/events/128585772/">SF Mesos Meetup</a></p>
<h2 id="hadoop-on-mesos"><a class="header" href="#hadoop-on-mesos">Hadoop on Mesos</a></h2>
<p><a href="http://www.youtube.com/watch?v=SFj5EMw8THk">Video</a>
Brenden Matthews
Presented July 25, 2013 at <a href="http://www.meetup.com/Distributed-data-processing-with-Mesos/events/128585772/">SF Mesos Meetup</a></p>
<h2 id="introduction-to-apache-mesos"><a class="header" href="#introduction-to-apache-mesos">Introduction to Apache Mesos</a></h2>
<p><a href="https://speakerdeck.com/benh/apache-mesos-nyc-meetup">Slides</a>
Benjamin Hindman
Presented August 20, 2013 at <a href="https://mesos-nyc-aug2013.eventbrite.com/">NYC Mesos Meetup</a></p>
<h2 id="chronos-a-distributed-fault-tolerant-and-highly-available-job-orchestration-framework-for-mesos"><a class="header" href="#chronos-a-distributed-fault-tolerant-and-highly-available-job-orchestration-framework-for-mesos">Chronos: A Distributed, Fault-Tolerant and Highly Available Job Orchestration Framework for Mesos</a></h2>
<p><a href="https://speakerdeck.com/mesos/chronos-august-2013-nyc-meetup">Slides</a>
Florian Leibert
Presented August 20, 2013 at <a href="https://mesos-nyc-aug2013.eventbrite.com/">NYC Mesos Meetup</a></p>
<h2 id="airbnb-tech-talk"><a class="header" href="#airbnb-tech-talk">Airbnb Tech Talk</a></h2>
<p><a href="http://www.youtube.com/watch?v=Hal00g8o1iY">Video</a>
Benjamin Hindman Presented September 6, 2012 at <a href="http://airbnb.com">Airbnb</a></p>
<h2 id="managing-twitter-clusters-with-mesos"><a class="header" href="#managing-twitter-clusters-with-mesos">Managing Twitter Clusters with Mesos</a></h2>
<p><a href="http://www.youtube.com/watch?v=37OMbAjnJn0">Video</a>
Benjamin Hindman Presented August 22, 2012 at <a href="http://ampcamp.berkeley.edu">AMP Camp</a></p>
<h2 id="mesos-a-platform-for-fine-grained-resource-sharing-in-datacenters"><a class="header" href="#mesos-a-platform-for-fine-grained-resource-sharing-in-datacenters">Mesos: A Platform for Fine-Grained Resource Sharing in Datacenters</a></h2>
<p><a href="http://www.youtube.com/watch?v=dB8IDu7g9Nc">Video</a>
Matei Zaharia
Presented March 2011 at <a href="http://berkeley.edu">UC Berkeley</a></p>
<h2 id="mesos-efficiently-sharing-the-datacenter"><a class="header" href="#mesos-efficiently-sharing-the-datacenter">Mesos: Efficiently Sharing the Datacenter</a></h2>
<p><a href="http://vimeo.com/17821090">Video</a>
Benjamin Hindman
Presented November 8, 2010 at <a href="http://linkedin.com">LinkedIn</a></p>
<h2 id="mesos-a-resource-management-platform-for-hadoop-and-big-data-clusters"><a class="header" href="#mesos-a-resource-management-platform-for-hadoop-and-big-data-clusters">Mesos: A Resource Management Platform for Hadoop and Big Data Clusters</a></h2>
<p><a href="http://www.youtube.com/watch?v=lE3jR6nM3bw">Video</a>
Matei Zaharia
Presented Summer 2010 at <a href="http://yahoo.com">Yahoo</a></p>
<h1 id="apache-mesos---paid-training"><a class="header" href="#apache-mesos---paid-training">Apache Mesos - Paid Training</a></h1>
<h2 id="automated-machine-learning-pipeline-with-mesos"><a class="header" href="#automated-machine-learning-pipeline-with-mesos">Automated Machine Learning Pipeline with Mesos</a></h2>
<p><a href="https://www.packtpub.com/big-data-and-business-intelligence/automated-machine-learning-pipeline-mesos-integrated-course">Video</a>
Karl Whitford
Packt (November 2017)</p>
<h2 id="docker-apache-mesos--dcos-run-and-manage-cloud-datacenter-a-hrefhttpswwwpacktpubcomnetworking-and-serversdocker-apache-mesos-dcos-run-and-manage-cloud-datacenter-videovideoa"><a class="header" href="#docker-apache-mesos--dcos-run-and-manage-cloud-datacenter-a-hrefhttpswwwpacktpubcomnetworking-and-serversdocker-apache-mesos-dcos-run-and-manage-cloud-datacenter-videovideoa">Docker, Apache Mesos &amp; DCOS: Run and manage cloud datacenter (<a href="https://www.packtpub.com/networking-and-servers/docker-apache-mesos-dcos-run-and-manage-cloud-datacenter-video">Video</a>)</a></h2>
<p>Manuj Aggarwal
Packt (January 2018) </p>
<h1 id="mesos-release-and-support-policy"><a class="header" href="#mesos-release-and-support-policy">Mesos Release and Support policy</a></h1>
<p>The Mesos versioning and release policy gives operators and developers clear guidelines on:</p>
<ul>
<li>Making modifications to the existing APIs without affecting backward compatibility.</li>
<li>How long a Mesos API will be supported.</li>
<li>Upgrading a Mesos installation across release versions.</li>
</ul>
<p>This document describes the release strategy for Mesos post 1.0.0 release.</p>
<h2 id="release-schedule"><a class="header" href="#release-schedule">Release Schedule</a></h2>
<p>Mesos releases are time-based, though we do make limited adjustments to the release schedule to accommodate feature development. This gives users and developers a predictable cadence to consume and produce features, while ensuring that each release can include the developments that users are waiting for.</p>
<p>If a feature is not ready by the time a release is cut, that feature should be disabled. This means that features should be developed in such a way that they are opt-in by default and can be easily disabled (e.g., flag).</p>
<p>A new Mesos release is cut approximately every <strong>3 months</strong>. The versioning scheme is <a href="http://semver.org">SemVer</a>. Typically, the minor release version is incremented by 1 (e.g., 1.1, 1.2, 1.3 etc) for every release, unless it is a major release.</p>
<p>Every (minor) release is a stable release and recommended for production use. This means a release candidate will go through rigorous testing (unit tests, integration tests, benchmark tests, cluster tests, scalability, etc.) before being officially released. In the rare case that a regular release is not deemed stable, a patch release will be released that will stabilize it.</p>
<p>At any given time, 3 releases are supported: the latest release and the two prior. Support means fixing of <em>critical issues</em> that affect the release. Once an issue is deemed critical, it will be fixed in only those <strong>affected</strong> releases that are still <strong>supported</strong>. This is called a patch release and increments the patch version by 1 (e.g., 1.2.1). Once a release reaches End Of Life (i.e., support period has ended), no more patch releases will be made for that release. Note that this is not related to backwards compatibility guarantees and deprecation periods (discussed later).</p>
<p>Which issues are considered critical?</p>
<ul>
<li>Security fixes</li>
<li>Compatibility regressions</li>
<li>Functional regressions</li>
<li>Performance regressions</li>
<li>Fixes for 3rd party integration (e.g., Docker remote API)</li>
</ul>
<p>Whether an issue is considered critical or not is sometimes subjective. In some cases it is obvious and sometimes it is fuzzy. Users should work with committers to figure out the criticality of an issue and get agreement and commitment for support.</p>
<p>Patch releases are normally done <strong>once per month</strong>.</p>
<p>If a particular issue is affecting a user and the user cannot wait until the next scheduled patch release, they can request an off-schedule patch release for a specific supported version. This should be done by sending an email to the dev list.</p>
<h2 id="upgrades"><a class="header" href="#upgrades">Upgrades</a></h2>
<p>All stable releases will be loosely compatible. Loose compatibility means:</p>
<ul>
<li>Master or agent can be upgraded to a new release version as long as they or the ecosystem components (scheduler, executor, zookeeper, service discovery layer, monitoring etc) do not depend on deprecated features (e.g., deprecated flags, deprecated metrics).</li>
<li>There should be no unexpected effect on externally visible behavior that is not deprecated. See API compatibility section for what should be expected for Mesos APIs.</li>
</ul>
<blockquote>
<p>NOTE: The compatibility guarantees do not apply to modules yet. See Modules section below for details.</p>
</blockquote>
<p>This means users should be able to upgrade (as long as they are not depending on deprecated / removed features) Mesos master or agent from a stable release version N directly to another stable release version M without having to go through intermediate release versions. For the purposes of upgrades, a stable release means the release with the latest patch version. For example, among 1.2.0, 1.2.1, 1.3.0, 1.4.0, 1.4.1 releases 1.2.1, 1.3.0 and 1.4.1 are considered stable and so a user should be able to upgrade from 1.2.1 directly to 1.4.1. Look at the API compatability section below for how frameworks can do seamless upgrades.</p>
<p>The deprecation period for any given feature will be <strong>6 months</strong>. Having a set period allows Mesos developers to not indefinitely accrue technical debt and allows users time to plan for upgrades.</p>
<p>The detailed information about upgrading to a particular Mesos version would be posted <a href="upgrades.html">here</a>.</p>
<h2 id="api-versioning"><a class="header" href="#api-versioning">API versioning</a></h2>
<p>The Mesos APIs (constituting Scheduler, Executor, Internal, Operator/Admin APIs) will have a version in the URL. The versioned URL will have a prefix of <strong><code>/api/vN</code></strong> where &quot;N&quot; is the version of the API. The &quot;/api&quot; prefix is chosen to distinguish API resources from Web UI paths.</p>
<p>Examples:</p>
<ul>
<li>http://localhost:5050/api/v1/scheduler :  Scheduler HTTP API hosted by the master.</li>
<li>http://localhost:5051/api/v1/executor  :  Executor HTTP API hosted by the agent.</li>
</ul>
<p>A given Mesos installation might host multiple versions of the same API i.e., Scheduler API v1 and/or v2 etc.</p>
<h3 id="api-version-vs-release-version"><a class="header" href="#api-version-vs-release-version">API version vs Release version</a></h3>
<ul>
<li>To keep things simple, the stable version of the API will correspond to the major release version of Mesos.
<ul>
<li>For example, v1 of the API will be supported by Mesos release versions 1.0.0, 1.4.0, 1.20.0 etc.</li>
</ul>
</li>
<li>vN version of the API might also be supported by release versions of N-1 series but the vN API is not considered stable until the last release version of N-1 series.</li>
<li>For example, v2 of the API might be introduced in Mesos 1.12.0 release but it is only considered stable in Mesos 1.21.0 release if it is the last release of &quot;1&quot; series. Note that all Mesos 1.x.y versions will still support v1 of the API.</li>
<li>The API version is only bumped if we need to make a backwards <a href="versioning.html#api-compatibility">incompatible</a> API change. We will strive to support a given API version for at least a year.</li>
<li>The deprecation clock for vN-1 API will start as soon as we release &quot;N.0.0&quot; version of Mesos. We will strive to give enough time (e.g., 6 months) for frameworks/operators to upgrade to vN API before we stop supporting vN-1 API.</li>
</ul>
<p><a name="api-compatibility"></a></p>
<h3 id="api-compatibility"><a class="header" href="#api-compatibility">API Compatibility</a></h3>
<p>The API compatibility is determined by the corresponding protobuf guarantees.</p>
<p>As an example, the following are considered &quot;backwards compatible&quot; changes for Scheduler API:</p>
<ul>
<li>Adding new types of Calls i.e., new types of HTTP requests to &quot;/scheduler&quot;.</li>
<li>Adding new optional fields to existing requests to &quot;/scheduler&quot;.</li>
<li>Adding new types of Events i.e., new types of chunks streamed on &quot;/scheduler&quot;.</li>
<li>Adding new header fields to chunked response streamed on &quot;/scheduler&quot;.</li>
<li>Adding new fields (or changing the order of fields) to chunks' body streamed on &quot;/scheduler&quot;.</li>
<li>Adding new API resources (e.g., &quot;/foobar&quot;).</li>
</ul>
<p>The following are considered backwards incompatible changes for Scheduler API:</p>
<ul>
<li>Adding new required fields to existing requests to &quot;/scheduler&quot;.</li>
<li>Renaming/removing fields from existing requests to &quot;/scheduler&quot;.</li>
<li>Renaming/removing fields from chunks streamed on &quot;/scheduler&quot;.</li>
<li>Renaming/removing existing Calls.</li>
</ul>
<h2 id="implementation-details"><a class="header" href="#implementation-details">Implementation Details</a></h2>
<h3 id="release-branches"><a class="header" href="#release-branches">Release branches</a></h3>
<p>For regular releases, the work is done on the master branch. There are no feature branches but there will be release branches.</p>
<p>When it is time to cut a minor release, a new branch (e.g., 1.2.x) is created off the master branch. We chose 'x' instead of patch release number to disambiguate branch names from tag names. Then the first RC (-rc1) is tagged on the release branch. Subsequent RCs, in case the previous RCs fail testing, should be tagged on the release branch.</p>
<p>Patch releases are also based off the release branches. Typically the fix for an issue that is affecting supported releases lands on the master branch and is then backported to the release branch(es). In rare cases, the fix might directly go into a release branch without landing on master (e.g.,  fix / issue is not applicable to master).</p>
<p>Having a branch for each minor release reduces the amount of work a release manager needs to do when it is time to do a release. It is the responsibility of the committer of a fix to commit it to all the affecting release branches. This is important because the committer has more context about the issue / fix at the time of the commit than a release manager at the time of release. The release manager of a minor release will be responsible for all its patch releases as well. Just like the master branch, history rewrites are not allowed in the release branch (i.e., no git push --force).</p>
<h3 id="api-protobufs"><a class="header" href="#api-protobufs">API protobufs</a></h3>
<p>Most APIs in Mesos accept protobuf messages with a corresponding JSON field mapping. To support multiple versions of the API, we decoupled the versioned protobufs backing the API from the &quot;internal&quot; protobufs used by the Mesos code.</p>
<p>For example, the protobufs for the v1 Scheduler API are located at:</p>
<pre><code>include/mesos/v1/scheduler/scheduler.proto

package mesos.v1.scheduler;
option java_package = &quot;org.apache.mesos.v1.scheduler&quot;;
option java_outer_classname = &quot;Protos&quot;;
...
</code></pre>
<p>The corresponding internal protobufs for the Scheduler API are located at:</p>
<pre><code>include/mesos/scheduler/scheduler.proto

package mesos.scheduler;
option java_package = &quot;org.apache.mesos.scheduler&quot;;
option java_outer_classname = &quot;Protos&quot;;
...
</code></pre>
<p>The users of the API send requests (and receive responses) based on the versioned protobufs. We implemented <a href="https://github.com/apache/mesos/blob/master/src/internal/evolve.hpp">evolve</a>/<a href="https://github.com/apache/mesos/blob/master/src/internal/devolve.hpp">devolve</a> converters that can convert protobufs from any supported version to the internal protobuf and vice versa.</p>
<p>Internally, message passing between various Mesos components would use the internal unversioned protobufs. When sending response (if any) back to the user of the API, the unversioned protobuf would be converted back to a versioned protobuf.</p>
<h1 id="building"><a class="header" href="#building">Building</a></h1>
<h2 id="downloading-mesos"><a class="header" href="#downloading-mesos">Downloading Mesos</a></h2>
<p>There are different ways you can get Mesos:</p>
<p>1. Download the latest stable release from <a href="http://mesos.apache.org/downloads/">Apache</a> (<em><strong>Recommended</strong></em>)</p>
<pre><code>$ wget https://downloads.apache.org/mesos/1.11.0/mesos-1.11.0.tar.gz
$ tar -zxf mesos-1.11.0.tar.gz
</code></pre>
<p>2. Clone the Mesos git <a href="https://gitbox.apache.org/repos/asf/mesos.git">repository</a> (<em><strong>Advanced Users Only</strong></em>)</p>
<pre><code>$ git clone https://gitbox.apache.org/repos/asf/mesos.git
</code></pre>
<p><em>NOTE: If you have problems running the above commands, you may need to first run through the <em><strong>System Requirements</strong></em> section below to install the <code>wget</code>, <code>tar</code>, and <code>git</code> utilities for your system.</em></p>
<h2 id="system-requirements"><a class="header" href="#system-requirements">System Requirements</a></h2>
<p>Mesos runs on Linux (64 Bit) and Mac OS X (64 Bit). To build Mesos from source, GCC 4.8.1+ or Clang 3.5+ is required.</p>
<p>On Linux, a kernel version &gt;= 2.6.28 is required at both build time and run time. For full support of process isolation under Linux a recent kernel &gt;= 3.10 is required.</p>
<p>The Mesos agent also runs on Windows. To build Mesos from source, follow the instructions in the <a href="windows.html">Windows</a> section.</p>
<p>Make sure your hostname is resolvable via DNS or via <code>/etc/hosts</code> to allow full support of Docker's host-networking capabilities, needed for some of the Mesos tests. When in doubt, please validate that <code>/etc/hosts</code> contains your hostname.</p>
<h3 id="ubuntu-1404"><a class="header" href="#ubuntu-1404">Ubuntu 14.04</a></h3>
<p>Following are the instructions for stock Ubuntu 14.04. If you are using a different OS, please install the packages accordingly.</p>
<pre><code># Update the packages.
$ sudo apt-get update

# Install a few utility tools.
$ sudo apt-get install -y tar wget git

# Install the latest OpenJDK.
$ sudo apt-get install -y openjdk-7-jdk

# Install autotools (Only necessary if building from git repository).
$ sudo apt-get install -y autoconf libtool

# Install other Mesos dependencies.
$ sudo apt-get -y install build-essential python-dev python-six python-virtualenv libcurl4-nss-dev libsasl2-dev libsasl2-modules maven libapr1-dev libsvn-dev
</code></pre>
<h3 id="ubuntu-1604"><a class="header" href="#ubuntu-1604">Ubuntu 16.04</a></h3>
<p>Following are the instructions for stock Ubuntu 16.04. If you are using a different OS, please install the packages accordingly.</p>
<pre><code># Update the packages.
$ sudo apt-get update

# Install a few utility tools.
$ sudo apt-get install -y tar wget git

# Install the latest OpenJDK.
$ sudo apt-get install -y openjdk-8-jdk

# Install autotools (Only necessary if building from git repository).
$ sudo apt-get install -y autoconf libtool

# Install other Mesos dependencies.
$ sudo apt-get -y install build-essential python-dev python-six python-virtualenv libcurl4-nss-dev libsasl2-dev libsasl2-modules maven libapr1-dev libsvn-dev zlib1g-dev iputils-ping
</code></pre>
<h3 id="mac-os-x-1011-el-capitan-macos-1012-sierra"><a class="header" href="#mac-os-x-1011-el-capitan-macos-1012-sierra">Mac OS X 10.11 (El Capitan), macOS 10.12 (Sierra)</a></h3>
<p>Following are the instructions for Mac OS X El Capitan. When building Mesos with the Apple-provided toolchain, the Command Line Tools from XCode &gt;= 8.0 are required; XCode 8 requires Mac OS X 10.11.5 or newer.</p>
<pre><code># Install Python 3: https://www.python.org/downloads/

# Install Command Line Tools. The Command Line Tools from XCode &gt;= 8.0 are required.
$ xcode-select --install

# Install Homebrew.
$ ruby -e &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)&quot;

# Install Java.
$ brew install Caskroom/cask/java

# Install libraries.
$ brew install wget git autoconf automake libtool subversion maven xz

# Install Python dependencies.
$ sudo easy_install pip
$ pip install virtualenv
</code></pre>
<p>When compiling on macOS 10.12, the following is needed:</p>
<pre><code># There is an incompatiblity with the system installed svn and apr headers.
# We need the svn and apr headers from a brew installation of subversion.
# You may need to unlink the existing version of subversion installed via
# brew in order to configure correctly.
$ brew unlink subversion # (If already installed)
$ brew install subversion

# When configuring, the svn and apr headers from brew will be automatically
# detected, so no need to explicitly point to them.
# If the build fails due to compiler warnings, `--disable-werror` can be passed
# to configure to not treat warnings as errors.
$ ../configure

# Lastly, you may encounter the following error when the libprocess tests run:
$ ./libprocess-tests
Failed to obtain the IP address for '&lt;hostname&gt;'; the DNS service may not be able to resolve it: nodename nor servname provided, or not known

# If so, turn on 'Remote Login' within System Preferences &gt; Sharing to resolve the issue.
</code></pre>
<p><em>NOTE: When upgrading from Yosemite to El Capitan, make sure to rerun <code>xcode-select --install</code> after the upgrade.</em></p>
<h3 id="centos-66"><a class="header" href="#centos-66">CentOS 6.6</a></h3>
<p>Following are the instructions for stock CentOS 6.6. If you are using a different OS, please install the packages accordingly.</p>
<pre><code># Install a recent kernel for full support of process isolation.
$ sudo rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org
$ sudo rpm -Uvh http://www.elrepo.org/elrepo-release-6-6.el6.elrepo.noarch.rpm
$ sudo yum --enablerepo=elrepo-kernel install -y kernel-lt

# Make the just installed kernel the one booted by default, and reboot.
$ sudo sed -i 's/default=1/default=0/g' /boot/grub/grub.conf
$ sudo reboot

# Install a few utility tools. This also forces an update of `nss`,
# which is necessary for the Java bindings to build properly.
$ sudo yum install -y tar wget git which nss

# 'Mesos &gt; 0.21.0' requires a C++ compiler with full C++11 support,
# (e.g. GCC &gt; 4.8) which is available via 'devtoolset-2'.
# Fetch the Scientific Linux CERN devtoolset repo file.
$ sudo wget -O /etc/yum.repos.d/slc6-devtoolset.repo http://linuxsoft.cern.ch/cern/devtoolset/slc6-devtoolset.repo

# Import the CERN GPG key.
$ sudo rpm --import http://linuxsoft.cern.ch/cern/centos/7/os/x86_64/RPM-GPG-KEY-cern

# Fetch the Apache Maven repo file.
$ sudo wget http://repos.fedorapeople.org/repos/dchen/apache-maven/epel-apache-maven.repo -O /etc/yum.repos.d/epel-apache-maven.repo

# 'Mesos &gt; 0.21.0' requires 'subversion &gt; 1.8' devel package, which is
# not available in the default repositories.
# Create a WANdisco SVN repo file to install the correct version:
$ sudo bash -c 'cat &gt; /etc/yum.repos.d/wandisco-svn.repo &lt;&lt;EOF
[WANdiscoSVN]
name=WANdisco SVN Repo 1.8
enabled=1
baseurl=http://opensource.wandisco.com/centos/6/svn-1.8/RPMS/$basearch/
gpgcheck=1
gpgkey=http://opensource.wandisco.com/RPM-GPG-KEY-WANdisco
EOF'

# Install essential development tools.
$ sudo yum groupinstall -y &quot;Development Tools&quot;

# Install 'devtoolset-2-toolchain' which includes GCC 4.8.2 and related packages.
# Installing 'devtoolset-3' might be a better choice since `perf` might
# conflict with the version of `elfutils` included in devtoolset-2.
$ sudo yum install -y devtoolset-2-toolchain

# Install other Mesos dependencies.
$ sudo yum install -y apache-maven python-devel python-six python-virtualenv java-1.7.0-openjdk-devel zlib-devel libcurl-devel openssl-devel cyrus-sasl-devel cyrus-sasl-md5 apr-devel subversion-devel apr-util-devel

# Enter a shell with 'devtoolset-2' enabled.
$ scl enable devtoolset-2 bash
$ g++ --version  # Make sure you've got GCC &gt; 4.8!

# Process isolation is using cgroups that are managed by 'cgconfig'.
# The 'cgconfig' service is not started by default on CentOS 6.6.
# Also the default configuration does not attach the 'perf_event' subsystem.
# To do this, add 'perf_event = /cgroup/perf_event;' to the entries in '/etc/cgconfig.conf'.
$ sudo yum install -y libcgroup
$ sudo service cgconfig start
</code></pre>
<h3 id="centos-71"><a class="header" href="#centos-71">CentOS 7.1</a></h3>
<p>Following are the instructions for stock CentOS 7.1. If you are using a different OS, please install the packages accordingly.</p>
<pre><code># Install a few utility tools
$ sudo yum install -y tar wget git

# Fetch the Apache Maven repo file.
$ sudo wget http://repos.fedorapeople.org/repos/dchen/apache-maven/epel-apache-maven.repo -O /etc/yum.repos.d/epel-apache-maven.repo

# Install the EPEL repo so that we can pull in 'libserf-1' as part of our
# subversion install below.
$ sudo yum install -y epel-release

# 'Mesos &gt; 0.21.0' requires 'subversion &gt; 1.8' devel package,
# which is not available in the default repositories.
# Create a WANdisco SVN repo file to install the correct version:
$ sudo bash -c 'cat &gt; /etc/yum.repos.d/wandisco-svn.repo &lt;&lt;EOF
[WANdiscoSVN]
name=WANdisco SVN Repo 1.9
enabled=1
baseurl=http://opensource.wandisco.com/centos/7/svn-1.9/RPMS/\$basearch/
gpgcheck=1
gpgkey=http://opensource.wandisco.com/RPM-GPG-KEY-WANdisco
EOF'

# Parts of Mesos require systemd in order to operate. However, Mesos
# only supports versions of systemd that contain the 'Delegate' flag.
# This flag was first introduced in 'systemd version 218', which is
# lower than the default version installed by centos. Luckily, centos
# 7.1 has a patched 'systemd &lt; 218' that contains the 'Delegate' flag.
# Explicity update systemd to this patched version.
$ sudo yum update systemd

# Install essential development tools.
$ sudo yum groupinstall -y &quot;Development Tools&quot;

# Install other Mesos dependencies.
$ sudo yum install -y apache-maven python-devel python-six python-virtualenv java-1.8.0-openjdk-devel zlib-devel libcurl-devel openssl-devel cyrus-sasl-devel cyrus-sasl-md5 apr-devel subversion-devel apr-util-devel
</code></pre>
<h3 id="windows"><a class="header" href="#windows">Windows</a></h3>
<p>Follow the instructions in the <a href="windows.html">Windows</a> section.</p>
<h2 id="building-mesos-posix"><a class="header" href="#building-mesos-posix">Building Mesos (Posix)</a></h2>
<pre><code># Change working directory.
$ cd mesos

# Bootstrap (Only required if building from git repository).
$ ./bootstrap

# Configure and build.
$ mkdir build
$ cd build
$ ../configure
$ make
</code></pre>
<p>In order to speed up the build and reduce verbosity of the logs, you can append <code>-j &lt;number of cores&gt; V=0</code> to <code>make</code>.</p>
<pre><code># Run test suite.
$ make check

# Install (Optional).
$ make install
</code></pre>
<h2 id="examples"><a class="header" href="#examples">Examples</a></h2>
<p>Mesos comes bundled with example frameworks written in C++, Java and Python.
The framework binaries will only be available after running <code>make check</code>, as
described in the <em><strong>Building Mesos</strong></em> section above.</p>
<pre><code># Change into build directory.
$ cd build

# Start Mesos master (ensure work directory exists and has proper permissions).
$ ./bin/mesos-master.sh --ip=127.0.0.1 --work_dir=/var/lib/mesos

# Start Mesos agent (ensure work directory exists and has proper permissions).
$ ./bin/mesos-agent.sh --master=127.0.0.1:5050 --work_dir=/var/lib/mesos

# Visit the Mesos web page.
$ http://127.0.0.1:5050

# Run C++ framework (exits after successfully running some tasks).
$ ./src/test-framework --master=127.0.0.1:5050

# Run Java framework (exits after successfully running some tasks).
$ ./src/examples/java/test-framework 127.0.0.1:5050

# Run Python framework (exits after successfully running some tasks).
$ ./src/examples/python/test-framework 127.0.0.1:5050
</code></pre>
<p><em>Note: These examples assume you are running Mesos on your local machine.
Following them will not allow you to access the Mesos web page in a production
environment (e.g. on AWS). For that you will need to specify the actual IP of
your host when launching the Mesos master and ensure your firewall settings
allow access to port 5050 from the outside world.</em></p>
<h1 id="binary-packages"><a class="header" href="#binary-packages">Binary Packages</a></h1>
<h2 id="downloading-the-mesos-rpm"><a class="header" href="#downloading-the-mesos-rpm">Downloading the Mesos RPM</a></h2>
<p>Download and install the latest stable CentOS7 RPM binary from the <a href="http://rpm.aventer.biz/CentOS/7/x86_64/">Repository</a>:</p>
<pre><code>$ cat &gt; /tmp/aventer.repo &lt;&lt;EOF
#aventer-mesos-el - packages by mesos from aventer
[aventer-rel]
name=AVENTER stable repository $releasever
baseurl=http://rpm.aventer.biz/CentOS/$releasever/$basearch/
enabled=1
gpgkey=https://www.aventer.biz/CentOS/support_aventer.asc
EOF

$ sudo mv /tmp/aventer.repo /etc/yum.repos.d/aventer.repo

$ sudo yum update

$ sudo yum install mesos
</code></pre>
<p>The above instructions show how to install the latest version of Mesos for RHEL 7.
Substitute <code>baseurl</code> the with the appropriate URL for your operating system.</p>
<h2 id="start-mesos-master-and-agent"><a class="header" href="#start-mesos-master-and-agent">Start Mesos Master and Agent.</a></h2>
<p>The RPM installation creates the directory <code>/var/lib/mesos</code> that can be used as a work directory.</p>
<p>Start the Mesos master with the following command:</p>
<pre><code>$ mesos-master --work_dir=/var/lib/mesos
</code></pre>
<p>On a different terminal, start the Mesos agent, and associate it with the Mesos master started above:</p>
<pre><code>$ mesos-agent --work_dir=/var/lib/mesos --master=127.0.0.1:5050
</code></pre>
<p>This is the simplest way to try out Mesos after downloading the RPM. For more complex and production
setup instructions refer to the <a href="http://mesos.apache.org/documentation/latest/#administration">Administration</a> section of the docs.</p>
<h1 id="mesos-runtime-configuration"><a class="header" href="#mesos-runtime-configuration">Mesos Runtime Configuration</a></h1>
<p>The Mesos master and agent can take a variety of configuration options
through command-line arguments or environment variables. A list of the
available options can be seen by running <code>mesos-master --help</code> or
<code>mesos-agent --help</code>. Each option can be set in two ways:</p>
<ul>
<li>
<p>By passing it to the binary using <code>--option_name=value</code>, either
specifying the value directly, or specifying a file in which the value
resides (<code>--option_name=file://path/to/file</code>). The path can be
absolute or relative to the current working directory.</p>
</li>
<li>
<p>By setting the environment variable <code>MESOS_OPTION_NAME</code> (the option
name with a <code>MESOS_</code> prefix added to it).</p>
</li>
</ul>
<p>Configuration values are searched for first in the environment, then
on the command-line.</p>
<p>Additionally, this documentation lists only a recent snapshot of the options in
Mesos. A definitive source for which flags your version of Mesos supports can be
found by running the binary with the flag <code>--help</code>, for example <code>mesos-master --help</code>.</p>
<h2 id="master-and-agent-options"><a class="header" href="#master-and-agent-options">Master and Agent Options</a></h2>
<p><em>These are options common to both the Mesos master and agent.</em></p>
<p>See <a href="configuration/master-and-agent.html">configuration/master-and-agent.md</a>.</p>
<h2 id="master-options"><a class="header" href="#master-options">Master Options</a></h2>
<p>See <a href="configuration/master.html">configuration/master.md</a>.</p>
<h2 id="agent-options"><a class="header" href="#agent-options">Agent Options</a></h2>
<p>See <a href="configuration/agent.html">configuration/agent.md</a>.</p>
<h2 id="libprocess-options"><a class="header" href="#libprocess-options">Libprocess Options</a></h2>
<p>See <a href="configuration/libprocess.html">configuration/libprocess.md</a>.</p>
<h1 id="mesos-build-configuration"><a class="header" href="#mesos-build-configuration">Mesos Build Configuration</a></h1>
<h2 id="autotools-options"><a class="header" href="#autotools-options">Autotools Options</a></h2>
<p>If you have special compilation requirements, please refer to <code>./configure --help</code> when configuring Mesos.</p>
<p>See <a href="configuration/autotools.html">configuration/autotools.md</a>.</p>
<h2 id="cmake-options"><a class="header" href="#cmake-options">CMake Options</a></h2>
<p>See <a href="configuration/cmake.html">configuration/cmake.md</a>.</p>
<h1 id="install-cmake-37"><a class="header" href="#install-cmake-37">Install CMake 3.7+</a></h1>
<h2 id="linux"><a class="header" href="#linux">Linux</a></h2>
<p>Install the latest version of CMake from <a href="https://cmake.org/download/">CMake.org</a>.
A self-extracting tarball is available to make this process painless.</p>
<p>Currently, few of the common Linux flavors package a sufficient CMake
version. Ubuntu versions 12.04 and 14.04 package CMake 2;
Ubuntu 16.04 packages CMake 3.5. If you already installed cmake from packages,
you may remove it via: <code>apt-get purge cmake</code>.</p>
<p>The standard CentOS package is CMake 2, and unfortunately even the <code>cmake3</code>
package in EPEL is only CMake 3.6, you may remove them via:
<code>yum remove cmake cmake3</code>.</p>
<h2 id="mac-os-x"><a class="header" href="#mac-os-x">Mac OS X</a></h2>
<p>HomeBrew's CMake version is sufficient: <code>brew install cmake</code>.</p>
<h2 id="windows-1"><a class="header" href="#windows-1">Windows</a></h2>
<p>Download and install the MSI from <a href="https://cmake.org/download/">CMake.org</a>.</p>
<p><strong>NOTE:</strong> Windows needs CMake 3.8+, rather than 3.7+.</p>
<h1 id="quick-start"><a class="header" href="#quick-start">Quick Start</a></h1>
<p>The most basic way to build with CMake, with no configuration, is fairly
straightforward:</p>
<pre><code>mkdir build
cd build
cmake ..
cmake --build .
</code></pre>
<p>The last step, <code>cmake --build .</code> can also take a <code>--target</code> command to build any
particular target (e.g. <code>mesos-tests</code>, or <code>tests</code> to build <code>mesos-tests</code>,
<code>libprocess-tests</code>, and <code>stout-tests</code>): <code>cmake --build . --target tests</code>. To
send arbitrary flags to the native build system underneath (e.g. <code>make</code>), append
the command with <code>-- &lt;flags to be passed&gt;</code>: <code>cmake --build . -- -j4</code>.</p>
<p>Also, <code>cmake --build</code> can be substituted by your build system of choice. For
instance, the default CMake generator on Linux produces GNU Makefiles, so after
configuring with <code>cmake ..</code>, you can just run <code>make tests</code> in the <code>build</code> folder
like usual. Similarly, if you configure with <code>-G Ninja</code> to use the Ninja
generator, you can then run <code>ninja tests</code> to build the <code>tests</code> target with
Ninja.</p>
<h1 id="installable-build"><a class="header" href="#installable-build">Installable build</a></h1>
<p>This example will build Mesos and install it into a custom prefix:</p>
<pre><code>mkdir build &amp;&amp; cd build
cmake -DCMAKE_INSTALL_PREFIX=/home/current_user/mesos
cmake --build . --target install
</code></pre>
<p>To additionally install <code>mesos-tests</code> executable and related test helpers
(this can be used to run Mesos tests against the installed binaries),
one can enable the <code>MESOS_INSTALL_TESTS</code> option.</p>
<p>To produce a set of binaries and libraries that will work after being
copied/moved to a different location, use <code>MESOS_FINAL_PREFIX</code>.</p>
<p>The example below employs both <code>MESOS_FINAL_PREFIX</code> and <code>MESOS_INSTALL_TESTS</code>.
On a build system:</p>
<pre><code>mkdir build &amp;&amp; cd build
cmake -DMESOS_FINAL_PREFIX=/opt/mesos -DCMAKE_INSTALL_PREFIX=/home/current_user/mesos -DMESOS_INSTALL_TESTS=ON
cmake --build . --target install
tar -czf mesos.tar.gz mesos -C /home/current_user
</code></pre>
<p>On a target system:</p>
<pre><code>sudo tar -xf mesos.tar.gz -C /opt
# Run tests against Mesos installation
sudo /opt/mesos/bin/mesos-tests
# Start Mesos agent
sudo /opt/mesos/bin/mesos-agent --work-dir=/var/lib/mesos ...
</code></pre>
<h1 id="supported-options"><a class="header" href="#supported-options">Supported options</a></h1>
<p>See <a href="configuration/cmake.html">configuration options</a>.</p>
<h1 id="examples-1"><a class="header" href="#examples-1">Examples</a></h1>
<p>See <a href="cmake-examples.html">CMake By Example</a>.</p>
<h1 id="documentation"><a class="header" href="#documentation">Documentation</a></h1>
<p>The <a href="https://cmake.org/cmake/help/latest/">CMake documentation</a> is written as a reference module. The most commonly
used sections are:</p>
<ul>
<li><a href="https://cmake.org/cmake/help/latest/manual/cmake-buildsystem.7.html">buildsystem overview</a></li>
<li><a href="https://cmake.org/cmake/help/latest/manual/cmake-commands.7.html">commands</a></li>
<li><a href="https://cmake.org/cmake/help/latest/manual/cmake-properties.7.html">properties</a></li>
<li><a href="https://cmake.org/cmake/help/latest/manual/cmake-variables.7.html">variables</a></li>
</ul>
<p>The wiki also has a set of <a href="https://cmake.org/Wiki/CMake_Useful_Variables">useful variables</a>.</p>
<h1 id="dependency-graph"><a class="header" href="#dependency-graph">Dependency graph</a></h1>
<p>Like any build system, CMake has a dependency graph. The difference is
that targets in CMake's dependency graph are <em>much richer</em> compared to other
build systems. CMake targets have the notion of 'interfaces', where build
properties are saved as part of the target, and these properties can be
inherited transitively within the graph.</p>
<p>For example, say there is a library <code>mylib</code>, and anything which links it must
include its headers, located in <code>mylib/include</code>. When building the library, some
private headers must also be included, but not when linking to it. When
compiling the executable <code>myprogram</code>, <code>mylib</code>'s public headers must be included,
but not its private headers. There is no manual step to add <code>mylib/include</code> to
<code>myprogram</code> (and any other program which links to <code>mylib</code>), it is instead
deduced from the public interface property of <code>mylib</code>. This is represented by
the following code:</p>
<pre><code># A new library with a single source file (headers are found automatically).
add_library(mylib mylib.cpp)

# The folder of private headers, not exposed to consumers of `mylib`.
target_include_directories(mylib PRIVATE mylib/private)

# The folder of public headers, added to the compilation of any consumer.
target_include_directories(mylib PUBLIC mylib/include)

# A new exectuable with a single source file.
add_executable(myprogram main.cpp)

# The creation of the link dependency `myprogram` -&gt; `mylib`.
target_link_libraries(myprogram mylib)

# There is no additional step to add `mylib/include` to `myprogram`.
</code></pre>
<p>This same notion applies to practically every build property:
compile definitions via <a href="https://cmake.org/cmake/help/latest/command/target_compile_definitions.html"><code>target_compile_definitions</code></a>,
include directories via <a href="https://cmake.org/cmake/help/latest/command/target_include_directories.html"><code>target_include_directories</code></a>,
link libraries via <a href="https://cmake.org/cmake/help/latest/command/target_link_libraries.html"><code>target_link_libraries</code></a>,
compile options via <a href="https://cmake.org/cmake/help/latest/command/target_compile_options.html"><code>target_compile_options</code></a>,
and compile features via <a href="https://cmake.org/cmake/help/latest/command/target_compile_features.html"><code>target_compile_features</code></a>.</p>
<p>All of these commands also take an optional argument of
<code>&lt;INTERFACE|PUBLIC|PRIVATE&gt;</code>, which constrains their transitivity in the graph.
That is, a <code>PRIVATE</code> include directory is recorded for the target, but not
shared transitively to anything depending on the target, <code>PUBLIC</code> is used
for both the target and dependencies on it, and <code>INTERFACE</code> is used only
for dependencies.</p>
<p>Notably missing from this list are link directories. CMake explicitly prefers
finding and using the absolute paths to libraries, obsoleting link directories.</p>
<h1 id="common-mistakes"><a class="header" href="#common-mistakes">Common mistakes</a></h1>
<h2 id="booleans"><a class="header" href="#booleans">Booleans</a></h2>
<p>CMake treats <code>ON</code>, <code>OFF</code>, <code>TRUE</code>, <code>FALSE</code>, <code>1</code>, and <code>0</code> all as true/false
booleans. Furthermore, variables of the form <code>&lt;target&gt;-NOTFOUND</code> are also
treated as false (this is used for finding packages).</p>
<p>In Mesos, we prefer the boolean types <code>TRUE</code> and <code>FALSE</code>.</p>
<p>See <a href="https://cmake.org/cmake/help/latest/command/if.html"><code>if</code></a> for more info.</p>
<h2 id="conditionals"><a class="header" href="#conditionals">Conditionals</a></h2>
<p>For historical reasons, CMake conditionals such as <code>if</code> and <code>elseif</code>
automatically interpolate variable names. It is therefore dangerous to
interpolate them manually, because if <code>${FOO}</code> evaluates to <code>BAR</code>, and <code>BAR</code> is
another variable name, then <code>if (${FOO})</code> becomes <code>if (BAR)</code>, and <code>BAR</code> is then
evaluated again by the <code>if</code>. Stick to <code>if (FOO)</code> to check the value of <code>${FOO}</code>.
Do not use <code>if (${FOO})</code>.</p>
<p>Also see the CMake policies
<a href="https://cmake.org/cmake/help/latest/policy/CMP0012.html">CMP0012</a> and
<a href="https://cmake.org/cmake/help/latest/policy/CMP0054.html">CMP0054</a>.</p>
<h2 id="definitions"><a class="header" href="#definitions">Definitions</a></h2>
<p>When using <code>add_definitions()</code> (which should be used rarely, as it is for
&quot;global&quot; compile definitions), the flags must be prefixed with <code>-D</code> to be
treated as preprocessor definitions. However, when using
<code>target_compile_definitions()</code> (which should be preferred, as it is
for specific targets), the flags do not need the prefix.</p>
<h1 id="style"><a class="header" href="#style">Style</a></h1>
<p>In general, wrap at 80 lines, and use a two-space indent. When wrapping
arguments, put the command on a separate line and arguments on subsequent lines:</p>
<pre><code>target_link_libraries(
  program PRIVATE
  alpha
  beta
  gamma)
</code></pre>
<p>Otherwise keep it together:</p>
<pre><code>target_link_libraries(program PUBLIC library)
</code></pre>
<p>Always keep the trailing parenthesis with the last argument.</p>
<p>Use a single space between conditionals and their open parenthesis, e.g.
<code>if (FOO)</code>, but not for commands, e.g. <code>add_executable(program)</code>.</p>
<p>CAPITALIZE the declaration and use of custom functions and macros (e.g.
<code>EXTERNAL</code> and <code>PATCH_CMD</code>), and do not capitalize the use of CMake built-in
(including modules) functions and macros. CAPITALIZE variables.</p>
<h1 id="cmake-anti-patterns"><a class="header" href="#cmake-anti-patterns">CMake anti-patterns</a></h1>
<p>Because CMake handles much more of the grunt work for you than other build
systems, there are unfortunately a lot of CMake <a href="http://voices.canonical.com/jussi.pakkanen/2013/03/26/a-list-of-common-cmake-antipatterns/">anti-patterns</a> you should
look out for when writing new CMake code. These are some common problems
that should be avoided when writing new CMake code:</p>
<h2 id="superfluous-use-of-add_dependencies"><a class="header" href="#superfluous-use-of-add_dependencies">Superfluous use of <code>add_dependencies</code></a></h2>
<p>When you've linked library <code>a</code> to library <code>b</code> with <code>target_link_libraries(a b)</code>,
the CMake graph is already updated with the dependency information. It is
redundant to use <code>add_dependencies(a b)</code> to (re)specify the dependency. In fact,
this command should <em>rarely</em> be used.</p>
<p>The exceptions to this are:</p>
<ol>
<li>Setting a dependency from an imported library to a target added via
<code>ExternalProject_Add</code>.</li>
<li>Setting a dependency on Mesos modules since no explicit linking is done.</li>
<li>Setting a dependency between executables (e.g. the <code>mesos-agent</code> requiring the
<code>mesos-containerizer</code> executable). In general, runtime dependencies need
to be setup with <code>add_dependency</code>, but never link dependencies.</li>
</ol>
<h2 id="use-of-link_libraries-or-link_directories"><a class="header" href="#use-of-link_libraries-or-link_directories">Use of <code>link_libraries</code> or <code>link_directories</code></a></h2>
<p>Neither of these commands should ever be used. The only appropriate command used
to link libraries is <a href="https://cmake.org/cmake/help/latest/command/target_link_libraries.html"><code>target_link_libraries</code></a>, which records the information
in the CMake dependency graph. Furthermore, imported third-party libraries
should have correct locations recorded in their respective targets, so the use
of <code>link_directories</code> should never be necessary. The
<a href="https://cmake.org/cmake/help/latest/command/link_directories.html">official documentation</a> states:</p>
<blockquote>
<p>Note that this command is rarely necessary. Library locations returned by
<code>find_package()</code> and <code>find_library()</code> are absolute paths. Pass these absolute
library file paths directly to the <code>target_link_libraries()</code> command. CMake
will ensure the linker finds them.</p>
</blockquote>
<p>The difference is that the former sets global (or directory level) side effects,
and the latter sets specific target information stored in the graph.</p>
<h2 id="use-of-include_directories"><a class="header" href="#use-of-include_directories">Use of <code>include_directories</code></a></h2>
<p>This is similar to the above: the <a href="https://cmake.org/cmake/help/latest/command/target_include_directories.html"><code>target_include_directories</code></a> should always
be preferred so that the include directory information remains localized to the
appropriate targets.</p>
<h2 id="adding-anything-to-endif-"><a class="header" href="#adding-anything-to-endif-">Adding anything to <code>endif ()</code></a></h2>
<p>Old versions of CMake expected the style <code>if (FOO) ... endif (FOO)</code>, where the
<code>endif</code> contained the same expression as the <code>if</code> command. However, this is
tortuously redundant, so leave the parentheses in <code>endif ()</code> empty. This goes
for other endings too, such as <code>endforeach ()</code>, <code>endwhile ()</code>, <code>endmacro ()</code> and
<code>endfunction ()</code>.</p>
<h2 id="specifying-header-files-superfluously"><a class="header" href="#specifying-header-files-superfluously">Specifying header files superfluously</a></h2>
<p>One of the distinct advantages of using CMake for C and C++ projects is that
adding header files to the source list for a target is unnecessary. CMake is
designed to parse the source files (<code>.c</code>, <code>.cpp</code>, etc.) and determine their
required headers automatically. The exception to this is headers generated as
part of the build (such as protobuf or the JNI headers).</p>
<h2 id="checking-cmake_build_type"><a class="header" href="#checking-cmake_build_type">Checking <code>CMAKE_BUILD_TYPE</code></a></h2>
<p>See the <a href="cmake-examples.html#building-debug-or-release-configurations">&quot;Building debug or release configurations&quot;</a>
example for more information. In short, not all generators respect the variable
<code>CMAKE_BUILD_TYPE</code> at configuration time, and thus it must not be used in CMake
logic. A usable alternative (where supported) is a <a href="https://cmake.org/cmake/help/latest/manual/cmake-generator-expressions.7.html#logical-expressions">generator expression</a> such
as <code>$&lt;$&lt;CONFIG:Debug&gt;:DEBUG_MODE&gt;</code>.</p>
<h1 id="remaining-hacks"><a class="header" href="#remaining-hacks">Remaining hacks</a></h1>
<h2 id="3rdparty_dependencies"><a class="header" href="#3rdparty_dependencies"><code>3RDPARTY_DEPENDENCIES</code></a></h2>
<p>Until Mesos on Windows is stable, we keep some dependencies in an external
repository, <a href="https://github.com/mesos/3rdparty">3rdparty</a>. When
all dependencies are bundled with Mesos, this extra repository will no longer be
necessary. Until then, the CMake variable <code>3RDPARTY_DEPENDENCIES</code> points by
default to this URL, but it can also point to the on-disk location of a local
clone of the repo. With this option you can avoid pulling from GitHub for every
clean build. Note that this must be an absolute path with forward slashes, e.g.
<code>-D3RDPARTY_DEPENDENCIES=C:/3rdparty</code>, otherwise it will fail on Windows.</p>
<h2 id="external"><a class="header" href="#external"><code>EXTERNAL</code></a></h2>
<p>The CMake function <code>EXTERNAL</code> defines a few variables that make it easy for us
to track the directory structure of a dependency. In particular, if our
library's name is <code>boost</code>, we invoke:</p>
<pre><code>EXTERNAL(boost ${BOOST_VERSION} ${CMAKE_CURRENT_BINARY_DIR})
</code></pre>
<p>Which will define the following variables as side-effects in the current scope:</p>
<ul>
<li><code>BOOST_TARGET</code>     (a target folder name to put dep in e.g., <code>boost-1.53.0</code>)</li>
<li><code>BOOST_CMAKE_ROOT</code> (where to have CMake put the uncompressed source, e.g.,
<code>build/3rdparty/boost-1.53.0</code>)</li>
<li><code>BOOST_ROOT</code>       (where the code goes in various stages of build, e.g.,
<code>build/.../boost-1.53.0/src</code>, which might contain folders
<code>build-1.53.0-build</code>, <code>-lib</code>, and so on, for each build
step that dependency has)</li>
</ul>
<p>The implementation is in <code>3rdparty/cmake/External.cmake</code>.</p>
<p>This is not to be confused with the CMake module <a href="https://cmake.org/cmake/help/latest/module/ExternalProject.html">ExternalProject</a>, from which
we use <code>ExternalProject_Add</code> to download, extract, configure, and build our
dependencies.</p>
<h2 id="cmake_noop"><a class="header" href="#cmake_noop"><code>CMAKE_NOOP</code></a></h2>
<p>This is a CMake variable we define in <code>3rdparty/CMakeLists.txt</code> so that we can
cancel steps of <code>ExternalProject</code>. <code>ExternalProject</code>'s default behavior is to
attempt to configure, build, and install a project using CMake. So when one of
these steps must be skipped, we use set it to <code>CMAKE_NOOP</code> so that nothing
is run instead.</p>
<h2 id="cmake_forward_args"><a class="header" href="#cmake_forward_args"><code>CMAKE_FORWARD_ARGS</code></a></h2>
<p>The <code>CMAKE_FORWARD_ARGS</code> variable defined in <code>3rdparty/CMakeLists.txt</code> is sent
as the <code>CMAKE_ARGS</code> argument to the <code>ExternalProject_Add</code> macro (along with any
per-project arguments), and is used when the external project is configured as a
CMake project. If either the <code>CONFIGURE_COMMAND</code> or <code>BUILD_COMMAND</code> arguments of
<code>ExternalProject_Add</code> are used, then the <code>CMAKE_ARGS</code> argument will be ignored.
This variable ensures that compilation configurations are properly propagated to
third-party dependencies, such as compiler flags.</p>
<h3 id="cmake_ssl_forward_args"><a class="header" href="#cmake_ssl_forward_args"><code>CMAKE_SSL_FORWARD_ARGS</code></a></h3>
<p>The <code>CMAKE_SSL_FORWARD_ARGS</code> variable defined in <code>3rdparty/CMakeLists.txt</code>
is like <code>CMAKE_FORWARD_ARGS</code>, but only used for specific external projects
that find and link against OpenSSL.</p>
<h2 id="library_linkage"><a class="header" href="#library_linkage"><code>LIBRARY_LINKAGE</code></a></h2>
<p>This variable is a shortcut used in <code>3rdparty/CMakeLists.txt</code>. It is set to
<code>SHARED</code> when <code>BUILD_SHARED_LIBS</code> is true, and otherwise it is set to <code>STATIC</code>.
The <code>SHARED</code> and <code>STATIC</code> keywords are used to declare how a library should be
built; however, if left out then the type is deduced automatically from
<code>BUILD_SHARED_LIBS</code>.</p>
<h2 id="make_include_dir"><a class="header" href="#make_include_dir"><code>MAKE_INCLUDE_DIR</code></a></h2>
<p>This function works around a <a href="https://gitlab.kitware.com/cmake/cmake/issues/15052">CMake issue</a> with setting include
directories of imported libraries built with <code>ExternalProject_Add</code>. We have to
call this for each <code>IMPORTED</code> third-party dependency which has set
<code>INTERFACE_INCLUDE_DIRECTORIES</code>, just to make CMake happy. An example is Glog:</p>
<pre><code>MAKE_INCLUDE_DIR(glog)
</code></pre>
<h2 id="get_byproducts"><a class="header" href="#get_byproducts"><code>GET_BYPRODUCTS</code></a></h2>
<p>This function works around a <a href="https://cmake.org/pipermail/cmake/2015-April/060234.html">CMake issue</a> with the Ninja
generator where it does not understand imported libraries, and instead needs
<code>BUILD_BYPRODUCTS</code> explicitly set. This simply allows us to use
<code>ExternalProject_Add</code> and Ninja. For Glog, it looks like this:</p>
<pre><code>GET_BYPRODUCTS(glog)
</code></pre>
<p>Also see the CMake policy <a href="https://cmake.org/cmake/help/latest/policy/CMP0058.html">CMP0058</a>.</p>
<h2 id="patch_cmd"><a class="header" href="#patch_cmd"><code>PATCH_CMD</code></a></h2>
<p>The CMake function <code>PATCH_CMD</code> generates a patch command given a patch file.
If the path is not absolute, it's resolved to the current source directory.
It stores the command in the variable name supplied. This is used to easily
patch third-party dependencies. For Glog, it looks like this:</p>
<pre><code>PATCH_CMD(GLOG_PATCH_CMD glog-${GLOG_VERSION}.patch)
ExternalProject_Add(
  ${GLOG_TARGET}
  ...
  PATCH_COMMAND     ${GLOG_PATCH_CMD})
</code></pre>
<p>The implementation is in <code>3rdparty/cmake/PatchCommand.cmake</code>.</p>
<h3 id="windows-patchexe"><a class="header" href="#windows-patchexe">Windows <code>patch.exe</code></a></h3>
<p>While using <code>patch</code> on Linux is straightforward, doing the same on Windows takes
a bit of work. <code>PATH_CMD</code> encapsulates this:</p>
<ul>
<li>Checks the cache variable <code>PATCHEXE_PATH</code> for <code>patch.exe</code>.</li>
<li>Searches for <code>patch.exe</code> in its default locations.</li>
<li>Copies <code>patch.exe</code> and a custom manifest to the temporary directory.</li>
<li>Applies the manifest to avoid the UAC prompt.</li>
<li>Uses the patched <code>patch.exe</code>.</li>
</ul>
<p>As such, <code>PATCH_CMD</code> lets us apply patches as we do on Linux, without requiring
an administrative prompt.</p>
<p>Note that on Windows, the patch file must have CRLF line endings. A file with LF
line endings will cause the error: &quot;Assertion failed, hunk, file patch.c, line
343&quot;. For this reason, it is required to checkout the Mesos repo with <code>git config core.autocrlf true</code>.</p>
<h1 id="windows-2"><a class="header" href="#windows-2">Windows</a></h1>
<p>Mesos 1.0.0 introduced experimental support for Windows.</p>
<h2 id="building-mesos"><a class="header" href="#building-mesos">Building Mesos</a></h2>
<h3 id="system-requirements-1"><a class="header" href="#system-requirements-1">System Requirements</a></h3>
<ol>
<li>
<p>Install the latest <a href="https://www.visualstudio.com/downloads/">Visual Studio 2017</a>:
The &quot;Community&quot; edition is sufficient (and free of charge).
During installation, choose the &quot;Desktop development with C++&quot; workload.</p>
</li>
<li>
<p>Install <a href="https://cmake.org/download/">CMake 3.8.0</a> or later.
During installation, choose to &quot;Add CMake to the system PATH for all users&quot;.</p>
</li>
<li>
<p>Install <a href="http://gnuwin32.sourceforge.net/packages/patch.htm">GNU patch for Windows</a>.</p>
</li>
<li>
<p>If building from source, install <a href="https://git-scm.com/download/win">Git</a>.</p>
</li>
<li>
<p>Make sure there are no spaces in your build directory.
For example, <code>C:/Program Files (x86)/mesos</code> is an invalid build directory.</p>
</li>
<li>
<p>If developing Mesos, install <a href="https://www.python.org/downloads/">Python 3</a>
(not Python 2), in order to use our <code>support</code> scripts (e.g.
to post and apply patches, or lint source code).</p>
</li>
</ol>
<h3 id="build-instructions"><a class="header" href="#build-instructions">Build Instructions</a></h3>
<p>Following are the instructions for Windows 10.</p>
<pre><code># Clone (or extract) Mesos.
git clone https://gitbox.apache.org/repos/asf/mesos.git
cd mesos

# Configure using CMake for an out-of-tree build.
mkdir build
cd build
cmake .. -G &quot;Visual Studio 15 2017 Win64&quot; -T &quot;host=x64&quot;

# Build Mesos.
# To build just the Mesos agent, add `--target mesos-agent`.
cmake --build .

# The Windows agent exposes new isolators that must be used as with
# the `--isolation` flag. To get started point the agent to a working
# master, using eiher an IP address or zookeeper information.
.\src\mesos-agent.exe --master=&lt;master&gt; --work_dir=&lt;work folder&gt; --launcher_dir=&lt;repository&gt;\build\src
</code></pre>
<h2 id="running-mesos"><a class="header" href="#running-mesos">Running Mesos</a></h2>
<p>If you deploy the executables to another machine, you must also
install the <a href="https://aka.ms/vs/15/release/VC_redist.x64.exe">Microsoft Visual C++ Redistributable for Visual Studio 2017</a>.</p>
<h2 id="known-limitations"><a class="header" href="#known-limitations">Known Limitations</a></h2>
<p>The current implementation is known to have the following limitations:</p>
<ul>
<li>
<p>Only the agent should be run on Windows. The Mesos master can be
launched, but only for testing as the master does not support
high-availability setups on Windows.</p>
</li>
<li>
<p>While Mesos supports NTFS long paths internally, tasks which do not support
long paths must be run on agent whose <code>--work_dir</code> is a short path.</p>
</li>
<li>
<p>The minimum versions of Windows supported are: Windows 10 Creators Update (AKA
version 1703, build number 15063), and <a href="https://docs.microsoft.com/en-us/windows-server/get-started/get-started-with-1709">Windows Server, version 1709</a>.
It is likely that this will increase, due to evolving Windows container
support and developer features which ease porting.</p>
</li>
<li>
<p>The ability to <a href="https://blogs.windows.com/buildingapps/2016/12/02/symlinks-windows-10/">create symlinks</a> as a non-admin user requires
Developer Mode to be enabled. Otherwise the agent will need to be
run under an administrator.</p>
</li>
</ul>
<h2 id="build-configuration-examples"><a class="header" href="#build-configuration-examples">Build Configuration Examples</a></h2>
<h3 id="building-with-ninja"><a class="header" href="#building-with-ninja">Building with Ninja</a></h3>
<p>Instead of using MSBuild, it is also possible to build Mesos on
Windows using <a href="https://ninja-build.org/">Ninja</a>, which can result in
significantly faster builds. To use Ninja, you need to download it and
ensure <code>ninja.exe</code> is in your <code>PATH</code>.</p>
<ul>
<li>Download the <a href="https://github.com/ninja-build/ninja/releases">Windows binary</a>.</li>
<li>Unzip it and place <code>ninja.exe</code> in your <code>PATH</code>.</li>
<li>Open an &quot;x64 Native Tools Command Prompt for VS 2017&quot; to set your
environment.</li>
<li>In that command prompt, type <code>powershell</code> to use a better shell.</li>
<li>Similar to above, configure CMake with <code>cmake .. -G Ninja</code>.</li>
<li>Now you can use <code>ninja</code> to build the various targets.</li>
<li>You may want to use <code>ninja -v</code> to make it verbose, as it's otherwise
very quiet.</li>
</ul>
<p>Note that with Ninja it is imperative to open the correct developer
command prompt so that the 64-bit build tools are used, as Ninja does
not otherwise know how to find them.</p>
<h3 id="building-with-java"><a class="header" href="#building-with-java">Building with Java</a></h3>
<p>This enables more unit tests, but we do not yet officially produce
<code>mesos-master</code>.</p>
<p>When building with Java on Windows, you must add the <a href="https://maven.apache.org/guides/getting-started/windows-prerequisites.html">Maven</a> build tool to
your path. The <code>JAVA_HOME</code> environment variable must also be manually set.
An installation of the Java SDK can be found form <a href="http://www.oracle.com/technetwork/java/javase/downloads/index.html">Oracle</a>.</p>
<p>As of this writing, Java 9 is not yet supported, but Java 8 has been tested.</p>
<p>The Java build defaults to <code>OFF</code> because it is slow. To build the Java
components on Windows, turn it <code>ON</code>:</p>
<pre><code class="language-powershell">mkdir build; cd build
$env:PATH += &quot;;C:\...\apache-maven-3.3.9\bin\&quot;
$env:JAVA_HOME = &quot;C:\Program Files\Java\jdk1.8.0_144&quot;
cmake .. -DENABLE_JAVA=ON -G &quot;Visual Studio 15 2017 Win64&quot; -T &quot;host=x64&quot;
cmake --build . --target mesos-java
</code></pre>
<p>Note that the <code>mesos-java</code> library does not have to be manually built; as
<code>libmesos</code> will link it when Java is enabled.</p>
<p>Unfortunately, on Windows the <code>FindJNI</code> CMake module will populate <code>JAVA_JVM_LIBRARY</code> with
the path to the static <code>jvm.lib</code>, but this variable must point to the shared
library, <code>jvm.dll</code>, as it is loaded at runtime. Set it correctly like this:</p>
<pre><code>$env:JAVA_JVM_LIBRARY = &quot;C:\Program Files\Java\jdk1.8.0_144\jre\bin\server\jvm.dll&quot;
</code></pre>
<p>The library may still fail to load at runtime with the following error:</p>
<blockquote>
<p>&quot;The specified module could not be found.&quot;</p>
</blockquote>
<p>If this is the case, and the path to <code>jvm.dll</code> is verified to be correct, then
the error message actually indicates that the dependencies of <code>jvm.dll</code> could
not be found. On Windows, the DLL search path includes the environment variable
<code>PATH</code>, so add the <code>bin</code> folder which contains <code>server\jvm.dll</code> to <code>PATH</code>:</p>
<pre><code>$env:PATH += &quot;;C:\Program Files\Java\jdk1.8.0_144\jre\bin&quot;
</code></pre>
<h3 id="building-with-openssl"><a class="header" href="#building-with-openssl">Building with OpenSSL</a></h3>
<p>When building with OpenSSL on Windows, you must build or install a distribution
of OpenSSL for Windows. A commonly chosen distribution is
<a href="https://slproweb.com/products/Win32OpenSSL.html">Shining Light Productions' OpenSSL</a>.</p>
<p>As of this writing, OpenSSL 1.1.x is supported.</p>
<p>Use <code>-DENABLE_SSL=ON</code> to build with OpenSSL.</p>
<p>Note that it will link to OpenSSL dynamically, so if the built executables are
deployed elsewhere, that machine also needs OpenSSL installed.</p>
<p>Beware that the OpenSSL installation, nor Mesos itself, comes with a certificate
bundle, and so it is likely that certificate verification will fail.</p>
<h1 id="mesos-runtime-configuration-1"><a class="header" href="#mesos-runtime-configuration-1">Mesos Runtime Configuration</a></h1>
<p>The Mesos master and agent can take a variety of configuration options
through command-line arguments or environment variables. A list of the
available options can be seen by running <code>mesos-master --help</code> or
<code>mesos-agent --help</code>. Each option can be set in two ways:</p>
<ul>
<li>
<p>By passing it to the binary using <code>--option_name=value</code>, either
specifying the value directly, or specifying a file in which the value
resides (<code>--option_name=file://path/to/file</code>). The path can be
absolute or relative to the current working directory.</p>
</li>
<li>
<p>By setting the environment variable <code>MESOS_OPTION_NAME</code> (the option
name with a <code>MESOS_</code> prefix added to it).</p>
</li>
</ul>
<p>Configuration values are searched for first in the environment, then
on the command-line.</p>
<p>Additionally, this documentation lists only a recent snapshot of the options in
Mesos. A definitive source for which flags your version of Mesos supports can be
found by running the binary with the flag <code>--help</code>, for example <code>mesos-master --help</code>.</p>
<h2 id="master-and-agent-options-1"><a class="header" href="#master-and-agent-options-1">Master and Agent Options</a></h2>
<p><em>These are options common to both the Mesos master and agent.</em></p>
<p>See <a href="configuration/master-and-agent.html">configuration/master-and-agent.md</a>.</p>
<h2 id="master-options-1"><a class="header" href="#master-options-1">Master Options</a></h2>
<p>See <a href="configuration/master.html">configuration/master.md</a>.</p>
<h2 id="agent-options-1"><a class="header" href="#agent-options-1">Agent Options</a></h2>
<p>See <a href="configuration/agent.html">configuration/agent.md</a>.</p>
<h2 id="libprocess-options-1"><a class="header" href="#libprocess-options-1">Libprocess Options</a></h2>
<p>See <a href="configuration/libprocess.html">configuration/libprocess.md</a>.</p>
<h1 id="mesos-build-configuration-1"><a class="header" href="#mesos-build-configuration-1">Mesos Build Configuration</a></h1>
<h2 id="autotools-options-1"><a class="header" href="#autotools-options-1">Autotools Options</a></h2>
<p>If you have special compilation requirements, please refer to <code>./configure --help</code> when configuring Mesos.</p>
<p>See <a href="configuration/autotools.html">configuration/autotools.md</a>.</p>
<h2 id="cmake-options-1"><a class="header" href="#cmake-options-1">CMake Options</a></h2>
<p>See <a href="configuration/cmake.html">configuration/cmake.md</a>.</p>
<h1 id="mesos-high-availability-mode"><a class="header" href="#mesos-high-availability-mode">Mesos High-Availability Mode</a></h1>
<p>If the Mesos master is unavailable, existing tasks can continue to execute, but new resources cannot be allocated and new tasks cannot be launched. To reduce the chance of this situation occurring, Mesos has a high-availability mode that uses multiple Mesos masters: one active master (called the <em>leader</em> or leading master) and several <em>backups</em> in case it fails. The masters elect the leader, with <a href="http://zookeeper.apache.org/">Apache ZooKeeper</a> both coordinating the election and handling leader detection by masters, agents, and scheduler drivers. More information regarding <a href="https://zookeeper.apache.org/doc/current/recipes.html#sc_leaderElection">how leader election works</a> is available on the Apache Zookeeper website.</p>
<p>This document describes how to configure Mesos to run in high-availability mode. For more information on developing highly available frameworks, see a <a href="high-availability-framework-guide.html">companion document</a>.</p>
<p><strong>Note</strong>: This document assumes you know how to start, run, and work with ZooKeeper, whose client library is included in the standard Mesos build.</p>
<h2 id="usage"><a class="header" href="#usage">Usage</a></h2>
<p>To put Mesos into high-availability mode:</p>
<ol>
<li>
<p>Ensure that the ZooKeeper cluster is up and running.</p>
</li>
<li>
<p>Provide the znode path to all masters, agents, and framework schedulers as follows:</p>
<ul>
<li>
<p>Start the mesos-master binaries using the <code>--zk</code> flag, e.g. <code>--zk=zk://host1:port1,host2:port2,.../path</code></p>
</li>
<li>
<p>Start the mesos-agent binaries with <code>--master=zk://host1:port1,host2:port2,.../path</code></p>
</li>
<li>
<p>Start any framework schedulers using the same <code>zk</code> path as in the last two steps. The SchedulerDriver must be constructed with this path, as shown in the <a href="app-framework-development-guide.html">Framework Development Guide</a>.</p>
</li>
</ul>
</li>
</ol>
<p>From now on, the Mesos masters and agents all communicate with ZooKeeper to find out which master is the current leading master. This is in addition to the usual communication between the leading master and the agents.</p>
<p>In addition to ZooKeeper, one can get the location of the leading master by sending an HTTP request to <a href="endpoints/master/redirect.html">/redirect</a> endpoint on any master.</p>
<p>For HTTP endpoints that only work at the leading master, requests made to endpoints at a non-leading master will result in either a <code>307 Temporary Redirect</code> (with the location of the leading master) or <code>503 Service Unavailable</code> (if the master does not know who the current leader is).</p>
<p>Refer to the <a href="app-framework-development-guide.html">Scheduler API</a> for how to deal with leadership changes.</p>
<h2 id="component-disconnection-handling"><a class="header" href="#component-disconnection-handling">Component Disconnection Handling</a></h2>
<p>When a network partition disconnects a component (master, agent, or scheduler driver) from ZooKeeper, the component's Master Detector induces a timeout event. This notifies the component that it has no leading master. Depending on the component, the following happens. (Note that while a component is disconnected from ZooKeeper, a master may still be in communication with agents or schedulers and vice versa.)</p>
<ul>
<li>
<p>Agents disconnected from ZooKeeper no longer know which master is the leader. They ignore messages from masters to ensure they don't act on a non-leader's decisions. When an agent reconnects to ZooKeeper, ZooKeeper informs it of the current leader and the agent stops ignoring messages from the leader.</p>
</li>
<li>
<p>Masters enter leaderless state irrespective of whether they are a leader or not before the disconnection.</p>
<ul>
<li>
<p>If the leader was disconnected from ZooKeeper, it aborts its process. The user/developer/administrator can then start a new master instance which will try to reconnect to ZooKeeper.</p>
<ul>
<li>Note that many production deployments of Mesos use a process supervisor (such as systemd or supervisord) that is configured to automatically restart the Mesos master if the process aborts unexpectedly.</li>
</ul>
</li>
<li>
<p>Otherwise, the disconnected backup waits to reconnect with ZooKeeper and possibly get elected as the new leading master.</p>
</li>
</ul>
</li>
<li>
<p>Scheduler drivers disconnected from the leading master notify the scheduler about their disconnection from the leader.</p>
</li>
</ul>
<p>When a network partition disconnects an agent from the leader:</p>
<ul>
<li>
<p>The agent fails health checks from the leader.</p>
</li>
<li>
<p>The leader marks the agent as deactivated and sends its tasks to the LOST state. The  <a href="app-framework-development-guide.html">Framework Development Guide</a> describes these various task states.</p>
</li>
<li>
<p>Deactivated agents may not reregister with the leader and are told to shut down upon any post-deactivation communication.</p>
</li>
</ul>
<h2 id="monitoring"><a class="header" href="#monitoring">Monitoring</a></h2>
<p>For monitoring the current number of masters in the cluster communicating with each other to form a quorum, see the monitoring guide's <a href="monitoring.html#replicated-log">Replicated Log</a> on <code>registrar/log/ensemble_size</code>.
For creating alerts covering failures in leader election, have a look at the monitoring guide's <a href="monitoring.html#basic-alerts">Basic Alerts</a> on <code>master/elected</code>.</p>
<h2 id="implementation-details-1"><a class="header" href="#implementation-details-1">Implementation Details</a></h2>
<p>Mesos implements two levels of ZooKeeper leader election abstractions, one in <code>src/zookeeper</code> and the other in <code>src/master</code> (look for <code>contender|detector.hpp|cpp</code>).</p>
<ul>
<li>
<p>The lower level <code>LeaderContender</code> and <code>LeaderDetector</code> implement a generic ZooKeeper election algorithm loosely modeled after this
<a href="http://zookeeper.apache.org/doc/current/recipes.html#sc_leaderElection">recipe</a> (sans herd effect handling due to the master group's small size, which is often 3).</p>
</li>
<li>
<p>The higher level <code>MasterContender</code> and <code>MasterDetector</code> wrap around ZooKeeper's contender and detector abstractions as adapters to provide/interpret the ZooKeeper data.</p>
</li>
<li>
<p>Each Mesos master simultaneously uses both a contender and a detector to try to elect themselves and detect who the current leader is. A separate detector is necessary because each master's WebUI redirects browser traffic to the current leader when that master is not elected. Other Mesos components (i.e., agents and scheduler drivers) use the detector to find the current leader and connect to it.</p>
</li>
</ul>
<p>The notion of the group of leader candidates is implemented in <code>Group</code>. This abstraction handles reliable (through queues and retries of retryable errors under the covers) ZooKeeper group membership registration, cancellation, and monitoring. It watches for several ZooKeeper session events:</p>
<ul>
<li>Connection</li>
<li>Reconnection</li>
<li>Session Expiration</li>
<li>ZNode creation, deletion, updates</li>
</ul>
<p>We also explicitly timeout our sessions when disconnected from ZooKeeper for a specified amount of time. See <code>--zk_session_timeout</code> configuration option. This is because the ZooKeeper client libraries only notify of session expiration upon reconnection. These timeouts are of particular interest for network partitions.</p>
<h1 id="the-mesos-replicated-log"><a class="header" href="#the-mesos-replicated-log">The Mesos Replicated Log</a></h1>
<p>Mesos provides a library that lets you create replicated fault-tolerant append-only logs; this library is known as the <em>replicated log</em>. The Mesos master uses this library to store cluster state in a replicated, durable way; the library is also available for use by frameworks to store replicated framework state or to implement the common &quot;<a href="https://en.wikipedia.org/wiki/State_machine_replication">replicated state machine</a>&quot; pattern.</p>
<h2 id="what-is-the-replicated-log"><a class="header" href="#what-is-the-replicated-log">What is the replicated log?</a></h2>
<p><img src="images/log-cluster.png" alt="Aurora and the Replicated Log" /></p>
<p>The replicated log provides <em>append-only</em> storage of <em>log entries</em>; each log entry can contain arbitrary data. The log is <em>replicated</em>, which means that each log entry has multiple copies in the system. Replication provides both fault tolerance and high availability. In the following example, we use <a href="https://aurora.apache.org/">Apache Aurora</a>, a fault tolerant scheduler (i.e., framework) running on top of Mesos, to show a typical replicated log setup.</p>
<p>As shown above, there are multiple Aurora instances running simultaneously (for high availability), with one elected as the leader. There is a log replica on each host running Aurora. Aurora can access the replicated log through a thin library containing the log API.</p>
<p>Typically, the leader is the only one that appends data to the log. Each log entry is replicated and sent to all replicas in the system. Replicas are strongly consistent. In other words, all replicas agree on the value of each log entry. Because the log is replicated, when Aurora decides to failover, it does not need to copy the log from a remote host.</p>
<h2 id="use-cases"><a class="header" href="#use-cases">Use Cases</a></h2>
<p>The replicated log can be used to build a wide variety of distributed applications. For example, Aurora uses the replicated log to store all task states and job configurations. The Mesos master's <em>registry</em> also leverages the replicated log to store information about all agents in the cluster.</p>
<p>The replicated log is often used to allow applications to manage replicated state in a strongly consistent way. One way to do this is to store a state-mutating operation in each log entry and have all instances of the distributed application agree on the same initial state (e.g., empty state). The replicated log ensures that each application instance will observe the same sequence of log entries in the same order; as long as applying a state-mutating operation is deterministic, this ensures that all application instances will remain consistent with one another. If any instance of the application crashes, it can reconstruct the current version of the replicated state by starting at the initial state and re-applying all the logged mutations in order.</p>
<p>If the log grows too large, an application can write out a snapshot and then delete all the log entries that occurred before the snapshot. Using this approach, we will be exposing a <a href="https://github.com/apache/mesos/blob/master/src/state/state.hpp">distributed state</a> abstraction in Mesos with replicated log as a backend.</p>
<p>Similarly, the replicated log can be used to build <a href="https://en.wikipedia.org/wiki/State_machine_replication">replicated state machines</a>. In this scenario, each log entry contains a state machine command. Since replicas are strongly consistent, all servers will execute the same commands in the same order.</p>
<h2 id="implementation"><a class="header" href="#implementation">Implementation</a></h2>
<p><img src="images/log-architecture.png" alt="Replicated Log Architecture" /></p>
<p>The replicated log uses the <a href="https://en.wikipedia.org/wiki/Paxos_%28computer_science%29">Paxos consensus algorithm</a> to ensure that all replicas agree on every log entry's value. It is similar to what's described in <a href="https://ramcloud.stanford.edu/%7Eongaro/userstudy/paxos.pdf">these slides</a>. Readers who are familiar with Paxos can skip this section.</p>
<p>The above figure is an implementation overview. When a user wants to append data to the log, the system creates a log writer. The log writer internally creates a coordinator. The coordinator contacts all replicas and executes the Paxos algorithm to make sure all replicas agree about the appended data. The coordinator is sometimes referred to as the <a href="https://en.wikipedia.org/wiki/Paxos_%28computer_science%29"><em>proposer</em></a>.</p>
<p>Each replica keeps an array of log entries. The array index is the log position. Each log entry is composed of three components: the value written by the user, the associated Paxos state and a <em>learned</em> bit where true means this log entry's value has been agreed. Therefore, a replica in our implementation is both an <a href="https://en.wikipedia.org/wiki/Paxos_%28computer_science%29"><em>acceptor</em></a> and a <a href="https://en.wikipedia.org/wiki/Paxos_%28computer_science%29"><em>learner</em></a>.</p>
<h3 id="reaching-consensus-for-a-single-log-entry"><a class="header" href="#reaching-consensus-for-a-single-log-entry">Reaching consensus for a single log entry</a></h3>
<p>A Paxos round can help all replicas reach consensus on a single log entry's value. It has two phases: a promise phase and a write phase. Note that we are using slightly different terminology from the <a href="https://research.microsoft.com/en-us/um/people/lamport/pubs/paxos-simple.pdf">original Paxos paper</a>. In our implementation, the <em>prepare</em> and <em>accept</em> phases in the original paper are referred to as the <em>promise</em> and <em>write</em> phases, respectively. Consequently, a prepare request (response) is referred to as a promise request (response), and an accept request (response) is referred to as a write request (response).</p>
<p>To append value <em>X</em> to the log at position <em>p</em>, the coordinator first broadcasts a promise request to all replicas with proposal number <em>n</em>, asking replicas to promise that they will not respond to any request (promise/write request) with a proposal number lower than <em>n</em>. We assume that <em>n</em> is higher than any other previously used proposal number, and will explain how we do this later.</p>
<p>When receiving the promise request, each replica checks its Paxos state to decide if it can safely respond to the request, depending on the promises it has previously given out. If the replica is able to give the promise (i.e., passes the proposal number check), it will first persist its promise (the proposal number <em>n</em>) on disk and reply with a promise response. If the replica has been previously written (i.e., accepted a write request), it needs to include the previously written value along with the proposal number used in that write request into the promise response it's about to send out.</p>
<p>Upon receiving promise responses from a <a href="https://en.wikipedia.org/wiki/Quorum_%28distributed_computing%29">quorum</a> of replicas, the coordinator first checks if there exist any previously written value from those responses. The append operation cannot continue if a previously written value is found because it's likely that a value has already been agreed on for that log entry. This is one of the key ideas in Paxos: restrict the value that can be written to ensure consistency.</p>
<p>If no previous written value is found, the coordinator broadcasts a write request to all replicas with value <em>X</em> and proposal number <em>n</em>. On receiving the write request, each replica checks the promise it has given again, and replies with a write response if the write request's proposal number is equal to or larger than the proposal number it has promised. Once the coordinator receives write responses from a quorum of replicas, the append operation succeeds.</p>
<h3 id="optimizing-append-latency-using-multi-paxos"><a class="header" href="#optimizing-append-latency-using-multi-paxos">Optimizing append latency using Multi-Paxos</a></h3>
<p>One naive solution to implement a replicated log is to run a full Paxos round (promise phase and write phase) for each log entry. As discussed in the <a href="https://research.microsoft.com/en-us/um/people/lamport/pubs/paxos-simple.pdf">original Paxos paper</a>, if the leader is relatively stable, <em>Multi-Paxos</em> can be used to eliminate the need for the promise phase for most of the append operations, resulting in improved performance.</p>
<p>To do that, we introduce a new type of promise request called an <em>implicit</em> promise request. An implicit promise request can be viewed as a <em>batched</em> promise request for a (potentially infinite) set of log entries. Broadcasting an implicit promise request is conceptually equivalent to broadcasting a promise request for every log entry whose value has not yet been agreed. If the implicit promise request broadcasted by a coordinator gets accepted by a quorum of replicas, this coordinator is no longer required to run the promise phase if it wants to append to a log entry whose value has not yet been agreed because the promise phase has already been done in <em>batch</em>. The coordinator in this case is therefore called <em>elected</em> (a.k.a., the leader), and has <em>exclusive</em> access to the replicated log. An elected coordinator may be <em>demoted</em> (or lose exclusive access) if another coordinator broadcasts an implicit promise request with a higher proposal number.</p>
<p>One question remaining is how can we find out those log entries whose values have not yet been agreed. We have a very simple solution: if a replica accepts an implicit promise request, it will include its largest known log position in the response. An elected coordinator will only append log entries at positions larger than <em>p</em>, where <em>p</em> is greater than any log position seen in these responses.</p>
<p>Multi-Paxos has better performance if the leader is stable. The replicated log itself does not perform leader election. Instead, we rely on the user of the replicated log to choose a stable leader. For example, Aurora uses <a href="https://zookeeper.apache.org/">ZooKeeper</a> to elect the leader.</p>
<h3 id="enabling-local-reads"><a class="header" href="#enabling-local-reads">Enabling local reads</a></h3>
<p>As discussed above, in our implementation, each replica is both an acceptor and a learner. Treating each replica as a learner allows us to do local reads without involving other replicas. When a log entry's value has been agreed, the coordinator will broadcast a <em>learned</em> message to all replicas. Once a replica receives the learned message, it will set the learned bit in the corresponding log entry, indicating the value of that log entry has been agreed. We say a log entry is &quot;learned&quot; if its learned bit is set. The coordinator does not have to wait for replicas' acknowledgments.</p>
<p>To perform a read, the log reader will directly look up the underlying local replica. If the corresponding log entry is learned, the reader can just return the value to the user. Otherwise, a full Paxos round is needed to discover the agreed value. We always make sure that the replica co-located with the elected coordinator always has all log entries learned. We achieve that by running full Paxos rounds for those unlearned log entries after the coordinator is elected.</p>
<h3 id="reducing-log-size-using-garbage-collection"><a class="header" href="#reducing-log-size-using-garbage-collection">Reducing log size using garbage collection</a></h3>
<p>In case the log grows large, the application has the choice to truncate the log. To perform a truncation, we append a special log entry whose value is the log position to which the user wants to truncate the log. A replica can actually truncate the log once this special log entry has been learned.</p>
<h3 id="unique-proposal-number"><a class="header" href="#unique-proposal-number">Unique proposal number</a></h3>
<p>Many of the <a href="https://research.microsoft.com/en-us/um/people/lamport/pubs/paxos-simple.pdf">Paxos research papers</a> assume that each proposal number is globally unique, and a coordinator can always come up with a proposal number that is larger than any other proposal numbers in the system. However, implementing this is not trivial, especially in a distributed environment. <a href="https://ramcloud.stanford.edu/%7Eongaro/userstudy/paxos.pdf">Some researchers suggest</a> concatenating a globally unique server id to each proposal number. But it is still not clear how to generate a globally unique id for each server.</p>
<p>Our solution does not make the above assumptions. A coordinator can use an arbitrary proposal number initially. During the promise phase, if a replica knows a proposal number higher than the proposal number used by the coordinator, it will send the largest known proposal number back to the coordinator. The coordinator will retry the promise phase with a higher proposal number.</p>
<p>To avoid livelock (e.g., when two coordinators completing), we inject a randomly delay between T and 2T before each retry. T has to be chosen carefully. On one hand, we want T &gt;&gt; broadcast time such that one coordinator usually times out and wins before others wake up. On the other hand, we want T to be as small as possible such that we can reduce the wait time. Currently, we use T = 100ms. This idea is actually borrowed from <a href="https://ramcloud.stanford.edu/wiki/download/attachments/11370504/raft.pdf">Raft</a>.</p>
<h2 id="automatic-replica-recovery"><a class="header" href="#automatic-replica-recovery">Automatic replica recovery</a></h2>
<p>The algorithm described above has a critical vulnerability: if a replica loses its durable state (i.e., log files) due to either disk failure or operational error, that replica may cause inconsistency in the log if it is simply restarted and re-added to the group. The operator needs to stop the application on all hosts, copy the log files from the leader's host, and then restart the application. Note that the operator cannot copy the log files from an arbitrary replica because copying an unlearned log entry may falsely assemble a quorum for an incorrect value, leading to inconsistency.</p>
<p>To avoid the need for operator intervention in this situation, the Mesos replicated log includes support for <em>auto recovery</em>. As long as a quorum of replicas is working properly, the users of the application won't notice any difference.</p>
<h3 id="non-voting-replicas"><a class="header" href="#non-voting-replicas">Non-voting replicas</a></h3>
<p>To enable auto recovery, a key insight is that a replica that loses its durable state should not be allowed to respond to requests from coordinators after restart. Otherwise, it may introduce inconsistency in the log as it could have accepted a promise/write request which it would not have accepted if its previous Paxos state had not been lost.</p>
<p>To solve that, we introduce a new status variable for each replica. A normal replica is said in VOTING status, meaning that it is allowed to respond to requests from coordinators. A replica with no persisted state is put in EMPTY status by default. A replica in EMPTY status is not allowed to respond to any request from coordinators.</p>
<p>A replica in EMPTY status will be promoted to VOTING status if the following two conditions are met:</p>
<ol>
<li>a sufficient amount of missing log entries are recovered such that if other replicas fail, the remaining replicas can recover all the learned log entries, and</li>
<li>its future responses to a coordinator will not break any of the promises (potentially lost) it has given out.</li>
</ol>
<p>In the following, we discuss how we achieve these two conditions.</p>
<h3 id="catch-up"><a class="header" href="#catch-up">Catch-up</a></h3>
<p>To satisfy the above two conditions, a replica needs to perform <em>catch-up</em> to recover lost states. In other words, it will run Paxos rounds to find out those log entries whose values that have already been agreed. The question is how many log entries the local replica should catch-up before the above two conditions can be satisfied.</p>
<p>We found that it is sufficient to catch-up those log entries from position <em>begin</em> to position <em>end</em> where <em>begin</em> is the smallest position seen in a quorum of VOTING replicas and <em>end</em> is the largest position seen in a quorum of VOTING replicas.</p>
<p>Here is our correctness argument. For a log entry at position <em>e</em> where <em>e</em> is larger than <em>end</em>, obviously no value has been agreed on. Otherwise, we should find at least one VOTING replica in a quorum of replicas such that its end position is larger than <em>end</em>. For the same reason, a coordinator should not have collected enough promises for the log entry at position <em>e</em>. Therefore, it's safe for the recovering replica to respond requests for that log entry. For a log entry at position <em>b</em> where <em>b</em> is smaller than <em>begin</em>, it should have already been truncated and the truncation should have already been agreed. Therefore, allowing the recovering replica to respond requests for that position is also safe.</p>
<h3 id="auto-initialization"><a class="header" href="#auto-initialization">Auto initialization</a></h3>
<p>Since we don't allow an empty replica (a replica in EMPTY status) to respond to requests from coordinators, that raises a question for bootstrapping because initially, each replica is empty. The replicated log provides two choices here. One choice is to use a tool (<code>mesos-log</code>) to explicitly initialize the log on each replica by setting the replica's status to VOTING, but that requires an extra step when setting up an application.</p>
<p>The other choice is to do automatic initialization. Our idea is: we allow a replica in EMPTY status to become VOTING immediately if it finds all replicas are in EMPTY status. This is based on the assumption that the only time <em>all</em> replicas are in EMPTY status is during start-up. This may not be true if a catastrophic failure causes all replicas to lose their durable state, and that's exactly the reason we allow conservative users to disable auto-initialization.</p>
<p>To do auto-initialization, if we use a single-phase protocol and allow a replica to directly transit from EMPTY status to VOTING status, we may run into a state where we cannot make progress even if all replicas are in EMPTY status initially. For example, say the quorum size is 2. All replicas are in EMPTY status initially. One replica will first set its status to VOTING because if finds all replicas are in EMPTY status. After that, neither the VOTING replica nor the EMPTY replicas can make progress. To solve this problem, we use a two-phase protocol and introduce an intermediate transient status (STARTING) between EMPTY and VOTING status. A replica in EMPTY status can transit to STARTING status if it finds all replicas are in either EMPTY or STARTING status. A replica in STARTING status can transit to VOTING status if it finds all replicas are in either STARTING or VOTING status. In that way, in our previous example, all replicas will be in STARTING status before any of them can transit to VOTING status.</p>
<h2 id="non-leading-voting-replica-catch-up"><a class="header" href="#non-leading-voting-replica-catch-up">Non-leading VOTING replica catch-up</a></h2>
<p>Starting with Mesos 1.5.0 it is possible to perform eventually consistent reads from a non-leading VOTING log replica. This makes possible to do additional work on non-leading framework replicas, e.g. offload some reading from a leader to standbys reduce failover time by keeping in-memory storage represented by the replicated log &quot;hot&quot;.</p>
<p>To serve eventually consistent reads a replica needs to perform <em>catch-up</em> to recover the latest log state in a manner similar to how it is done during <a href="replicated-log-internals.html#catch-up">EMPTY replica recovery</a>. After that the recovered positions can be replayed without fear of seeing &quot;holes&quot;.</p>
<p>A truncation can take place during the non-leading replica catch-up. The replica may try to fill the truncated position if truncation happens after the replica has recovered <em>begin</em> and <em>end</em> positions, which may lead to producing inconsistent data during log replay. In order to protect against it we use a special tombstone flag that signals to the replica that the position was truncated and <em>begin</em> needs to be adjusted. The replica is not blocked from truncations during or after catching-up, which means that the user may need to retry the catch-up procedure if positions that were recovered became truncated during log replay.</p>
<h2 id="future-work"><a class="header" href="#future-work">Future work</a></h2>
<p>Currently, replicated log does not support dynamic quorum size change, also known as <em>reconfiguration</em>. Supporting reconfiguration would allow us more easily to add, move or swap hosts for replicas. We plan to support reconfiguration in the future.</p>
<h1 id="agent-recovery"><a class="header" href="#agent-recovery">Agent Recovery</a></h1>
<p>If the <code>mesos-agent</code> process on a host exits (perhaps due to a Mesos bug or
because the operator kills the process while <a href="upgrades.html">upgrading Mesos</a>),
any executors/tasks that were being managed by the <code>mesos-agent</code> process will
continue to run.</p>
<p>By default, all the executors/tasks that were being managed by the old
<code>mesos-agent</code> process are expected to gracefully exit on their own, and
will be shut down after the agent restarted if they did not.</p>
<p>However, if a framework enabled  <em>checkpointing</em> when it registered with the
master, any executors belonging to that framework can reconnect to the new
<code>mesos-agent</code> process and continue running uninterrupted. Hence, enabling
framework checkpointing allows tasks to tolerate Mesos agent upgrades and
unexpected <code>mesos-agent</code> crashes without experiencing any downtime.</p>
<p>Agent recovery works by having the agent checkpoint information about its own
state and about the tasks and executors it is managing to local disk, for
example the <code>SlaveInfo</code>, <code>FrameworkInfo</code> and <code>ExecutorInfo</code> messages or the
unacknowledged status updates of running tasks.</p>
<p>When the agent restarts, it will verify that its current configuration, set
from the environment variables and command-line flags, is compatible with the
checkpointed information and will refuse to restart if not.</p>
<p>A special case occurs when the agent detects that its host system was rebooted
since the last run of the agent: The agent will try to recover its previous ID
as usual, but if that fails it will actually erase the information of the
previous run and will register with the master as a new agent.</p>
<p>Note that executors and tasks that exited between agent shutdown and restart
are not automatically restarted during agent recovery.</p>
<h2 id="framework-configuration"><a class="header" href="#framework-configuration">Framework Configuration</a></h2>
<p>A framework can control whether its executors will be recovered by setting
the <code>checkpoint</code> flag in its <code>FrameworkInfo</code> when registering with the master.
Enabling this feature results in increased I/O overhead at each agent that runs
tasks launched by the framework. By default, frameworks do <strong>not</strong> checkpoint
their state.</p>
<h2 id="agent-configuration"><a class="header" href="#agent-configuration">Agent Configuration</a></h2>
<p>Four <a href="configuration/agent.html">configuration flags</a> control the recovery
behavior of a Mesos agent:</p>
<ul>
<li>
<p><code>strict</code>: Whether to do agent recovery in strict mode [Default: true].</p>
<ul>
<li>If strict=true, all recovery errors are considered fatal.</li>
<li>If strict=false, any errors (e.g., corruption in checkpointed data) during
recovery are ignored and as much state as possible is recovered.</li>
</ul>
</li>
<li>
<p><code>reconfiguration_policy</code>: Which kind of configuration changes are accepted
when trying to recover [Default: equal].</p>
<ul>
<li>If reconfiguration_policy=equal, no configuration changes are accepted.</li>
<li>If reconfiguration_policy=additive, the agent will allow the new
configuration to contain additional attributes, increased resourced or an
additional fault domain. For a more detailed description, see
<a href="https://gitbox.apache.org/repos/asf?p=mesos.git;a=blob;f=src/slave/compatibility.hpp;h=78b421a01abe5d2178c93832577577a7ba282b38;hb=HEAD#l37">this</a>.</li>
</ul>
</li>
<li>
<p><code>recover</code>: Whether to recover status updates and reconnect with old
executors [Default: reconnect]</p>
<ul>
<li>If recover=reconnect, reconnect with any old live executors, provided
the executor's framework enabled checkpointing.</li>
<li>If recover=cleanup, kill any old live executors and exit. Use this
option when doing an incompatible agent or executor upgrade!
<strong>NOTE:</strong> If no checkpointing information exists, no recovery is performed
and the agent registers with the master as a new agent.</li>
</ul>
</li>
<li>
<p><code>recovery_timeout</code>: Amount of time allotted for the agent to
recover [Default: 15 mins].</p>
<ul>
<li>If the agent takes longer than <code>recovery_timeout</code> to recover, any
executors that are waiting to reconnect to the agent will self-terminate.
<strong>NOTE:</strong> If none of the frameworks have enabled checkpointing, the
executors and tasks running at an agent die when the agent dies and are
not recovered.</li>
</ul>
</li>
</ul>
<p>A restarted agent should reregister with master within a timeout (75 seconds
by default: see the <code>--max_agent_ping_timeouts</code> and <code>--agent_ping_timeout</code>
<a href="configuration.html">configuration flags</a>). If the agent takes longer than this
timeout to reregister, the master shuts down the agent, which in turn will
shutdown any live executors/tasks.</p>
<p>Therefore, it is highly recommended to automate the process of restarting an
agent, e.g. using a process supervisor such as <a href="http://mmonit.com/monit/">monit</a>
or <code>systemd</code>.</p>
<h2 id="known-issues-with-systemd-and-process-lifetime"><a class="header" href="#known-issues-with-systemd-and-process-lifetime">Known issues with <code>systemd</code> and process lifetime</a></h2>
<p>There is a known issue when using <code>systemd</code> to launch the <code>mesos-agent</code>. A
description of the problem can be found in <a href="https://issues.apache.org/jira/browse/MESOS-3425">MESOS-3425</a>
and all relevant work can be tracked in the epic <a href="https://issues.apache.org/jira/browse/MESOS-3007">MESOS-3007</a>.</p>
<p>This problem was fixed in Mesos <code>0.25.0</code> for the mesos containerizer when
cgroups isolation is enabled. Further fixes for the posix isolators and docker
containerizer are available in <code>0.25.1</code>, <code>0.26.1</code>, <code>0.27.1</code>, and <code>0.28.0</code>.</p>
<p>It is recommended that you use the default <a href="http://www.freedesktop.org/software/systemd/man/systemd.kill.html">KillMode</a>
for systemd processes, which is <code>control-group</code>, which kills all child processes
when the agent stops. This ensures that &quot;side-car&quot; processes such as the
<code>fetcher</code> and <code>perf</code> are terminated alongside the agent.
The systemd patches for Mesos explicitly move executors and their children into
a separate systemd slice, dissociating their lifetime from the agent. This
ensures the executors survive agent restarts.</p>
<p>The following excerpt of a <code>systemd</code> unit configuration file shows how to set
the flag explicitly:</p>
<pre><code>[Service]
ExecStart=/usr/bin/mesos-agent
KillMode=control-cgroup
</code></pre>
<h1 id="framework-rate-limiting"><a class="header" href="#framework-rate-limiting">Framework Rate Limiting</a></h1>
<p>Framework rate limiting is a feature introduced in Mesos 0.20.0.</p>
<h2 id="what-is-framework-rate-limiting"><a class="header" href="#what-is-framework-rate-limiting">What is Framework Rate Limiting</a></h2>
<p>In a multi-framework environment, this feature aims to protect the throughput of high-SLA (e.g., production, service) frameworks by having the master throttle messages from other (e.g., development, batch) frameworks.</p>
<p>To throttle messages from a framework, the Mesos cluster operator sets a <code>qps</code> (queries per seconds) value for each framework identified by its principal (You can also throttle a group of frameworks together but we'll assume individual frameworks in this doc unless otherwise stated; see the <code>RateLimits</code> <a href="https://github.com/apache/mesos/blob/master/include/mesos/mesos.proto">Protobuf definition</a> and the configuration notes below). The master then promises not to process messages from that framework at a rate above <code>qps</code>. The outstanding messages are stored in memory on the master.</p>
<h2 id="rate-limits-configuration"><a class="header" href="#rate-limits-configuration">Rate Limits Configuration</a></h2>
<p>The following is a sample config file (in JSON format) which could be specified with the <code>--rate_limits</code> master flag.</p>
<pre><code>{
  &quot;limits&quot;: [
    {
      &quot;principal&quot;: &quot;foo&quot;,
      &quot;qps&quot;: 55.5
      &quot;capacity&quot;: 100000
    },
    {
      &quot;principal&quot;: &quot;bar&quot;,
      &quot;qps&quot;: 300
    },
    {
      &quot;principal&quot;: &quot;baz&quot;,
    }
  ],
  &quot;aggregate_default_qps&quot;: 333,
  &quot;aggregate_default_capacity&quot;: 1000000
}
</code></pre>
<p>In this example, framework <code>foo</code> is throttled at the configured <code>qps</code> and <code>capacity</code>, framework <code>bar</code> is given unlimited capacity and framework <code>baz</code> is not throttled at all. If there is a fourth framework <code>qux</code> or a framework without a principal connected to the master, it is throttled by the rules <code>aggregate_default_qps</code> and <code>aggregate_default_capacity</code>.</p>
<h3 id="configuration-notes"><a class="header" href="#configuration-notes">Configuration Notes</a></h3>
<p>Below are the fields in the JSON configuration.</p>
<ul>
<li><strong>principal</strong>: (Required) uniquely identifies the entity being throttled or given unlimited rate explicitly.
<ul>
<li>It should match the framework's <code>FrameworkInfo.principal</code> (See <a href="https://github.com/apache/mesos/blob/master/include/mesos/mesos.proto">definition</a>).</li>
<li>You can have multiple frameworks use the same principal (e.g., some Mesos frameworks launch a new framework instance for each job), in which case the combined traffic from all frameworks using the same principal are throttled at the specified QPS.</li>
</ul>
</li>
<li><strong>qps</strong>: (Optional) queries per second, i.e., the rate.
<ul>
<li>Once set, the master guarantees that it does not process messages from this principal higher than this rate. However the master could be slower than this rate, especially if the specified rate is too high.</li>
<li>To explicitly give a framework unlimited rate (i.e., not throttling it), add an entry to <code>limits</code> without the qps.</li>
</ul>
</li>
<li><strong>capacity</strong>: (Optional) The number of <em>outstanding</em> messages frameworks of this principal can put on the master. If not specified, this principal is given unlimited capacity. Note that it is possible the queued messages use too much memory and cause the master to OOM if the capacity is set too high or not set.
<ul>
<li>NOTE: If <code>qps</code> is not specified, <code>capacity</code> is ignored.</li>
</ul>
</li>
<li>Use <strong>aggregate_default_qps</strong> and <strong>aggregate_default_capacity</strong> to safeguard the master from unspecified frameworks. All the frameworks not specified in <code>limits</code> get this default rate and capacity.
<ul>
<li>The rate and capacity are aggregate values for all of them, i.e., their combined traffic is throttled together.</li>
<li>Same as above, if <code>aggregate_default_qps</code> is not specified, <code>aggregate_default_capacity</code> is ignored.</li>
<li>If these fields are not present, the unspecified frameworks are not throttled.
This is an implicit way of giving frameworks unlimited rate compared to the explicit way above (using an entry in <code>limits</code> with only the principal).
We recommend using the explicit option especially when the master does not require authentication to prevent unexpected frameworks from overwhelming the master.</li>
</ul>
</li>
</ul>
<h2 id="using-framework-rate-limiting"><a class="header" href="#using-framework-rate-limiting">Using Framework Rate Limiting</a></h2>
<h3 id="monitoring-framework-traffic"><a class="header" href="#monitoring-framework-traffic">Monitoring Framework Traffic</a></h3>
<p>While a framework is registered with the master, the master exposes counters for all messages received and processed from that framework at its metrics endpoint: <code>http://&lt;master&gt;/metrics/snapshot</code>. For instance, framework <code>foo</code> has two message counters <code>frameworks/foo/messages_received</code> and <code>frameworks/foo/messages_processed</code>. Without framework rate limiting the two numbers should differ by little or none (because messages are processed ASAP) but when a framework is being throttled the difference indicates the outstanding messages as a result of the throttling.</p>
<p>By continuously monitoring the counters, you can derive the rate messages arrive and how fast the message queue length for the framework is growing (if it is throttled). This should depict the characteristics of the framework in terms of network traffic.</p>
<h2 id="configuring-rate-limits"><a class="header" href="#configuring-rate-limits">Configuring Rate Limits</a></h2>
<p>Since the goal for framework rate limiting is to prevent low-SLA frameworks from using <strong>too much</strong> resources and not to model their traffic and behavior as precisely as possible, you can start by using large <code>qps</code> values to throttle them. The fact that they are throttled (regardless of the configured <code>qps</code>) is already effective in giving messages from high-SLA frameworks higher priority because they are processed ASAP.</p>
<p>To calculate how much <code>capacity</code> the master can handle, you need to know the memory limit for the master process, the amount of memory it typically uses to serve similar workload without rate limiting (e.g., use <code>ps -o rss $MASTER_PID</code>) and average sizes of the framework messages (queued messages are stored as <a href="https://github.com/apache/mesos/blob/master/3rdparty/libprocess/include/process/message.hpp">serialized Protocol Buffers with a few additional fields</a>) and you should sum up all capacity values in the config.
However since this kind of calculation is imprecise, you should start with small values that tolerate reasonable temporary framework burstiness but far from the memory limit to leave enough headroom for the master and frameworks that don't have limited capacity.</p>
<h2 id="handling-capacity-exceeded-error"><a class="header" href="#handling-capacity-exceeded-error">Handling &quot;Capacity Exceeded&quot; Error</a></h2>
<p>When a framework <strong>exceeds the capacity</strong>, a FrameworkErrorMessage is sent back to the framework which will <a href="https://github.com/apache/mesos/blob/master/src/sched/sched.cpp">abort the scheduler driver and invoke the error() callback</a>. It doesn't kill any tasks or the scheduler itself. The framework developer can choose to restart or failover the scheduler instance to remedy the consequences of dropped messages (unless your framework doesn't assume all messages sent to the master are processed).</p>
<p>After version 0.20.0 we are going to iterate on this feature by having the master send an early alert when the message queue for this framework <strong>starts to build up</strong> (<a href="https://issues.apache.org/jira/browse/MESOS-1664">MESOS-1664</a>, consider it a &quot;soft limit&quot;). The scheduler can react by throttling itself (to avoid the error message) or ignoring this alert if it's a temporary burst by design.</p>
<p>Before the early alerting is implemented we <strong>don't recommend using the rate limiting feature to throttle production frameworks</strong> for now unless you are sure about the consequences of the error message. Of course it's OK to use it to protect production frameworks by throttling other frameworks and it doesn't have any effect on the master if it's not explicitly enabled.</p>
<h1 id="performing-node-maintenance-in-a-mesos-cluster"><a class="header" href="#performing-node-maintenance-in-a-mesos-cluster">Performing Node Maintenance in a Mesos Cluster</a></h1>
<p>Operators regularly need to perform maintenance tasks on machines that comprise
a Mesos cluster.  Most Mesos upgrades can be done without affecting running
tasks, but there are situations where maintenance may affect running tasks.
For example:</p>
<ul>
<li>Hardware repair</li>
<li>Kernel upgrades</li>
<li>Agent upgrades (e.g., adjusting agent attributes or resources)</li>
</ul>
<p>Before performing maintenance on an agent node in a Mesos cluster, it is
typically desirable to gracefully migrate tasks away from the node beforehand in
order to minimize service disruption when the machine is taken down. Mesos
provides several ways to accomplish this migration:</p>
<ul>
<li>Automatic agent draining, which does not explicitly require cooperation from
schedulers</li>
<li>Manual node draining, which allows operators to exercise precise control over
the task draining process</li>
<li>Maintenance primitives, which permit complex coordination but do require that
schedulers react to the maintenance-related messages that they receive</li>
</ul>
<h1 id="automatic-node-draining"><a class="header" href="#automatic-node-draining">Automatic Node Draining</a></h1>
<p>Node draining was added to provide a simple method for operators to drain tasks
from nodes on which they plan to perform maintenance, without requiring that
schedulers implement support for any maintenance-specific messages.</p>
<p>Initiating draining will cause all tasks on the target agent node to receive a
kill event immediately, assuming the agent is currently reachable. If the agent
is unreachable, initiation of the kill event will be delayed until the agent is
reachable by the master again. When the tasks receive a kill event, a SIGTERM
signal will be sent to the task to begin the killing process. Depending on the
particular task's behavior, this signal may be sufficient to terminate it. Some
tasks may use this signal to begin the process of graceful termination, which
may take some time. After some delay, a SIGKILL signal will be sent to the task,
which forcefully terminates the task if it is still running. The delay between
the SIGTERM and SIGKILL signals is determined by the length of the task's kill
grace period. If no grace period is set for the task, a default value of several
seconds will be used.</p>
<h2 id="initiating-draining-on-a-node"><a class="header" href="#initiating-draining-on-a-node">Initiating Draining on a Node</a></h2>
<p>To begin draining an agent, issue the operator API <a href="operator-http-api.html#drain_agent"><code>DRAIN_AGENT</code>
call</a> to the master:</p>
<pre><code>$ curl -X POST -d '{&quot;type&quot;: &quot;DRAIN_AGENT&quot;, &quot;drain_agent&quot;: {&quot;agent_id&quot;: {&quot;value&quot;: &quot;&lt;mesos-agent-id&gt;&quot;}}}' masterhost:5050/api/v1
</code></pre>
<p>This will immediately begin the process of killing all tasks on the agent. Once
draining has begun, it cannot be cancelled. To monitor the progress of the
draining process, you can inspect the state of the agent via the master operator
API <a href="operator-http-api.html#get_state"><code>GET_STATE</code></a> or
<a href="operator-http-api.html#get_agents"><code>GET_AGENTS</code></a> calls:</p>
<pre><code>$ curl -X POST -d '{&quot;type&quot;: &quot;GET_AGENTS&quot;}' masterhost:5050/api/v1
</code></pre>
<p>Locate the relevant agent and inspect its <code>drain_info.state</code> field. While
draining, the state will be <code>DRAINING</code>. When all tasks on the agent have
terminated, all their terminal status updates have been acknowledged by the
schedulers, and all offer operations on the agent have finished, draining is
complete and the agent's drain state will transition to <code>DRAINED</code>. At this
point, the node may be taken down for maintenance.</p>
<h2 id="options-for-automatic-node-draining"><a class="header" href="#options-for-automatic-node-draining">Options for Automatic Node Draining</a></h2>
<p>You may set an upper bound on the kill grace period of draining tasks by
specifying the <code>max_grace_period</code> option when draining:</p>
<pre><code>$ curl -X POST -d '{&quot;type&quot;: &quot;DRAIN_AGENT&quot;, &quot;drain_agent&quot;: {&quot;agent_id&quot;: {&quot;value&quot;: &quot;&lt;mesos-agent-id&gt;&quot;}, &quot;max_grace_period&quot;: &quot;10mins&quot;}}' masterhost:5050/api/v1
</code></pre>
<p>In cases where you know that the node being drained will not return after
draining is complete, and you would like it to be automatically permanently
removed from the cluster, you may specify the <code>mark_gone</code> option:</p>
<pre><code>$ curl -X POST -d '{&quot;type&quot;: &quot;DRAIN_AGENT&quot;, &quot;drain_agent&quot;: {&quot;agent_id&quot;: {&quot;value&quot;: &quot;&lt;mesos-agent-id&gt;&quot;}, &quot;mark_gone&quot;: true}}' masterhost:5050/api/v1
</code></pre>
<p>This can be useful, for example, in the case of autoscaled cloud instances,
where an instance is being scaled down and will never return. This is equivalent
to issuing the <a href="operator-http-api.html#mark_agent_gone"><code>MARK_AGENT_GONE</code></a> call on
the agent immediately after it finishes draining. WARNING: draining with the
<code>mark_gone</code> option is irreversible, and results in the loss of all local
persistent data on the agent node. Use this option with caution!</p>
<h2 id="reactivating-a-node-after-maintenance"><a class="header" href="#reactivating-a-node-after-maintenance">Reactivating a Node After Maintenance</a></h2>
<p>Once maintenance on an agent is complete, it must be reactivated so that it can
reregister with the master and rejoin the cluster. You may use the master
operator API <a href="operator-http-api.html#reactivate_agent"><code>REACTIVATE_AGENT</code></a> call to
accomplish this:</p>
<pre><code>$ curl -X POST -d '{&quot;type&quot;: &quot;REACTIVATE_AGENT&quot;, &quot;reactivate_agent&quot;: {&quot;agent_id&quot;: {&quot;value&quot;: &quot;&lt;mesos-agent-id&gt;&quot;}}}' masterhost:5050/api/v1
</code></pre>
<h1 id="manual-node-draining"><a class="header" href="#manual-node-draining">Manual Node Draining</a></h1>
<p>If you require greater control over the draining process, you may be able to
drain the agent manually using both the Mesos operator API as well as APIs
exposed by the schedulers running tasks on the agent.</p>
<h2 id="deactivating-an-agent"><a class="header" href="#deactivating-an-agent">Deactivating an Agent</a></h2>
<p>The first step in the manual draining process is agent deactivation, which
prevents new tasks from launching on the target agent:</p>
<pre><code>$ curl -X POST -d '{&quot;type&quot;: &quot;DEACTIVATE_AGENT&quot;, &quot;deactivate_agent&quot;: {&quot;agent_id&quot;: {&quot;value&quot;: &quot;&lt;mesos-agent-id&gt;&quot;}}}' masterhost:5050/api/v1
</code></pre>
<p>If you receive a <code>200 OK</code> response, then the agent has been deactivated. You can
confirm the deactivation state of any agent by inspecting its <code>deactivated</code>
field in the response of the master operator API
<a href="operator-http-api.html#get_state"><code>GET_STATE</code></a> or
<a href="operator-http-api.html#get_agents"><code>GET_AGENTS</code></a> calls. Once the agent is
deactivated, you can use the APIs exposed by the schedulers responsible for the
tasks running on the agent to kill those tasks manually. To verify that all
tasks on the agent have terminated and their terminal status updates have been
acknowledged by the schedulers, ensure that the <code>pending_tasks</code>, <code>queued_tasks</code>,
and <code>launched_tasks</code> fields in the response to the
<a href="operator-http-api.html#get_tasks-1"><code>GET_TASKS</code></a> agent operator API call are
empty:</p>
<pre><code>$ curl -X POST -d '{&quot;type&quot;: &quot;GET_TASKS&quot;}' agenthost:5051/api/v1
</code></pre>
<p>If you are making use of volumes backed by network storage on the target agent,
it's possible that there may be a long-running offer operation on the agent
which has not yet finished. To check if this is the case, issue the agent
operator API <a href="operator-http-api.html#get_operations-1"><code>GET_OPERATIONS</code></a> call to
the agent:</p>
<pre><code>$ curl -X POST -d '{&quot;type&quot;: &quot;GET_OPERATIONS&quot;}' agenthost:5051/api/v1
</code></pre>
<p>If any operations have a <code>latest_status</code> with a state of <code>OPERATION_PENDING</code>,
you should wait for them to finish before taking down the node. Unfortunately,
it is not possible to cancel or forcefully terminate such storage operations. If
such an operation becomes stuck in the pending state, you should inspect the
relevant storage backend for any issues.</p>
<p>Once all tasks on the agent have terminated and all offer operations are
finished, the node may be taken down for maintenance. Once maintenance is
complete, the procedure for reactivating the node is the same as that detailed
in the section on automatic node draining.</p>
<h1 id="maintenance-primitives"><a class="header" href="#maintenance-primitives">Maintenance Primitives</a></h1>
<p>Frameworks require visibility into any actions that disrupt cluster operation
in order to meet Service Level Agreements or to ensure uninterrupted services
for their end users.  Therefore, to reconcile the requirements of frameworks
and operators, frameworks must be aware of planned maintenance events and
operators must be aware of frameworks' ability to adapt to maintenance.
Maintenance primitives add a layer to facilitate communication between the
frameworks and operator.</p>
<h2 id="terminology"><a class="header" href="#terminology">Terminology</a></h2>
<p>For the purpose of this section, an &quot;Operator&quot; is a person, tool, or script
that manages a Mesos cluster.</p>
<p>Maintenance primitives add several new concepts to Mesos. Those concepts are:</p>
<ul>
<li><strong>Maintenance</strong>: An operation that makes resources on a machine unavailable,
either temporarily or permanently.</li>
<li><strong>Maintenance window</strong>: A set of machines and an associated time interval during
which some maintenance is planned on those machines.</li>
<li><strong>Maintenance schedule</strong>: A list of maintenance windows.
A single machine may only appear in a schedule once.</li>
<li><strong>Unavailability</strong>: An operator-specified interval, defined by a start time
and duration, during which an associated machine may become unavailable.
In general, no assumptions should be made about the availability of the
machine (or resources) after the unavailability.</li>
<li><strong>Drain</strong>: An interval between the scheduling of maintenance and when the
machine(s) become unavailable.  Offers sent with resources from draining
machines will contain unavailability information.  Frameworks running on
draining machines will receive inverse offers (see next).  Frameworks
utilizing resources on affected machines are expected either to take
preemptive steps to prepare for the unavailability; or to communicate the
framework's inability to conform to the maintenance schedule.</li>
<li><strong>Inverse offer</strong>: A communication mechanism for the master to ask for
resources back from a framework.  This notifies frameworks about any
unavailability and gives frameworks a mechanism to respond about their
ability to comply.  Inverse offers are similar to offers in that they
can be accepted, declined, re-offered, and rescinded.</li>
</ul>
<p><strong>Note</strong>: Unavailability and inverse offers are not specific to maintenance.
The same concepts can be used for non-maintenance goals, such as reallocating
resources or resource preemption.</p>
<h2 id="how-does-it-work"><a class="header" href="#how-does-it-work">How does it work?</a></h2>
<p>Maintenance primitives were introduced in Mesos 0.25.0.  Several machine
maintenance modes were also introduced.  Those modes are illustrated below.</p>
<p><img src="images/maintenance-primitives-modes.png" alt="Maintenance mode transitions" /></p>
<p>All mode transitions must be initiated by the operator.  Mesos will not
change the mode of any machine, regardless of the estimate provided in
the maintenance schedule.</p>
<h3 id="scheduling-maintenance"><a class="header" href="#scheduling-maintenance">Scheduling maintenance</a></h3>
<p>A machine is transitioned from Up mode to Draining mode as soon as it is
scheduled for maintenance.  To transition a machine into Draining mode, an
operator constructs a maintenance schedule as a JSON document and posts it to
the <a href="endpoints/master/maintenance/schedule.html">/maintenance/schedule</a> HTTP
endpoint on the Mesos master. Each Mesos cluster has a single maintenance
schedule; posting a new schedule replaces the previous schedule, if any.</p>
<p>See the definition of a <a href="https://github.com/apache/mesos/blob/016b02d7ed5a65bcad9261a133c8237c2df66e6e/include/mesos/maintenance/maintenance.proto#L48-L67">maintenance::Schedule</a>
and of <a href="https://github.com/apache/mesos/blob/016b02d7ed5a65bcad9261a133c8237c2df66e6e/include/mesos/v1/mesos.proto#L140-L154">Unavailability</a>.</p>
<p>In a production environment, the schedule should be constructed to ensure that
enough agents are operational at any given point in time to ensure
uninterrupted service by the frameworks.</p>
<p>For example, in a cluster of three machines, the operator might schedule two
machines for one hour of maintenance, followed by another hour for the last
machine.  The timestamps for unavailability are expressed in nanoseconds since
the Unix epoch (note that making reliable use of maintenance primitives requires
that the system clocks of all machines in the cluster are roughly synchronized).</p>
<p>The schedule might look like:</p>
<pre><code>{
  &quot;windows&quot; : [
    {
      &quot;machine_ids&quot; : [
        { &quot;hostname&quot; : &quot;machine1&quot;, &quot;ip&quot; : &quot;10.0.0.1&quot; },
        { &quot;hostname&quot; : &quot;machine2&quot;, &quot;ip&quot; : &quot;10.0.0.2&quot; }
      ],
      &quot;unavailability&quot; : {
        &quot;start&quot; : { &quot;nanoseconds&quot; : 1443830400000000000 },
        &quot;duration&quot; : { &quot;nanoseconds&quot; : 3600000000000 }
      }
    }, {
      &quot;machine_ids&quot; : [
        { &quot;hostname&quot; : &quot;machine3&quot;, &quot;ip&quot; : &quot;10.0.0.3&quot; }
      ],
      &quot;unavailability&quot; : {
        &quot;start&quot; : { &quot;nanoseconds&quot; : 1443834000000000000 },
        &quot;duration&quot; : { &quot;nanoseconds&quot; : 3600000000000 }
      }
    }
  ]
}
</code></pre>
<p>The operator can then post the schedule to the master's
<a href="endpoints/master/maintenance/schedule.html">/maintenance/schedule</a> endpoint:</p>
<pre><code>curl http://localhost:5050/maintenance/schedule \
  -H &quot;Content-type: application/json&quot; \
  -X POST \
  -d @schedule.json
</code></pre>
<p>The machines in a maintenance schedule do not need to be registered with the
Mesos master at the time when the schedule is set.  The operator may add a
machine to the maintenance schedule prior to launching an agent on the machine.
For example, this can be useful to prevent a faulty machine from launching an
agent on boot.</p>
<p><strong>Note</strong>: Each machine in the maintenance schedule should have as
complete information as possible.  In order for Mesos to recognize an agent
as coming from a particular machine, both the <code>hostname</code> and <code>ip</code> fields must
match.  Any omitted data defaults to the empty string <code>&quot;&quot;</code>.  If there are
multiple hostnames or IPs for a machine, the machine's fields need to match
what the agent announces to the master.  If there is any ambiguity in a
machine's configuration, the operator should use the <code>--hostname</code> and <code>--ip</code>
options when starting agents.</p>
<p>The master checks that a maintenance schedule has the following properties:</p>
<ul>
<li>Each maintenance window in the schedule must have at least one machine
and a specified unavailability interval.</li>
<li>Each machine must only appear in the schedule once.</li>
<li>Each machine must have at least a hostname or IP included.
The hostname is not case-sensitive.</li>
<li>All machines that are in Down mode must be present in the schedule.
This is required because this endpoint does not handle the transition
from Down mode to Up mode.</li>
</ul>
<p>If any of these properties are not met, the maintenance schedule is rejected
with a corresponding error message and the master's state is not changed.</p>
<p>To update the maintenance schedule, the operator should first read the current
schedule, make any necessary changes, and then post the modified schedule. The
current maintenance schedule can be obtained by sending a GET request to the
master's <code>/maintenance/schedule</code> endpoint.</p>
<p>To cancel the maintenance schedule, the operator should post an empty schedule.</p>
<h3 id="draining-mode"><a class="header" href="#draining-mode">Draining mode</a></h3>
<p>As soon as a schedule is posted to the Mesos master, the following things occur:</p>
<ul>
<li>The schedule is stored in the <a href="replicated-log-internals.html">replicated log</a>.
This means the schedule is persisted in case of master failover.</li>
<li>All machines in the schedule are immediately transitioned into Draining
mode.  The mode of each machine is also persisted in the replicated log.</li>
<li>All frameworks using resources on affected agents are immediately
notified.  Existing offers from the affected agents are rescinded
and re-sent with additional unavailability data.  All frameworks using
resources from the affected agents are given inverse offers.</li>
<li>New offers from the affected agents will also include
the additional unavailability data.</li>
</ul>
<p>Frameworks should use this additional information to schedule tasks in a
maintenance-aware fashion. Exactly how to do this depends on the design
requirements of each scheduler, but tasks should typically be scheduled in a way
that maximizes utilization but that also attempts to vacate machines before that
machine's advertised unavailability period occurs. A scheduler might choose to
place long-running tasks on machines with no unavailability, or failing that, on
machines whose unavailability is the furthest away.</p>
<p>How a framework responds to an inverse offer indicates its ability to conform to
the maintenance schedule. Accepting an inverse offer communicates that the
framework is okay with the current maintenance schedule, given the current state
of the framework's resources.  The master and operator should interpret
acceptance as a best-effort promise by the framework to free all the resources
contained in the inverse offer before the start of the unavailability
interval. Declining an inverse offer is an advisory notice to the operator that
the framework is unable or unlikely to meet to the maintenance schedule.</p>
<p>For example:</p>
<ul>
<li>A data store may choose to start a new replica if one of its agents is
scheduled for maintenance. The data store should accept an inverse offer if it
can reasonably copy the data on the machine to a new host before the
unavailability interval described in the inverse offer begins. Otherwise, the
data store should decline the offer.</li>
<li>A stateful task on an agent with an impending unavailability may be migrated
to another available agent.  If the framework has sufficient resources to do
so, it would accept any inverse offers.  Otherwise, it would decline them.</li>
</ul>
<p>A framework can use a filter to control when it wants to be contacted again
with an inverse offer.  This is useful since future circumstances may change
the viability of the maintenance schedule.  The filter for inverse offers is
identical to the existing mechanism for re-offering offers to frameworks.</p>
<p><strong>Note</strong>: Accepting or declining an inverse offer does not result in
immediate changes in the maintenance schedule or in the way Mesos acts.
Inverse offers only represent extra information that frameworks may
find useful. In the same manner, rejecting or accepting an inverse offer is a
hint for an operator. The operator may or may not choose to take that hint
into account.</p>
<h3 id="starting-maintenance"><a class="header" href="#starting-maintenance">Starting maintenance</a></h3>
<p>The operator starts maintenance by posting a list of machines to the
<a href="endpoints/master/machine/down.html">/machine/down</a> HTTP endpoint. The list of
machines is specified in JSON format; each element of the list is a
<a href="https://github.com/apache/mesos/blob/016b02d7ed5a65bcad9261a133c8237c2df66e6e/include/mesos/v1/mesos.proto#L157-L167">MachineID</a>.</p>
<p>For example, to start maintenance on two machines:</p>
<pre><code>[
  { &quot;hostname&quot; : &quot;machine1&quot;, &quot;ip&quot; : &quot;10.0.0.1&quot; },
  { &quot;hostname&quot; : &quot;machine2&quot;, &quot;ip&quot; : &quot;10.0.0.2&quot; }
]
</code></pre>
<pre><code>curl http://localhost:5050/machine/down \
  -H &quot;Content-type: application/json&quot; \
  -X POST \
  -d @machines.json
</code></pre>
<p>The master checks that a list of machines has the following properties:</p>
<ul>
<li>The list of machines must not be empty.</li>
<li>Each machine must only appear once.</li>
<li>Each machine must have at least a hostname or IP included.
The hostname is not case-sensitive.</li>
<li>If a machine's IP is included, it must be correctly formed.</li>
<li>All listed machines must be present in the schedule.</li>
</ul>
<p>If any of these properties are not met, the operation is rejected with a
corresponding error message and the master's state is not changed.</p>
<p>The operator can start maintenance on any machine that is scheduled for
maintenance. Machines that are not scheduled for maintenance cannot be directly
transitioned from Up mode into Down mode.  However, the operator may schedule a
machine for maintenance with a timestamp equal to the current time or in the
past, and then immediately start maintenance on that machine.</p>
<p>This endpoint can be used to start maintenance on machines that are not
currently registered with the Mesos master. This can be useful if a machine has
failed and the operator intends to remove it from the cluster; starting
maintenance on the machine prevents the machine from being accidentally rebooted
and rejoining the Mesos cluster.</p>
<p>The operator must explicitly transition a machine from Draining to Down
mode. That is, Mesos will keep a machine in Draining mode even if the
unavailability window arrives or passes.  This means that the operation of the
machine is not disrupted in any way and offers (with unavailability information)
are still sent for this machine.</p>
<p>When maintenance is triggered by the operator, all agents on the machine are
told to shutdown.  These agents are removed from the master, which means that a
<code>TASK_LOST</code> status update will be sent for every task running on each of those
agents. The scheduler driver's <code>slaveLost</code> callback will also be invoked for
each of the removed agents. Any agents on machines in maintenance are also
prevented from reregistering with the master in the future (until maintenance
is completed and the machine is brought back up).</p>
<h3 id="completing-maintenance"><a class="header" href="#completing-maintenance">Completing maintenance</a></h3>
<p>When maintenance is complete or if maintenance needs to be cancelled,
the operator can stop maintenance.  The process is very similar
to starting maintenance (same validation criteria as the previous section).
The operator posts a list of machines to the master's <a href="endpoints/master/machine/up.html">/machine/up</a> endpoint:</p>
<pre><code>[
  { &quot;hostname&quot; : &quot;machine1&quot;, &quot;ip&quot; : &quot;10.0.0.1&quot; },
  { &quot;hostname&quot; : &quot;machine2&quot;, &quot;ip&quot; : &quot;10.0.0.2&quot; }
]
</code></pre>
<pre><code>curl http://localhost:5050/machine/up \
  -H &quot;Content-type: application/json&quot; \
  -X POST \
  -d @machines.json
</code></pre>
<p><strong>Note</strong>: The duration of the maintenance window, as indicated by the
&quot;unavailability&quot; field in the maintenance schedule, is a best-effort guess made
by the operator.  Stopping maintenance before the end of the unavailability
interval is allowed, as is stopping maintenance after the end of the
unavailability interval.  Machines are never automatically transitioned out of
maintenance.</p>
<p>Frameworks are informed about the completion or cancellation of maintenance when
offers from that machine start being sent.  There is no explicit mechanism for
notifying frameworks when maintenance has finished.  After maintenance has
finished, new offers are no longer tagged with unavailability and inverse offers
are no longer sent.  Also, agents running on the machine will be allowed to
register with the Mesos master.</p>
<h3 id="viewing-maintenance-status"><a class="header" href="#viewing-maintenance-status">Viewing maintenance status</a></h3>
<p>The current maintenance status (Up, Draining, or Down) of each machine in the
cluster can be viewed by accessing the master's
<a href="endpoints/master/maintenance/status.html">/maintenance/status</a> HTTP endpoint. For
each machine that is Draining, this endpoint also includes the frameworks' responses to
inverse offers for resources on that machine. For more information, see the
format of the <a href="https://github.com/apache/mesos/blob/fa36917dd142f66924c5f7ed689b87d5ceabbf79/include/mesos/maintenance/maintenance.proto#L73-L84">ClusterStatus message</a>.</p>
<blockquote>
<p>NOTE: The format of the data returned by this endpoint may change in a
future release of Mesos.</p>
</blockquote>
<hr />
<h2>title: Apache Mesos - Upgrading Mesos
layout: documentation</h2>
<h1 id="upgrading-mesos"><a class="header" href="#upgrading-mesos">Upgrading Mesos</a></h1>
<p>This document serves as a guide for users who wish to upgrade an existing Mesos cluster. Some versions require particular upgrade techniques when upgrading a running cluster. Some upgrades will have incompatible changes.</p>
<h2 id="overview"><a class="header" href="#overview">Overview</a></h2>
<p>This section provides an overview of the changes for each version (in particular when upgrading from the next lower version). For more details please check the respective sections below.</p>
<p>We categorize the changes as follows:</p>
<pre><code>A New feature/behavior
C Changed feature/behavior
D Deprecated feature/behavior
R Removed feature/behavior
</code></pre>
<table class="table table-bordered" style="table-layout: fixed;">
  <thead>
    <tr>
      <th width="10%">
        Version
      </th>
      <th width="18%">
        Mesos Core
      </th>
      <th width="18%">
        Flags
      </th>
      <th width="18%">
        Framework API
      </th>
      <th width="18%">
        Module API
      </th>
      <th width="18%">
        Endpoints
      </th>
    </tr>
  </thead>
<tr>
  <td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Version-->
  1.10.x
  </td>
<td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Mesos Core-->
    <ul style="padding-left:10px;">
      <li>D <a href="upgrades.html#1-10-x-ssl-env-var-rename">Renamed LIBPROCESS_SSL_VERIFY_CERT and LIBPROCESS_SSL_REQUIRE_CERT environment variables.</a></li>
      <li>D <a href="upgrades.html#1-10-x-limits-cfs-quota">CPU limits affect the function of the agent's `cgroups_enable_cfs` flag.</a></li>
    </ul>
 </td>
<td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Flags-->
    <ul style="padding-left:10px;">
      <li>C <a href="upgrades.html#1-10-x-agent-features">agent_features</a></li>
    </ul>
  </td>
<td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Framework API-->
    <ul style="padding-left:10px;">
    </ul>
  </td>
<td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Module API-->
    <ul style="padding-left:10px;">
      <li>C <a href="upgrades.html#1-10-x-synchronous-authorization">Authorizers must support synchronous authorization.</a></li>
      <li>AC <a href="upgrades.html#1-10-x-allocator-module-changes">Resource consumption is exposed to allocators.</a></li>
    </ul>
  </td>
<td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Endpoints-->
    <ul style="padding-left:10px;">
      <li>D <a href="upgrades.html#1-10-x-tasks-pending-authoirization-deprecated">v1 GetTasks pending_tasks</a></li>
    </ul>
  </td>
</tr>
<tr>
  <td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Version-->
  1.9.x
  </td>
<td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Mesos Core-->
    <ul style="padding-left:10px;">
      <li>A <a href="upgrades.html#1-9-x-quota-guarantees">Quota Limits</a></li>
      <li>A <a href="upgrades.html#1-9-x-linux-nnp-isolator">Linux NNP isolator</a></li>
      <li>A <a href="upgrades.html#1-9-x-hostname-validation-scheme">hostname_validation_scheme</a></li>
      <li>C <a href="upgrades.html#1-9-x-client-certificate-verification">TLS certificate verification behaviour</a></li>
      <li>C <a href="upgrades.html#1-9-x-configurable-ipc">Configurable IPC namespace and /dev/shm</a></li>
      <li>A <a href="upgrades.html#1-9-x-automatic-agent-draining">Automatic Agent Draining</a></li>
    </ul>
 </td>
<td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Flags-->
    <ul style="padding-left:10px;">
      <li>A <a href="upgrades.html#1-9-x-docker-ignore-runtime">docker_ignore_runtime</a></li>
      <li>A <a href="upgrades.html#1-9-x-configurable-ipc">disallow_sharing_agent_ipc_namespace</a></li>
      <li>A <a href="upgrades.html#1-9-x-configurable-ipc">default_container_shm_size</a></li>
      <li>C <a href="upgrades.html#1-9-x-agent-features">agent_features</a></li>
    </ul>
  </td>
<td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Framework API-->
    <ul style="padding-left:10px;">
      <li>A <a href="upgrades.html#1-9-x-configurable-ipc">LinuxInfo.ipc_mode and LinuxInfo.shm_size</a></li>
    </ul>
  </td>
<td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Module API-->
    <ul style="padding-left:10px;">
    </ul>
  </td>
<td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Endpoints-->
    <ul style="padding-left:10px;">
      <li>D <a href="upgrades.html#1-9-x-update-quota">SET_QUOTA and REMOVE QUOTA deprecated
            in favor of UPDATE_QUOTA</a></li>
      <li>D <a href="upgrades.html#1-9-x-quota-guarantees">Quota guarantees deprecated in favor
            of using quota limits</a></li>
    </ul>
  </td>
</tr>
<tr>
  <td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Version-->
  1.8.x
  </td>
<td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Mesos Core-->
    <ul style="padding-left:10px;">
      <li>A <a href="upgrades.html#1-8-x-linux-seccomp-isolator">Linux Seccomp isolator</a></li>
    </ul>
  </td>
<td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Flags-->
    <ul style="padding-left:10px;">
      <li>A <a href="upgrades.html#1-8-x-linux-seccomp-isolator">seccomp_config_dir</a></li>
      <li>A <a href="upgrades.html#1-8-x-linux-seccomp-isolator">seccomp_profile_name</a></li>
    </ul>
  </td>
<td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Framework API-->
    <ul style="padding-left:10px;">
    </ul>
  </td>
<td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Module API-->
    <ul style="padding-left:10px;">
    </ul>
  </td>
<td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Endpoints-->
    <ul style="padding-left:10px;">
    </ul>
  </td>
</tr>
<tr>
  <td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Version-->
  1.7.x
  </td>
<td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Mesos Core-->
    <ul style="padding-left:10px;">
      <li>A <a href="upgrades.html#1-7-x-linux-devices-isolator">Linux devices isolator</a></li>
      <li>A <a href="upgrades.html#1-7-x-auto-load-subsystems">Automatically load local enabled cgroups subsystems</a></li>
      <li>A <a href="upgrades.html#1-7-x-container-specific-cgroups-mounts">Container-specific cgroups mounts</a></li>
      <li>A <a href="upgrades.html#1-7-x-volume-mode-support">Volume mode support</a></li>
      <li>A <a href="upgrades.html#1-7-x-resource-provider-acls">Resource Provider ACLs</a></li>
    </ul>
  </td>
<td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Flags-->
    <ul style="padding-left:10px;">
      <li>A <a href="upgrades.html#1-7-x-enforce-container-ports">enforce_container_ports</a></li>
      <li>A <a href="upgrades.html#1-7-x-gc-non-executor-container-sandboxes">gc_non_executor_container_sandboxes</a></li>
      <li>A <a href="upgrades.html#1-7-x-network-cni-root-dir-persist">network_cni_root_dir_persist</a></li>
    </ul>
  </td>
<td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Framework API-->
    <ul style="padding-left:10px;">
      <li>C <a href="upgrades.html#1-7-x-create-disk">`CREATE_DISK` and `DESTROY_DISK` operations and ACLs</a></li>
    </ul>
  </td>
<td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Module API-->
    <ul style="padding-left:10px;">
      <li>C <a href="upgrades.html#1-7-x-container-logger">ContainerLogger module interface changes</a></li>
      <li>C <a href="upgrades.html#1-7-x-isolator-recover">Isolator::recover module interface changes</a></li>
    </ul>
  </td>
<td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Endpoints-->
    <ul style="padding-left:10px;">
      <li>C <a href="upgrades.html#1-7-x-json-serialization">JSON serialization changes</a></li>
    </ul>
  </td>
</tr>
<tr>
  <td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Version-->
  1.6.x
  </td>
<td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Mesos Core-->
    <ul style="padding-left:10px;">
      <li>C <a href="upgrades.html#1-6-x-grpc-requirement">Requirement for gRPC library</a></li>
      <li>C <a href="upgrades.html#1-6-x-csi-support">CSI v0.2 Support</a></li>
    </ul>
  </td>
<td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Flags-->
    <ul style="padding-left:10px;">
      <li>A <a href="upgrades.html#1-6-x-fetcher-stall-timeout">fetcher_stall_timeout</a></li>
    </ul>
    <ul style="padding-left:10px;">
      <li>A <a href="upgrades.html#1-6-x-xfs-kill-containers">xfs_kill_containers</a></li>
    </ul>
  </td>
<td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Framework API-->
    <ul style="padding-left:10px;">
    </ul>
  </td>
<td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Module API-->
    <ul style="padding-left:10px;">
      <li>C <a href="upgrades.html#1-6-x-disk-profile-adaptor">Disk profile adaptor module changes</a></li>
    </ul>
  </td>
<td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Endpoints-->
    <ul style="padding-left:10px;">
    </ul>
  </td>
</tr>
<tr>
  <td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Version-->
  1.5.x
  </td>
<td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Mesos Core-->
    <ul style="padding-left:10px;">
      <li>C <a href="upgrades.html#1-5-x-task-starting">Built-in executors send a TASK_STARTING update</a></li>
      <li>A <a href="upgrades.html#1-5-x-network-ports-isolator">Network ports isolator</a></li>
      <li>C <a href="upgrades.html#1-5-x-relative-disk-source-root-path">Relative source root paths for disk resources</a></li>
      <li>A <a href="upgrades.html#1-5-x-reconfiguration-policy">Agent state recovery after resource changes</a></li>
      <li>C <a href="upgrades.html#1-5-x-protobuf-requirement">Requirement for Protobuf library</a></li>
    </ul>
  </td>
<td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Flags-->
    <ul style="padding-left:10px;">
      <li>A <a href="upgrades.html#1-5-x-network-ports-isolator">container_ports_watch_interval</a></li>
      <li>A <a href="upgrades.html#1-5-x-network-ports-isolator">check_agent_port_range_only</a></li>
      <li>D <a href="upgrades.html#1-5-x-executor-secret-key">executor_secret_key</a></li>
      <li>A <a href="upgrades.html#1-5-x-reconfiguration-policy">reconfiguration_policy</a></li>
    </ul>
  </td>
<td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Framework API-->
    <ul style="padding-left:10px;">
      <li>A <a href="upgrades.html#1-5-x-task-resource-limitation">Added the TaskStatus.limitation message</a></li>
    </ul>
  </td>
<td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Module API-->
    <ul style="padding-left:10px;">
    </ul>
  </td>
<td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Endpoints-->
    <ul style="padding-left:10px;">
      <li>A <a href="upgrades.html#1-5-x-get-containers">Allowed to view nested/standalone containers</a></li>
    </ul>
  </td>
</tr>
<tr>
  <td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Version-->
  1.4.x
  </td>
<td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Mesos Core-->
    <ul style="padding-left:10px;">
      <li>A <a href="upgrades.html#1-4-x-ambient-capabilities">Container capabilities are made ambient if supported</a></li>
      <li>A <a href="upgrades.html#1-4-x-bounding-capabilities">Support for explicit bounding capabilities</a></li>
      <li>C <a href="upgrades.html#1-4-x-agent-recovery">Agent recovery post reboot</a></li>
      <li>C <a href="upgrades.html#1-4-x-xfs-no-enforce">XFS disk isolator support for not enforcing disk limits</a></li>
      <li>C <a href="upgrades.html#1-4-x-update-minimal-docker-version">Update the minimal supported Docker version</a></li>
    </ul>
  </td>
<td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Flags-->
    <ul style="padding-left:10px;">
      <li>A <a href="upgrades.html#1-4-x-agent-capabilities-flags">effective_capabilities</a></li>
      <li>A <a href="upgrades.html#1-4-x-agent-capabilities-flags">bounding-capabilities</a></li>
      <li>D <a href="upgrades.html#1-4-x-agent-capabilities-flags">allowed-capabilities</a></li>
    </ul>
  </td>
<td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Framework API-->
    <ul style="padding-left:10px;">
      <li>A <a href="upgrades.html#1-4-x-bounding-capabilities">Support for explicit setting bounding capabilities</a></li>
      <li>D <a href="upgrades.html#1-4-x-linuxinfo-capabilities">LinuxInfo.effective_capabilities deprecates LinuxInfo.capabilities</a></li>
      <li>C <a href="upgrades.html#1-4-x-mesos-library">`Resources` class in the internal Mesos C++ library only supports post-`RESERVATION_REFINEMENT` format</a></li>
    </ul>
  </td>
<td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Module API-->
    <ul style="padding-left:10px;">
      <li>C <a href="upgrades.html#1-4-x-allocator-update-slave">Changed semantics of Allocator::updateSlave</a></li>
    </ul>
  </td>
<td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Endpoints-->
    <ul style="padding-left:10px;">
    </ul>
  </td>
</tr>
<tr>
  <td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Version-->
  1.3.x
  </td>
  <td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Mesos Core-->
    <ul style="padding-left:10px;">
      <li>R <a href="upgrades.html#1-3-x-disallow-old-agents">Prevent registration by old Mesos agents</a></li>
    </ul>
  </td>
  <td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Flags-->
    <ul style="padding-left:10px;">
      <li>R <a href="upgrades.html#1-3-x-setquota-removequota-acl">--acls (set_quotas and remove_quotas)</a></li>
      <li>R <a href="upgrades.html#1-3-x-shutdown-framework-acl">--acls (shutdown_frameworks)</a></li>
      <li>A <a href="upgrades.html#1-3-x-executor-authentication">authenticate_http_executors</a></li>
      <li>A <a href="upgrades.html#1-3-x-executor-authentication">executor_secret_key</a></li>
    </ul>
  </td>
  <td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Framework API-->
    <ul style="padding-left:10px;">
      <li>A <a href="upgrades.html#1-3-x-multi-role-support">MULTI_ROLE support</a></li>
      <li>D <a href="upgrades.html#1-3-x-framework-info-role">FrameworkInfo.roles deprecates FrameworkInfo.role</a></li>
    </ul>
  </td>
  <td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Module API-->
    <ul style="padding-left:10px;">
      <li>C <a href="upgrades.html#1-3-x-allocator-interface-change">Allocator MULTI_ROLE interface changes</a></li>
    </ul>
  </td>
  <td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Endpoints-->
    <ul style="padding-left:10px;">
      <li>D <a href="upgrades.html#1-3-x-endpoints-roles">MULTI_ROLE deprecates 'role' field in endpoints</a></li>
    </ul>
  </td>
</tr>
<tr>
  <td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Version-->
  1.2.x
  </td>
  <td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Mesos Core-->
    <ul style="padding-left:10px;">
      <li>R <a href="upgrades.html#1-2-1-disallow-old-agents">Prevent registration by old Mesos agents</a></li>
    </ul>
  </td>
  <td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Flags-->
    <ul style="padding-left:10px;">
      <li>A <a href="upgrades.html#1-2-x-heartbeat-flag">http_heartbeat_interval</a></li>
      <li>A <a href="upgrades.html#1-2-x-backend-flag">image_provisioner_backend</a></li>
      <li>A <a href="upgrades.html#1-2-x-unreachable-flag">max_unreachable_tasks_per_framework</a></li>
    </ul>
  </td>
  <td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Framework API-->
    <ul style="padding-left:10px;">
      <li>A <a href="upgrades.html#1-2-x-revive-suppress">Revive and Suppress v1 scheduler Calls</a></li>
    </ul>
  </td>
  <td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Module API-->
    <ul style="padding-left:10px;">
      <li>C <a href="upgrades.html#1-2-x-container-logger-interface">Container Logger prepare method</a></li>
      <li>C <a href="upgrades.html#1-2-x-allocator-module-changes">Allocator module changes</a></li>
      <li>A <a href="upgrades.html#1-2-x-new-authz-actions">New Authorizer module actions</a></li>
      <li>D <a href="upgrades.html#1-2-x-renamed-authz-actions">Renamed Authorizer module actions (deprecated old aliases)</a></li>
      <li>R <a href="upgrades.html#1-2-x-removed-hooks">Removed slavePreLaunchDockerEnvironmentDecorator and slavePreLaunchDockerHook</a></li>
    </ul>
  </td>
  <td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Endpoints-->
    <ul style="padding-left:10px;">
      <li>A <a href="upgrades.html#1-2-x-debug-endpoints">LAUNCH_NESTED_CONTAINER_SESSION, ATTACH_CONTAINER_INPUT, ATTACH_CONTAINER_OUTPUT</a></li>
      <li>D <a href="upgrades.html#1-2-x-recovered-frameworks">v1 GetFrameworks recovered_frameworks</a></li>
      <li>D <a href="upgrades.html#1-2-x-orphan-executors">v1 GetExecutors orphan_executors</a></li>
      <li>D <a href="upgrades.html#1-2-x-orphan-tasks">v1 GetTasks orphan_tasks</a></li>
    </ul>
  </td>
</tr>
<tr>
  <td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Version-->
  1.1.x
  </td>
  <td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Mesos Core-->
  </td>
  <td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Flags-->
  </td>
  <td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Framework API-->
  </td>
  <td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Module API-->
    <ul style="padding-left:10px;">
      <li>R <a href="upgrades.html#1-1-x-container-logger-interface">Container Logger recovery method</a></li>
      <li>C <a href="upgrades.html#1-1-x-allocator-updateallocation">Allocator updateAllocation method</a></li>
    </ul>
  </td>
  <td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Endpoints-->
  </td>
</tr>
<tr>
  <td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Version-->
  1.0.x
  </td>
  <td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Mesos Core-->
    <ul style="padding-left:10px;">
      <li>CD <a href="upgrades.html#1-0-x-allocator-metrics">Allocator Metrics</a></li>
      <li>C <a href="upgrades.html#1-0-x-persistent-volume">Destruction of persistent volumes</a></li>
      <li>C <a href="upgrades.html#1-0-x-slave">Slave to Agent rename</a></li>
      <li>C <a href="upgrades.html#1-0-x-quota-acls">Quota ACLs</a></li>
      <li>R <a href="upgrades.html#1-0-x-executor-environment-variables">Executor environment variables inheritance</a></li>
      <li>R <a href="upgrades.html#1-0-x-deprecated-fields-in-container-config">Deprecated fields in ContainerConfig</a></li>
      <li>C <a href="upgrades.html#1-0-x-persistent-volume-ownership">Persistent volume ownership</a></li>
      <li>C <a href="upgrades.html#1-0-x-fetcher-user">Fetcher assumes same user as task</a></li>
    </ul>
  </td>
  <td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Flags-->
    <ul style="padding-left:10px;">
      <li>D <a href="upgrades.html#1-0-x-docker-timeout-flag">docker_stop_timeout</a></li>
      <li>D <a href="upgrades.html#1-0-x-credentials-file">credential(s) (plain text format)</a></li>
      <li>C <a href="upgrades.html#1-0-x-slave">Slave to Agent rename</a></li>
      <li>R <a href="upgrades.html#1-0-x-workdir">work_dir default value</a></li>
      <li>D <a href="upgrades.html#1-0-x-deprecated-ssl-env-variables">SSL environment variables</a></li>
      <li>ACD <a href="upgrades.html#1-0-x-http-authentication-flags">HTTP authentication</a></li>
      <li>R <a href="upgrades.html#1-0-x-registry-strict">registry_strict</a></li>
    </ul>
  </td>
  <td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Framework API-->
    <ul style="padding-left:10px;">
      <li>DC <a href="upgrades.html#1-0-x-executorinfo">ExecutorInfo.source</a></li>
      <li>A <a href="upgrades.html#1-0-x-v1-commandinfo">CommandInfo.URI output_file</a></li>
      <li>C <a href="upgrades.html#1-0-x-scheduler-proto">scheduler.proto optional fields</a></li>
      <li>C <a href="upgrades.html#1-0-x-executor-proto">executor.proto optional fields</a></li>
    </ul>
  </td>
  <td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Module API-->
    <ul style="padding-left:10px;">
      <li>C <a href="upgrades.html#1-0-x-authorizer">Authorizer</a></li>
      <li>C <a href="upgrades.html#1-0-x-allocator">Allocator</a></li>
    </ul>
  </td>
  <td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Endpoints-->
    <ul style="padding-left:10px;">
      <li>C <a href="upgrades.html#1-0-x-status-code">HTTP return codes</a></li>
      <li>R <a href="upgrades.html#1-0-x-status-code">/observe</a></li>
      <li>C <a href="upgrades.html#1-0-x-endpoint-authorization">Added authorization</a></li>
    </ul>
  </td>
</tr>
<tr>
  <td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Version-->
  0.28.x
  </td>
  <td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Mesos Core-->
    <ul style="padding-left:10px;">
      <li>C <a href="upgrades.html#0-28-x-resource-precision">Resource Precision</a></li>
    </ul>
  </td>
  <td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Flags-->
    <ul style="padding-left:10px;">
      <li>C <a href="upgrades.html#0-28-x-autherization-acls">Authentication ACLs</a></li>
    </ul>
  </td>
  <td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Framework API-->
  </td>
  <td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Module API-->
  </td>
  <td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Endpoints-->
  </td>
</tr>
<tr>
  <td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Version-->
  0.27.x
  </td>
  <td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Mesos Core-->
  </td>
  <td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Flags-->
    <ul style="padding-left:10px;">
      <li>D <a href="upgrades.html#0-27-x-implicit-roles">--roles</a></li>
      <li>D <a href="upgrades.html#0-27-x-acl-shutdown-flag">--acls (shutdown_frameworks)</a></li>
    </ul>
  </td>
  <td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Framework API-->
    <ul style="padding-left:10px;">
      <li>C <a href="upgrades.html#0-27-x-executor-lost-callback">executorLost callback</a></li>
    </ul>
  </td>
  <td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Module API-->
    <ul style="padding-left:10px;">
      <li>C <a href="upgrades.html#0-27-x-allocator-api">Allocator API</a></li>
      <li>C <a href="upgrades.html#0-27-x-isolator-api">Isolator API</a></li>
    </ul>
  </td>
  <td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Endpoints-->
  </td>
</tr>
<tr>
  <td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Version-->
  0.26.x
  </td>
  <td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Mesos Core-->
  </td>
  <td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Flags-->
  </td>
  <td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Framework API-->
    <ul style="padding-left:10px;">
      <li>C <a href="upgrades.html#0-26-x-taskstatus-reason">TaskStatus::Reason Enum</a></li>
      <li>C <a href="upgrades.html#0-26-x-credential-protobuf">Credential Protobuf</a></li>
      <li>C <a href="upgrades.html#0-26-x-network-info-protobuf">NetworkInfo Protobuf</a></li>
    </ul>
  </td>
  <td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Module API-->
  </td>
  <td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Endpoints-->
    <ul style="padding-left:10px;">
      <li>C <a href="upgrades.html#0-26-x-state-endpoint">State Endpoint</a></li>
    </ul>
  </td>
</tr>
<tr>
  <td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Version-->
  0.25.x
  </td>
  <td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Mesos Core-->
  </td>
  <td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Flags-->
  </td>
  <td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Framework API-->
    <ul style="padding-left:10px;">
      <li>C <a href="upgrades.html#0-25-x-scheduler-bindings">C++/Java/Python Scheduler Bindings</a></li>
    </ul>
  </td>
  <td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Module API-->
  </td>
  <td style="word-wrap: break-word; overflow-wrap: break-word;"><!--Endpoints-->
    <ul style="padding-left:10px;">
      <li>D <a href="upgrades.html#0-25-x-json-endpoints">*.json Endpoints</a></li>
    </ul>
  </td>
</tr>
</table>
<h2 id="upgrading-from-19x-to-110x"><a class="header" href="#upgrading-from-19x-to-110x">Upgrading from 1.9.x to 1.10.x</a></h2>
<p><a name="1-10-x-ssl-env-var-rename"></a></p>
<ul>
<li>The canonical name for the environment variable <code>LIBPROCESS_SSL_VERIFY_CERT</code> was changed to <code>LIBPROCESS_SSL_VERIFY_SERVER_CERT</code>.
The canonical name for the environment variable <code>LIBPROCESS_SSL_REQUIRE_CERT</code> was changed to <code>LIBPROCESS_SSL_REQUIRE_CLIENT_CERT</code>.
The old names will continue to work as before, but operators are encouraged to update their configuration to reduce confusion.</li>
</ul>
<p><a name="1-10-x-limits-cfs-quota"></a></p>
<ul>
<li>The Mesos agent's <code>cgroups_enable_cfs</code> flag previously controlled whether or not CFS quota would be used for all tasks on the agent. Resource limits have been added to tasks, and when a CPU limit is specified on a task, the agent will now apply a CFS quota regardless of the value of <code>cgroups_enable_cfs</code>.</li>
</ul>
<p><a name="1-10-x-agent-features"></a></p>
<ul>
<li>The Mesos agent now requires the new <code>TASK_RESOURCE_LIMITS</code> feature. This capability is set by default, but if the <code>--agent_features</code> flag is specified explicitly, <code>TASK_RESOURCE_LIMITS</code> must be included.</li>
</ul>
<p><a name="1-10-x-synchronous-authorization"></a></p>
<ul>
<li>Authorizers now must implement a method <code>getApprover(...)</code> (see the
<a href="authorization.html#implementing-an-authorizer">authorization documentation</a>
and <a href="https://issues.apache.org/jira/browse/MESOS-10056">MESOS-10056</a>)
that returns <code>ObjectApprover</code>s that are valid throughout their whole lifetime.
Keeping the state of an <code>ObjectApprover</code> up-to-date becomes a responsibility
of the authorizer. This is a <strong>breaking change</strong> for authorizer modules.</li>
</ul>
<p><a name="1-10-x-tasks-pending-authoirization-deprecated"></a></p>
<ul>
<li>The field <code>pending_tasks</code> in <code>GetTasks</code> master API call has been deprecated.
From now on, this field will be empty. Moreover, the notion of
<em>tasks pending authorization</em> no longer exists
(see <a href="https://issues.apache.org/jira/browse/MESOS-10056">MESOS-10056</a>).</li>
</ul>
<p><a name="1-10-x-allocator-module-changes"></a></p>
<ul>
<li>Allocator interface has been changed to supply allocator with information on
resources actually consumed by frameworks. A method
<code>transitionOfferedToAllocated(...)</code> has been added and the signature of
<code>recoverResources(...)</code> has been extended. Note that allocators must implement
these new/extended method signatures, but are free to ignore resource
consumption data provided by master.</li>
</ul>
<h2 id="upgrading-from-18x-to-19x"><a class="header" href="#upgrading-from-18x-to-19x">Upgrading from 1.8.x to 1.9.x</a></h2>
<p><a name="1-9-x-automatic-agent-draining"></a></p>
<ul>
<li>A new <code>DRAINING</code> state has been added to Mesos agents. Once an agent is draining, all tasks running on that agent are gracefully
killed and no offers for that agent are sent to schedulers, preventing the launching of new tasks.
Operators can put an agent into <code>DRAINING</code> state by using the <code>DRAIN_AGENT</code> operator API call.
See <a href="maintenance.html"><code>docs/maintenance</code></a> for details.</li>
</ul>
<p><a name="1-9-x-agent-features"></a></p>
<ul>
<li>The Mesos agent now requires the new <code>AGENT_DRAINING</code> feature. This capability is set by default, but if the <code>--agent_features</code> flag is specified explicitly, <code>AGENT_DRAINING</code> must be included.</li>
</ul>
<p><a name="1-9-x-linux-nnp-isolator"></a></p>
<ul>
<li>A new <a href="isolators/linux-nnp.html"><code>linux/nnp</code></a> isolator has been added. The isolator supports setting of the <code>no_new_privs</code> bit in the container, preventing tasks from acquiring additional privileges.</li>
</ul>
<p><a name="1-9-x-docker-ignore-runtime"></a></p>
<ul>
<li>A new <a href="configuration/agent.html#docker_ignore_runtime"><code>--docker_ignore_runtime</code></a> flag has been added. This causes the agent to ignore any runtime configuration present in Docker images.</li>
</ul>
<p><a name="1-9-x-hostname-validation-scheme"></a></p>
<ul>
<li>A new libprocess TLS flag <code>--hostname_validation_scheme</code> along with the corresponding environment variable <code>LIBPROCESS_SSL_HOSTNAME_VALIDATION_SCHEME</code>
has been added. Using this flag, users can configure the way libprocess performs hostname validation for TLS connections.
See <a href="ssl.html"><code>docs/ssl</code></a> for details.</li>
</ul>
<p><a name="1-9-x-client-certificate-verification"></a></p>
<ul>
<li>The semantics of the libprocess environment variables <code>LIBPROCESS_SSL_VERIFY_CERT</code> and <code>LIBPROCESS_SSL_REQUIRE_CERT</code> have been slightly updated such that
the former now only applies to client-mode and the latter only to server-mode connections. As part of this re-adjustment, the following two changes have
been introduced that might require changes for operators running Mesos in unusual TLS configurations.
<ul>
<li>Anonymous ciphers can not be used anymore when <code>LIBPROCESS_SSL_VERIFY_CERT</code> is set to true. This is because the use of anonymous ciphers enables
a malicious attacker to bypass certificate verification by choosing a certificate-less cipher.
Users that rely on anonymous ciphers being available should make sure that <code>LIBPROCESS_SSL_VERIFY_CERT</code> is set to false.</li>
<li>For incoming connections, certificates are not verified unless <code>LIBPROCESS_SSL_REQUIRE_CERT</code> is set to true.
This is because verifying the certificate can lead to false negatives, where a connection is aborted even though presenting no certificate at all
would have been successfull. Users that rely on incoming connection requests presenting valid TLS certificates should make sure that
the <code>LIBPROCESS_SSL_REQUIRE_CERT</code> option is set to true.</li>
</ul>
</li>
</ul>
<p><a name="1-9-x-configurable-ipc"></a></p>
<ul>
<li>The Mesos containerizer now supports configurable IPC namespace and /dev/shm. Container can be configured to have a private IPC namespace and /dev/shm or share them from its parent via the field <code>LinuxInfo.ipc_mode</code>, and the size of its private /dev/shm is also configurable via the field <code>LinuxInfo.shm_size</code>. Operators can control whether it is allowed to share host's IPC namespace and /dev/shm with top level containers via the agent flag <code>--disallow_sharing_agent_ipc_namespace</code>, and specify the default size of the /dev/shm for the container which has a private /dev/shm via the agent flag <code>--default_container_shm_size</code>.</li>
</ul>
<p><a name="1-9-x-update-quota"></a></p>
<ul>
<li>The <code>SET_QUOTA</code> and <code>REMOVE QUOTA</code> master calls are deprecated in favor of a new <code>UPDATE_QUOTA</code> master call.</li>
</ul>
<p><a name="1-9-x-quota-guarantees"></a></p>
<ul>
<li>Prior to Mesos 1.9, the quota related APIs only exposed quota &quot;guarantees&quot; which ensured a minimum amount of resources would be available to a role. Setting guarantees also set implicit quota limits. In Mesos 1.9+, quota limits are now exposed directly.
<ul>
<li>Quota guarantees are now deprecated in favor of using only quota limits. Enforcement of quota guarantees required that Mesos holds back enough resources to meet all of the unsatisfied quota guarantees. Since Mesos is moving towards an optimistic offer model (to improve multi-role / multi- scheduler scalability, see MESOS-1607), it will become no longer possible to enforce quota guarantees by holding back resources. In such a model, quota limits are simple to enforce, but quota guarantees would require a complex &quot;effective limit&quot; propagation model to leave space for unsatisfied guarantees.</li>
<li>For these reasons, quota guarantees, while still functional in Mesos 1.9, are now deprecated. A combination of limits and priority based preemption will be simpler in an optimistic offer model.</li>
</ul>
</li>
</ul>
<h2 id="upgrading-from-17x-to-18x"><a class="header" href="#upgrading-from-17x-to-18x">Upgrading from 1.7.x to 1.8.x</a></h2>
<p><a name="1-8-x-linux-seccomp-isolator"></a></p>
<ul>
<li>A new <a href="isolators/linux-seccomp.html"><code>linux/seccomp</code></a> isolator has been added. The isolator supports the following new agent flags:
<ul>
<li><code>--seccomp_config_dir</code> specifies the directory path of the Seccomp profiles.</li>
<li><code>--seccomp_profile_name</code> specifies the path of the default Seccomp profile relative to the <code>seccomp_config_dir</code>.</li>
</ul>
</li>
</ul>
<h2 id="upgrading-from-16x-to-17x"><a class="header" href="#upgrading-from-16x-to-17x">Upgrading from 1.6.x to 1.7.x</a></h2>
<p><a name="1-7-x-linux-devices-isolator"></a></p>
<ul>
<li>A new <a href="isolators/linux-devices.html"><code>linux/devices</code></a> isolator has been
added. This isolator automatically populates containers with devices
that have been whitelisted with the <code>--allowed_devices</code> agent flag.</li>
</ul>
<p><a name="1-7-x-auto-load-subsystems"></a></p>
<ul>
<li>A new option <code>cgroups/all</code> has been added to the agent flag <code>--isolation</code>. This allows cgroups isolator to automatically load all the local enabled cgroups subsystems. If this option is specified in the agent flag <code>--isolation</code> along with other cgroups related options (e.g., <code>cgroups/cpu</code>), those options will be just ignored.</li>
</ul>
<p><a name="1-7-x-container-specific-cgroups-mounts"></a></p>
<ul>
<li>Added container-specific cgroups mounts under <code>/sys/fs/cgroup</code> to containers with image launched by Mesos containerizer.</li>
</ul>
<p><a name="1-7-x-volume-mode-support"></a></p>
<ul>
<li>Previously the <code>HOST_PATH</code>, <code>SANDBOX_PATH</code>, <code>IMAGE</code>, <code>SECRET</code>, and <code>DOCKER_VOLUME</code> volumes were always mounted for container in read-write mode, i.e., the <code>Volume.mode</code> field was not honored. Now we will mount these volumes based on the <code>Volume.mode</code> field so framework can choose to mount the volume for the container in either read-write mode or read-only mode.</li>
</ul>
<p><a name="1-7-x-create-disk"></a></p>
<ul>
<li>To simplify the API for CSI-backed disk resources, the following operations and corresponding ACLs have been introduced to replace the experimental <code>CREATE_VOLUME</code>, <code>CREATE_BLOCK</code>, <code>DESTROY_VOLUME</code> and <code>DESTROY_BLOCK</code> operations:
<ul>
<li><code>CREATE_DISK</code> to create a <code>MOUNT</code> or <code>BLOCK</code> disk resource from a <code>RAW</code> disk resource. The <code>CreateMountDisk</code> and <code>CreateBlockDisk</code> ACLs control which principals are allowed to create <code>MOUNT</code> or <code>BLOCK</code> disks for which roles.</li>
<li><code>DESTROY_DISK</code> to reclaim a <code>MOUNT</code> or <code>BLOCK</code> disk resource back to a <code>RAW</code> disk resource. The <code>DestroyMountDisk</code> and <code>DestroyBlockDisk</code> ACLs control which principals are allowed to reclaim <code>MOUNT</code> or <code>BLOCK</code> disks for which roles.</li>
</ul>
</li>
</ul>
<p><a name="1-7-x-resource-provider-acls"></a></p>
<ul>
<li>A new <code>ViewResourceProvider</code> ACL has been introduced to control which principals are allowed to call the <code>GET_RESOURCE_PROVIDERS</code> agent API.</li>
</ul>
<p><a name="1-7-x-enforce-container-ports"></a></p>
<ul>
<li>A new <a href="configuration/agent.html#enforce_container_ports"><code>--enforce_container_ports</code></a> flag has been added to toggle whether the <a href="isolators/network-ports.html"><code>network/ports</code></a> isolator should enforce TCP ports usage limits.</li>
</ul>
<p><a name="1-7-x-gc-non-executor-container-sandboxes"></a></p>
<ul>
<li>A new <a href="configuration/agent.html#gc_non_executor_container_sandboxes"><code>--gc_non_executor_container_sandboxes</code></a>
agent flag has been added to garbage collect the sandboxes of nested
containers, which includes the tasks groups launched by the default executor.
We recommend enabling the flag if you have frameworks that launch multiple
task groups on the same default executor instance.</li>
</ul>
<p><a name="1-7-x-network-cni-root-dir-persist"></a></p>
<ul>
<li>A new <a href="configuration/agent.html#network_cni_root_dir_persist"><code>--network_cni_root_dir_persist</code></a> flag has been added to toggle whether the <a href="cni.html"><code>network/cni</code></a> isolator should persist the network information across reboots.</li>
</ul>
<p><a name="1-7-x-container-logger"></a></p>
<ul>
<li><code>ContainerLogger</code> module interface has been changed. The <code>prepare()</code> method now takes <code>ContainerID</code> and <code>ContainerConfig</code> instead.</li>
</ul>
<p><a name="1-7-x-isolator-recover"></a></p>
<ul>
<li><code>Isolator::recover()</code> has been updated to take an <code>std::vector</code> instead of <code>std::list</code> of container states.</li>
</ul>
<p><a name="1-7-x-json-serialization"></a></p>
<ul>
<li>As a result of adapting rapidjson for performance improvement, all JSON endpoints serialize differently while still conforming to the ECMA-404 spec for JSON. This means that if a client has a JSON de-serializer that conforms to ECMA-404 they will see no change. Otherwise, they may break. As an example, Mesos would previously serialize '/' as '/', but the spec does not require the escaping and rapidjson does not escape '/'.</li>
</ul>
<h2 id="upgrading-from-15x-to-16x"><a class="header" href="#upgrading-from-15x-to-16x">Upgrading from 1.5.x to 1.6.x</a></h2>
<p><a name="1-6-x-grpc-requirement"></a></p>
<ul>
<li>gRPC version 1.10+ is required to build Mesos when enabling gRPC-related features. Please upgrade your gRPC library if you are using an unbundled one.</li>
</ul>
<p><a name="1-6-x-csi-support"></a></p>
<ul>
<li>CSI v0.2 is now supported as experimental. Due to the incompatibility between CSI v0.1 and v0.2, the experimental support for CSI v0.1 is removed, and the operator must remove all storage local resource providers within an agent before upgrading the agent. NOTE: This is a <strong>breaking change</strong> for storage local resource providers.</li>
</ul>
<p><a name="1-6-x-fetcher-stall-timeout"></a></p>
<ul>
<li>A new agent flag <code>--fetcher_stall_timeout</code> has been added. This flag specifies the amount of time for the container image and artifact fetchers to wait before aborting a stalled download (i.e., the speed keeps below one byte per second). NOTE: This flag only applies when downloading data from the net and does not apply to HDFS.</li>
</ul>
<p><a name="1-6-x-disk-profile-adaptor"></a></p>
<ul>
<li>The disk profile adaptor module has been changed to support CSI v0.2, and its header file has been renamed to be consistent with other modules. See <code>disk_profile_adaptor.hpp</code> for interface changes.</li>
</ul>
<p><a name="1-6-x-xfs-kill-containers"></a></p>
<ul>
<li>A new agent flag <code>--xfs_kill_containers</code> has been added. By setting this flag, the <a href="isolators/disk-xfs.html"><code>disk/xfs</code></a> isolator
will now kill containers that exceed the disk limit.</li>
</ul>
<h2 id="upgrading-from-14x-to-15x"><a class="header" href="#upgrading-from-14x-to-15x">Upgrading from 1.4.x to 1.5.x</a></h2>
<p><a name="1-5-x-task-starting"></a></p>
<ul>
<li>The built-in executors will now send a <code>TASK_STARTING</code> status update for
every task they've successfully received and are about to start.
The possibility of any executor sending this update has been documented since
the beginning of Mesos, but prior to this version the built-in executors did
not actually send it. This means that all schedulers using one of the built-in
executors must be upgraded to expect <code>TASK_STARTING</code> updates before upgrading
Mesos itself.</li>
</ul>
<p><a name="1-5-x-task-resource-limitation"></a></p>
<ul>
<li>A new field, <code>limitation</code>, was added to the <code>TaskStatus</code> message. This
field is a <code>TaskResourceLimitation</code> message that describes the resources
that caused a task to fail with a resource limitation reason.</li>
</ul>
<p><a name="1-5-x-network-ports-isolator"></a></p>
<ul>
<li>A new <a href="isolators/network-ports.html"><code>network/ports</code></a> isolator has been added. The isolator supports the following new agent flags:
<ul>
<li><code>--container_ports_watch_interval</code> specifies the interval at which the isolator reconciles port assignments.</li>
<li><code>--check_agent_port_range_only</code> excludes ports outside the agent's range from port reconciliation.</li>
</ul>
</li>
</ul>
<p><a name="1-5-x-executor-secret-key"></a></p>
<ul>
<li>Agent flag <code>--executor_secret_key</code> has been deprecated. Operators should use <code>--jwt_secret_key</code> instead.</li>
</ul>
<p><a name="1-5-x-relative-disk-source-root-path"></a></p>
<ul>
<li>The fields <code>Resource.disk.source.path.root</code> and <code>Resource.disk.source.mount.root</code> can now be set to relative paths to an agent's work directory. The containerizers will interpret the paths based on the <code>--work_dir</code> flag on an agent.</li>
</ul>
<p><a name="1-5-x-get-containers"></a></p>
<ul>
<li>The agent operator API call <code>GET_CONTAINERS</code> has been updated to support listing nested or standalone containers. One can specify the following fields in the request:
<ul>
<li><code>show_nested</code>: Whether to show nested containers.</li>
<li><code>show_standalone</code>: Whether to show standalone containers.</li>
</ul>
</li>
</ul>
<p><a name="1-5-x-reconfiguration-policy"></a></p>
<ul>
<li>A new agent flag <code>--reconfiguration_policy</code> has been added. By setting the value of this flag to <code>additive</code>,
operators can allow the agent to be restarted with increased resources without requiring the agent ID to be
changed. Note that if this feature is used, the master version is required to be &gt;= 1.5 as well.</li>
</ul>
<p><a name="1-5-x-protobuf-requirement"></a></p>
<ul>
<li>Protobuf version 3+ is required to build Mesos. Please upgrade your Protobuf library if you are using an unbundled one.</li>
</ul>
<p><a name="1-5-x-log-reader-catchup"></a></p>
<ul>
<li>A new <code>catchup()</code> method has been added to the replicated log reader API. The method allows to catch-up positions missing in the local non-leading replica to allow safe eventually consistent reads from it. Note about backwards compatibility: In order for the feature to work correctly in presence of log truncations all log replicas need to be updated.</li>
</ul>
<h2 id="upgrading-from-13x-to-14x"><a class="header" href="#upgrading-from-13x-to-14x">Upgrading from 1.3.x to 1.4.x</a></h2>
<p><a name="1-4-x-ambient-capabilities"></a></p>
<ul>
<li>If the <code>mesos-agent</code> kernel supports ambient capabilities (Linux 4.3 or later), the capabilities specified in the <code>LinuxInfo.effective_capabilities</code> message will be made ambient in the container task.</li>
</ul>
<p><a name="1-4-x-bounding-capabilities"></a></p>
<ul>
<li>Explicitly setting the bounding capabilities of a task independently of the effective capabilities is now supported. Frameworks can specify the task bounding capabilities by using the <code>LinuxInfo.bounding_capabilities</code> message. Operators can specify the default bounding capabilities using the agent <code>--bounding_capabilities</code> flag. This flag also specifies the maximum bounding set that a framework is allowed to specify.</li>
</ul>
<p><a name="1-4-x-agent-recovery"></a></p>
<ul>
<li>Agent is now allowed to recover its agent ID post a host reboot. This prevents the unnecessary discarding of agent ID by prior Mesos versions. Notes about backwards compatibility:
<ul>
<li>In case the agent's recovery runs into agent info mismatch which may happen due to resource change associated with reboot, it'll fall back to recovering as a new agent (existing behavior).</li>
<li>In other cases such as checkpointed resources (e.g. persistent volumes) being incompatible with the agent's resources the recovery will still fail (existing behavior).</li>
</ul>
</li>
</ul>
<p><a name="1-4-x-linuxinfo-capabilities"></a></p>
<ul>
<li>The <code>LinuxInfo.capabilities</code> field has been deprecated in favor of <code>LinuxInfo.effective_capabilities</code>.</li>
</ul>
<p><a name="1-4-x-agent-capabilities-flags"></a></p>
<ul>
<li>Changes to capability-related agent flags:
<ul>
<li>The agent <code>--effective_capabilities</code> flag has been added to specify the default effective capability set for tasks.</li>
<li>The agent <code>--bounding_capabilities</code> flag has been added to specify the default bounding capability set for tasks.</li>
<li>The agent <code>--allowed-capabilities</code> flag has been deprecated in favor of <code>--effective_capabilities</code>.</li>
</ul>
</li>
</ul>
<p><a name="1-4-x-allocator-update-slave"></a></p>
<ul>
<li>The semantics of the optional resource argument passed in <code>Allocator::updateSlave</code> was change. While previously the passed value denoted a new amount of oversubscribed (revocable) resources on the agent, it now denotes the new amount of total resources on the agent. This requires custom allocator implementations to update their interpretation of the passed value.</li>
</ul>
<p><a name="1-4-x-xfs-no-enforce"></a></p>
<ul>
<li>The XFS Disk Isolator now supports the <code>--no-enforce_container_disk_quota</code> option to efficiently measure disk resource usage without enforcing any usage limits.</li>
</ul>
<p><a name="1-4-x-mesos-library"></a></p>
<ul>
<li>The <code>Resources</code> class in the internal Mesos C++ library changed its behavior to only support post-<code>RESERVATION_REFINEMENT</code> format. If a framework is using this internal utility, it is likely to break if the <code>RESERVATION_REFINEMENT</code> capability is not enabled.</li>
</ul>
<p><a name="1-4-x-update-minimal-docker-version"></a></p>
<ul>
<li>To specify the <code>--type=container</code> option for the <code>docker inspect &lt;container_name&gt;</code> command, the minimal supported Docker version has been updated from 1.0.0 to 1.8.0 since Docker supported <code>--type=container</code> for the <code>docker inspect</code> command starting from 1.8.0.</li>
</ul>
<h2 id="upgrading-from-12x-to-13x"><a class="header" href="#upgrading-from-12x-to-13x">Upgrading from 1.2.x to 1.3.x</a></h2>
<p><a name="1-3-x-disallow-old-agents"></a></p>
<ul>
<li>The master will no longer allow 0.x agents to register. Interoperability between 1.1+ masters and 0.x agents has never been supported; however, it was not explicitly disallowed, either. Starting with this release of Mesos, registration attempts by 0.x agents will be ignored.</li>
</ul>
<p><a name="1-3-x-setquota-removequota-acl"></a></p>
<ul>
<li>Support for deprecated ACLs <code>set_quotas</code> and <code>remove_quotas</code> has been removed from the local authorizer. Before upgrading the Mesos binaries, consolidate the ACLs used under <code>set_quotas</code> and <code>remove_quotes</code> under their replacement ACL <code>update_quotas</code>. After consolidation of the ACLs, the binaries could be safely replaced.</li>
</ul>
<p><a name="1-3-x-shutdown-framework-acl"></a></p>
<ul>
<li>Support for deprecated ACL <code>shutdown_frameworks</code> has been removed from the local authorizer. Before upgrading the Mesos binaries, replace all instances of the ACL <code>shutdown_frameworks</code> with the newer ACL <code>teardown_frameworks</code>. After updating the ACLs, the binaries can be safely replaced.</li>
</ul>
<p><a name="1-3-x-multi-role-support"></a>
<a name="1-3-x-framework-info-role"></a></p>
<ul>
<li>Support for multi-role frameworks deprecates the <code>FrameworkInfo.role</code> field in favor of <code>FrameworkInfo.roles</code> and the <code>MULTI_ROLE</code> capability. Frameworks using the new field can continue to use a single role.</li>
</ul>
<p><a name="1-3-x-endpoints-roles"></a></p>
<ul>
<li>Support for multi-role frameworks means that the framework <code>role</code> field in the master and agent endpoints is deprecated in favor of <code>roles</code>. Any tooling parsing endpoint information and relying on the role field needs to be updated before multi-role frameworks can be safely run in the cluster.</li>
</ul>
<p><a name="1-3-x-allocator-interface-change"></a></p>
<ul>
<li>Implementors of allocator modules have to provide new implementation functionality to satisfy the <code>MULTI_ROLE</code> framework capability. Also, the interface has changed.</li>
</ul>
<p><a name="1-3-x-executor-authentication"></a></p>
<ul>
<li>New Agent flags <code>authenticate_http_executors</code> and <code>executor_secret_key</code>: Used to enable required HTTP executor authentication and set the key file used for generation and authentication of HTTP executor tokens. Note that enabling these flags after upgrade is disruptive to HTTP executors that were launched before the upgrade. For more information on the recommended upgrade procedure when enabling these flags, see the <a href="authentication.html">authentication documentation</a>.</li>
</ul>
<p>In order to upgrade a running cluster:</p>
<ol>
<li>Rebuild and install any modules so that upgraded masters/agents/schedulers can use them.</li>
<li>Install the new master binaries and restart the masters.</li>
<li>Install the new agent binaries and restart the agents.</li>
<li>Upgrade the schedulers by linking the latest native library / jar / egg (if necessary).</li>
<li>Restart the schedulers.</li>
<li>Upgrade the executors by linking the latest native library / jar / egg (if necessary).</li>
</ol>
<h2 id="upgrading-from-11x-to-12x"><a class="header" href="#upgrading-from-11x-to-12x">Upgrading from 1.1.x to 1.2.x</a></h2>
<p><a name="1-2-1-disallow-old-agents"></a></p>
<ul>
<li>In Mesos 1.2.1, the master will no longer allow 0.x agents to register. Interoperability between 1.1+ masters and 0.x agents has never been supported; however, it was not explicitly disallowed, either. Starting with Mesos 1.2.1, registration attempts by 0.x agents will be ignored. <strong>NOTE:</strong> This applies only when upgrading to Mesos 1.2.1. Mesos 1.2.0 does not implement this behavior.</li>
</ul>
<p><a name="1-2-x-heartbeat-flag"></a></p>
<ul>
<li>New Agent flag http_heartbeat_interval: This flag sets a heartbeat interval for messages to be sent over persistent connections made against the agent HTTP API. Currently, this only applies to the LAUNCH_NESTED_CONTAINER_SESSION and ATTACH_CONTAINER_OUTPUT calls. (default: 30secs)</li>
</ul>
<p><a name="1-2-x-backend-flag"></a></p>
<ul>
<li>New Agent flag image_provisioner_backend: Strategy for provisioning container rootfs from images, e.g., aufs, bind, copy, overlay.</li>
</ul>
<p><a name="1-2-x-unreachable-flag"></a></p>
<ul>
<li>New Master flag max_unreachable_tasks_per_framework: Maximum number of unreachable tasks per framework to store in memory. (default: 1000)</li>
</ul>
<p><a name="1-2-x-revive-suppress"></a></p>
<ul>
<li>New Revive and Suppress v1 scheduler Calls: Revive or Suppress offers for a specified role. If role is unset, the call will revive/suppress offers for all of the roles the framework is subscribed to. (Especially for multi-role frameworks.)</li>
</ul>
<p><a name="1-2-x-container-logger-interface"></a></p>
<ul>
<li>Mesos 1.2 modifies the <code>ContainerLogger</code>'s <code>prepare()</code> method.  The method now takes an additional argument for the <code>user</code> the logger should run a subprocess as.  Please see <a href="https://issues.apache.org/jira/browse/MESOS-5856">MESOS-5856</a> for more information.</li>
</ul>
<p><a name="1-2-x-allocator-module-changes"></a></p>
<ul>
<li>Allocator module changes to support inactive frameworks, multi-role frameworks, and suppress/revive. See <code>allocator.hpp</code> for interface changes.</li>
</ul>
<p><a name="1-2-x-new-authz-actions"></a></p>
<ul>
<li>New Authorizer module actions: LAUNCH_NESTED_CONTAINER, KILL_NESTED_CONTAINER, WAIT_NESTED_CONTAINER, LAUNCH_NESTED_CONTAINER_SESSION, ATTACH_CONTAINER_INPUT, ATTACH_CONTAINER_OUTPUT, VIEW_CONTAINER, and SET_LOG_LEVEL. See <code>authorizer.proto</code> for module interface changes, and <code>acls.proto</code> for corresponding LocalAuthorizer ACL changes.</li>
</ul>
<p><a name="1-2-x-renamed-authz-actions"></a></p>
<ul>
<li>Renamed Authorizer module actions (and deprecated old aliases): REGISTER_FRAMEWORK, TEARDOWN_FRAMEWORK, RESERVE_RESOURCES, UNRESERVE_RESOURCES, CREATE_VOLUME, DESTROY_VOLUME, UPDATE_WEIGHT, GET_QUOTA. See <code>authorizer.proto</code> for interface changes.</li>
</ul>
<p><a name="1-2-x-removed-hooks"></a></p>
<ul>
<li>Removed slavePreLaunchDockerEnvironmentDecorator and slavePreLaunchDockerHook in favor of slavePreLaunchDockerTaskExecutorDecorator.</li>
</ul>
<p><a name="1-2-x-debug-endpoints"></a></p>
<ul>
<li>New Agent v1 operator API calls: LAUNCH_NESTED_CONTAINER_SESSION, ATTACH_CONTAINER_INPUT, ATTACH_CONTAINER_OUTPUT for debugging into running containers (Mesos containerizer only).</li>
</ul>
<p><a name="1-2-x-recovered-frameworks"></a></p>
<ul>
<li>Deprecated <code>recovered_frameworks</code> in v1 GetFrameworks call. Now it will be empty.</li>
</ul>
<p><a name="1-2-x-orphan-executors"></a></p>
<ul>
<li>Deprecated <code>orphan_executors</code> in v1 GetExecutors call. Now it will be empty.</li>
</ul>
<p><a name="1-2-x-orphan-tasks"></a></p>
<ul>
<li>Deprecated <code>orphan_tasks</code> in v1 GetTasks call. Now it will be empty.</li>
</ul>
<p>In order to upgrade a running cluster:</p>
<ol>
<li>Rebuild and install any modules so that upgraded masters/agents/schedulers can use them.</li>
<li>Install the new master binaries and restart the masters.</li>
<li>Install the new agent binaries and restart the agents.</li>
<li>Upgrade the schedulers by linking the latest native library / jar / egg (if necessary).</li>
<li>Restart the schedulers.</li>
<li>Upgrade the executors by linking the latest native library / jar / egg (if necessary).</li>
</ol>
<h2 id="upgrading-from-10x-to-11x"><a class="header" href="#upgrading-from-10x-to-11x">Upgrading from 1.0.x to 1.1.x</a></h2>
<p><a name="1-1-x-container-logger-interface"></a></p>
<ul>
<li>Mesos 1.1 removes the <code>ContainerLogger</code>'s <code>recover()</code> method.  The <code>ContainerLogger</code> had an incomplete interface for a stateful implementation.  This removes the incomplete parts to avoid adding tech debt in the containerizer.  Please see <a href="https://issues.apache.org/jira/browse/MESOS-6371">MESOS-6371</a> for more information.</li>
</ul>
<p><a name="1-1-x-allocator-updateallocation"></a></p>
<ul>
<li>Mesos 1.1 adds an <code>offeredResources</code> argument to the <code>Allocator::updateAllocation()</code> method. It is used to indicate the resources that the operations passed to <code>updateAllocation()</code> are applied to. <a href="https://issues.apache.org/jira/browse/MESOS-4431">MESOS-4431</a> (particularly <a href="https://reviews.apache.org/r/45961/">/r/45961/</a>) has more details on the motivation.</li>
</ul>
<h2 id="upgrading-from-028x-to-10x"><a class="header" href="#upgrading-from-028x-to-10x">Upgrading from 0.28.x to 1.0.x</a></h2>
<p><a name="1-0-x-deprecated-ssl-env-variables"></a></p>
<ul>
<li>Prior to Mesos 1.0, environment variables prefixed by <code>SSL_</code> are used to control libprocess SSL support. However, it was found that those environment variables may collide with some libraries or programs (e.g., openssl, curl). From Mesos 1.0, <code>SSL_*</code> environment variables are deprecated in favor of the corresponding <code>LIBPROCESS_SSL_*</code> variables.</li>
</ul>
<p><a name="1-0-x-persistent-volume-ownership"></a></p>
<ul>
<li>Prior to Mesos 1.0, Mesos agent recursively changes the ownership of the persistent volumes every time they are mounted to a container. From Mesos 1.0, this behavior has been changed. Mesos agent will do a <em>non-recursive</em> change of ownership of the persistent volumes.</li>
</ul>
<p><a name="1-0-x-deprecated-fields-in-container-config"></a></p>
<ul>
<li>Mesos 1.0 removed the camel cased protobuf fields in <code>ContainerConfig</code> (see <code>include/mesos/slave/isolator.proto</code>):
<ul>
<li><code>required ExecutorInfo executorInfo = 1;</code></li>
<li><code>optional TaskInfo taskInfo = 2;</code></li>
</ul>
</li>
</ul>
<p><a name="1-0-x-executor-environment-variables"></a></p>
<ul>
<li>By default, executors will no longer inherit environment variables from the agent. The operator can still use the <code>--executor_environment_variables</code> flag on the agent to explicitly specify what environment variables the executors will get. Mesos generated environment variables (i.e., <code>$MESOS_</code>, <code>$LIBPROCESS_</code>) will not be affected. If <code>$PATH</code> is not specified for an executor, a default value <code>/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin</code> will be used.</li>
</ul>
<p><a name="1-0-x-allocator-metrics"></a></p>
<ul>
<li>The allocator metric named <code>allocator/event_queue_dispatches</code> is now deprecated. The new name is <code>allocator/mesos/event_queue_dispatches</code> to better support metrics for alternative allocator implementations.</li>
</ul>
<p><a name="1-0-x-docker-timeout-flag"></a></p>
<ul>
<li>The <code>--docker_stop_timeout</code> agent flag is deprecated.</li>
</ul>
<p><a name="1-0-x-executorinfo"></a></p>
<ul>
<li>The ExecutorInfo.source field is deprecated in favor of ExecutorInfo.labels.</li>
</ul>
<p><a name="1-0-x-slave"></a></p>
<ul>
<li>Mesos 1.0 deprecates the 'slave' keyword in favor of 'agent' in a number of places
<ul>
<li>Deprecated flags with keyword 'slave' in favor of 'agent'.</li>
<li>Deprecated sandbox links with 'slave' keyword in the WebUI.</li>
<li>Deprecated <code>slave</code> subcommand for mesos-cli.</li>
</ul>
</li>
</ul>
<p><a name="1-0-x-workdir"></a></p>
<ul>
<li>Mesos 1.0 removes the default value for the agent's <code>work_dir</code> command-line flag. This flag is now required; the agent will exit immediately if it is not provided.</li>
</ul>
<p><a name="1-0-x-registry-strict"></a></p>
<ul>
<li>Mesos 1.0 disables support for the master's <code>registry_strict</code> command-line flag. If this flag is specified, the master will exit immediately. Note that this flag was previously marked as experimental and not recommended for production use.</li>
</ul>
<p><a name="1-0-x-credentials-file"></a></p>
<ul>
<li>Mesos 1.0 deprecates the use of plain text credential files in favor of JSON-formatted credential files.</li>
</ul>
<p><a name="1-0-x-persistent-volume"></a></p>
<ul>
<li>When a persistent volume is destroyed, Mesos will now remove any data that was stored on the volume from the filesystem of the appropriate agent. In prior versions of Mesos, destroying a volume would not delete data (this was a known missing feature that has now been implemented).</li>
</ul>
<p><a name="1-0-x-status-code"></a></p>
<ul>
<li>Mesos 1.0 changes the HTTP status code of the following endpoints from <code>200 OK</code> to <code>202 Accepted</code>:
<ul>
<li><code>/reserve</code></li>
<li><code>/unreserve</code></li>
<li><code>/create-volumes</code></li>
<li><code>/destroy-volumes</code></li>
</ul>
</li>
</ul>
<p><a name="1-0-x-v1-commandinfo"></a></p>
<ul>
<li>Added <code>output_file</code> field to CommandInfo.URI in Scheduler API and v1 Scheduler HTTP API.</li>
</ul>
<p><a name="1-0-x-scheduler-proto"></a></p>
<ul>
<li>Changed Call and Event Type enums in scheduler.proto from required to optional for the purpose of backwards compatibility.</li>
</ul>
<p><a name="1-0-x-executor-proto"></a></p>
<ul>
<li>Changed Call and Event Type enums in executor.proto from required to optional for the purpose of backwards compatibility.</li>
</ul>
<p><a name="1-0-x-nonterminal"></a></p>
<ul>
<li>Added non-terminal task metadata to the container resource usage information.</li>
</ul>
<p><a name="1-0-x-observe-endpoint"></a></p>
<ul>
<li>Deleted the /observe HTTP endpoint.</li>
</ul>
<p><a name="1-0-x-quota-acls"></a></p>
<ul>
<li>The <code>SetQuota</code> and <code>RemoveQuota</code> ACLs have been deprecated. To replace these, a new ACL <code>UpdateQuota</code> have been introduced. In addition, a new ACL <code>GetQuota</code> have been added; these control which principals are allowed to query quota information for which roles. These changes affect the <code>--acls</code> flag for the local authorizer in the following ways:
<ul>
<li>The <code>update_quotas</code> ACL cannot be used in combination with either the <code>set_quotas</code> or <code>remove_quotas</code> ACL. The local authorizer will produce an error in such a case;</li>
<li>When upgrading a Mesos cluster that uses the <code>set_quotas</code> or <code>remove_quotas</code> ACLs, the operator should first upgrade the Mesos binaries. At this point, the deprecated ACLs will still be enforced. After the upgrade has been verified, the operator should replace deprecated values for <code>set_quotas</code> and <code>remove_quotas</code> with equivalent values for <code>update_quotas</code>;</li>
<li>If desired, the operator can use the <code>get_quotas</code> ACL after the upgrade to control which principals are allowed to query quota information.</li>
</ul>
</li>
</ul>
<p><a name="1-0-x-authorizer"></a></p>
<ul>
<li>Mesos 1.0 contains a number of authorizer changes that particularly effect custom authorizer modules:
<ul>
<li>The authorizer interface has been refactored in order to decouple the ACL definition language from the interface. It additionally includes the option of retrieving <code>ObjectApprover</code>. An <code>ObjectApprover</code> can be used to synchronously check authorizations for a given object and is hence useful when authorizing a large number of objects and/or large objects (which need to be copied using request-based authorization). NOTE: This is a <strong>breaking change</strong> for authorizer modules.</li>
<li>Authorization-based HTTP endpoint filtering enables operators to restrict which parts of the cluster state a user is authorized to see. Consider for example the <code>/state</code> master endpoint: an operator can now authorize users to only see a subset of the running frameworks, tasks, or executors.</li>
<li>The <code>subject</code> and <code>object</code> fields in the authorization::Request protobuf message have been changed to be optional. If these fields are not set, the request should only be allowed for ACLs with <code>ANY</code> semantics. NOTE: This is a semantic change for authorizer modules.</li>
</ul>
</li>
</ul>
<p><a name="1-0-x-allocator"></a></p>
<ul>
<li>Namespace and header file of <code>Allocator</code> has been moved to be consistent with other packages.</li>
</ul>
<p><a name="1-0-x-fetcher-user"></a></p>
<ul>
<li>When a task is run as a particular user, the fetcher now fetches files as that user also. Note, this means that filesystem permissions for that user will be enforced when fetching local files.</li>
</ul>
<p><a name="1-0-x-http-authentication-flags"></a></p>
<ul>
<li>The <code>--authenticate_http</code> flag has been deprecated in favor of <code>--authenticate_http_readwrite</code>. Setting <code>--authenticate_http_readwrite</code> will now enable authentication for all endpoints which previously had authentication support. These happen to be the endpoints which allow modification of the cluster state, or &quot;read-write&quot; endpoints. Note that <code>/logging/toggle</code>, <code>/profiler/start</code>, <code>/profiler/stop</code>, <code>/maintenance/schedule</code>, <code>/machine/up</code>, and <code>/machine/down</code> previously did not have authentication support, but in 1.0 if either <code>--authenticate_http</code> or <code>--authenticate_http_readwrite</code> is set, those endpoints will now require authentication. A new flag has also been introduced, <code>--authenticate_http_readonly</code>, which enables authentication for endpoints which support authentication and do not allow modification of the state of the cluster, like <code>/state</code> or <code>/flags</code>.</li>
</ul>
<p><a name="1-0-x-endpoint-authorization"></a></p>
<ul>
<li>
<p>Mesos 1.0 introduces authorization support for several HTTP endpoints. Note that some of these endpoints are used by the web UI, and thus using the web UI in a cluster with authorization enabled will require that ACLs be set appropriately. Please refer to the <a href="authorization.html">authorization documentation</a> for details.</p>
</li>
<li>
<p>The endpoints with coarse-grained authorization enabled are:</p>
<ul>
<li><code>/files/debug</code></li>
<li><code>/logging/toggle</code></li>
<li><code>/metrics/snapshot</code></li>
<li><code>/slave(id)/containers</code></li>
<li><code>/slave(id)/monitor/statistics</code></li>
</ul>
</li>
<li>
<p>If the defined ACLs used <code>permissive: false</code>, the listed HTTP endpoints will stop working unless ACLs for the <code>get_endpoints</code> actions are defined.</p>
</li>
</ul>
<p>In order to upgrade a running cluster:</p>
<ol>
<li>Rebuild and install any modules so that upgraded masters/agents can use them.</li>
<li>Install the new master binaries and restart the masters.</li>
<li>Install the new agent binaries and restart the agents.</li>
<li>Upgrade the schedulers by linking the latest native library / jar / egg (if necessary).</li>
<li>Restart the schedulers.</li>
<li>Upgrade the executors by linking the latest native library / jar / egg (if necessary).</li>
</ol>
<h2 id="upgrading-from-027x-to-028x"><a class="header" href="#upgrading-from-027x-to-028x">Upgrading from 0.27.x to 0.28.x</a></h2>
<p><a name="0-28-x-resource-precision"></a></p>
<ul>
<li>Mesos 0.28 only supports three decimal digits of precision for scalar resource values. For example, frameworks can reserve &quot;0.001&quot; CPUs but more fine-grained reservations (e.g., &quot;0.0001&quot; CPUs) are no longer supported (although they did not work reliably in prior versions of Mesos anyway). Internally, resource math is now done using a fixed-point format that supports three decimal digits of precision, and then converted to/from floating point for input and output, respectively. Frameworks that do their own resource math and manipulate fractional resources may observe differences in roundoff error and numerical precision.</li>
</ul>
<p><a name="0-28-x-autherization-acls"></a></p>
<ul>
<li>Mesos 0.28 changes the definitions of two ACLs used for authorization. The objects of the <code>ReserveResources</code> and <code>CreateVolume</code> ACLs have been changed to <code>roles</code>. In both cases, principals can now be authorized to perform these operations for particular roles. This means that by default, a framework or operator can reserve resources/create volumes for any role. To restrict this behavior, <a href="authorization.html">ACLs can be added</a> to the master which authorize principals to reserve resources/create volumes for specified roles only. Previously, frameworks could only reserve resources for their own role; this behavior can be preserved by configuring the <code>ReserveResources</code> ACLs such that the framework's principal is only authorized to reserve for the framework's role. <strong>NOTE</strong> This renders existing <code>ReserveResources</code> and <code>CreateVolume</code> ACL definitions obsolete; if you are authorizing these operations, your ACL definitions should be updated.</li>
</ul>
<p>In order to upgrade a running cluster:</p>
<ol>
<li>Rebuild and install any modules so that upgraded masters/agents can use them.</li>
<li>Install the new master binaries and restart the masters.</li>
<li>Install the new agent binaries and restart the agents.</li>
<li>Upgrade the schedulers by linking the latest native library / jar / egg (if necessary).</li>
<li>Restart the schedulers.</li>
<li>Upgrade the executors by linking the latest native library / jar / egg (if necessary).</li>
</ol>
<h2 id="upgrading-from-026x-to-027x"><a class="header" href="#upgrading-from-026x-to-027x">Upgrading from 0.26.x to 0.27.x</a></h2>
<p><a name="0-27-x-implicit-roles"></a></p>
<ul>
<li>Mesos 0.27 introduces the concept of <em>implicit roles</em>. In previous releases, configuring roles required specifying a static whitelist of valid role names on master startup (via the <code>--roles</code> flag). In Mesos 0.27, if <code>--roles</code> is omitted, <em>any</em> role name can be used; controlling which principals are allowed to register as which roles should be done using <a href="authorization.html">ACLs</a>. The role whitelist functionality is still supported but is deprecated.</li>
</ul>
<p><a name="0-27-x-allocator-api"></a></p>
<ul>
<li>The Allocator API has changed due to the introduction of implicit roles. Custom allocator implementations will need to be updated. See <a href="https://issues.apache.org/jira/browse/MESOS-4000">MESOS-4000</a> for more information.</li>
</ul>
<p><a name="0-27-x-executor-lost-callback"></a></p>
<ul>
<li>The <code>executorLost</code> callback in the Scheduler interface will now be called whenever the agent detects termination of a custom executor. This callback was never called in previous versions, so please make sure any framework schedulers can now safely handle this callback. Note that this callback may not be reliably delivered.</li>
</ul>
<p><a name="0-27-x-isolator-api"></a></p>
<ul>
<li>The isolator <code>prepare</code> interface has been changed slightly. Instead of keeping adding parameters to the <code>prepare</code> interface, we decide to use a protobuf (<code>ContainerConfig</code>). Also, we renamed <code>ContainerPrepareInfo</code> to <code>ContainerLaunchInfo</code> to better capture the purpose of this struct. See <a href="https://issues.apache.org/jira/browse/MESOS-4240">MESOS-4240</a> and <a href="https://issues.apache.org/jira/browse/MESOS-4282">MESOS-4282</a> for more information. If you are an isolator module writer, you will have to adjust your isolator module according to the new interface and re-compile with 0.27.</li>
</ul>
<p><a name="0-27-x-acl-shutdown-flag"></a></p>
<ul>
<li>
<p>ACLs.shutdown_frameworks has been deprecated in favor of the new ACLs.teardown_frameworks. This affects the <code>--acls</code> master flag for the local authorizer.</p>
</li>
<li>
<p>Reserved resources are now accounted for in the DRF role sorter. Previously unaccounted reservations will influence the weighted DRF sorter. If role weights were explicitly set, they may need to be adjusted in order to account for the reserved resources in the cluster.</p>
</li>
</ul>
<p>In order to upgrade a running cluster:</p>
<ol>
<li>Rebuild and install any modules so that upgraded masters/agents can use them.</li>
<li>Install the new master binaries and restart the masters.</li>
<li>Install the new agent binaries and restart the agents.</li>
<li>Upgrade the schedulers by linking the latest native library / jar / egg (if necessary).</li>
<li>Restart the schedulers.</li>
<li>Upgrade the executors by linking the latest native library / jar / egg (if necessary).</li>
</ol>
<h2 id="upgrading-from-025x-to-026x"><a class="header" href="#upgrading-from-025x-to-026x">Upgrading from 0.25.x to 0.26.x</a></h2>
<p><a name="0-26-x-taskstatus-reason"></a></p>
<ul>
<li>
<p>The names of some TaskStatus::Reason enums have been changed. But the tag numbers remain unchanged, so it is backwards compatible. Frameworks using the new version might need to do some compile time adjustments:</p>
<ul>
<li>REASON_MEM_LIMIT -&gt; REASON_CONTAINER_LIMITATION_MEMORY</li>
<li>REASON_EXECUTOR_PREEMPTED -&gt; REASON_CONTAINER_PREEMPTED</li>
</ul>
</li>
</ul>
<p><a name="0-26-x-credential-protobuf"></a></p>
<ul>
<li>The <code>Credential</code> protobuf has been changed. <code>Credential</code> field <code>secret</code> is now a string, it used to be bytes. This will affect framework developers and language bindings ought to update their generated protobuf with the new version. This fixes JSON based credentials file support.</li>
</ul>
<p><a name="0-26-x-state-endpoint"></a></p>
<ul>
<li>The <code>/state</code> endpoints on master and agent will no longer include <code>data</code> fields as part of the JSON models for <code>ExecutorInfo</code> and <code>TaskInfo</code> out of consideration for memory scalability (see <a href="https://issues.apache.org/jira/browse/MESOS-3794">MESOS-3794</a> and <a href="http://www.mail-archive.com/dev@mesos.apache.org/msg33536.html">this email thread</a>).
<ul>
<li>On master, the affected <code>data</code> field was originally found via <code>frameworks[*].executors[*].data</code>.</li>
<li>On agents, the affected <code>data</code> field was originally found via <code>executors[*].tasks[*].data</code>.</li>
</ul>
</li>
</ul>
<p><a name="0-26-x-network-info-protobuf"></a></p>
<ul>
<li>The <code>NetworkInfo</code> protobuf has been changed. The fields <code>protocol</code> and <code>ip_address</code> are now deprecated. The new field <code>ip_addresses</code> subsumes the information provided by them.</li>
</ul>
<p>In order to upgrade a running cluster:</p>
<ol>
<li>Rebuild and install any modules so that upgraded masters/agents can use them.</li>
<li>Install the new master binaries and restart the masters.</li>
<li>Install the new agent binaries and restart the agents.</li>
<li>Upgrade the schedulers by linking the latest native library / jar / egg (if necessary).</li>
<li>Restart the schedulers.</li>
<li>Upgrade the executors by linking the latest native library / jar / egg (if necessary).</li>
</ol>
<h2 id="upgrading-from-024x-to-025x"><a class="header" href="#upgrading-from-024x-to-025x">Upgrading from 0.24.x to 0.25.x</a></h2>
<p><a name="0-25-x-json-endpoints"></a></p>
<ul>
<li>
<p>The following endpoints will be deprecated in favor of new endpoints. Both versions will be available in 0.25 but the deprecated endpoints will be removed in a subsequent release.</p>
<p>For master endpoints:</p>
<ul>
<li>/state.json becomes /state</li>
<li>/tasks.json becomes /tasks</li>
</ul>
<p>For agent endpoints:</p>
<ul>
<li>/state.json becomes /state</li>
<li>/monitor/statistics.json becomes /monitor/statistics</li>
</ul>
<p>For both master and agent:</p>
<ul>
<li>/files/browse.json becomes /files/browse</li>
<li>/files/debug.json becomes /files/debug</li>
<li>/files/download.json becomes /files/download</li>
<li>/files/read.json becomes /files/read</li>
</ul>
</li>
</ul>
<p><a name="0-25-x-scheduler-bindings"></a></p>
<ul>
<li>The C++/Java/Python scheduler bindings have been updated. In particular, the driver can make a suppressOffers() call to stop receiving offers (until reviveOffers() is called).</li>
</ul>
<p>In order to upgrade a running cluster:</p>
<ol>
<li>Rebuild and install any modules so that upgraded masters/agents can use them.</li>
<li>Install the new master binaries and restart the masters.</li>
<li>Install the new agent binaries and restart the agents.</li>
<li>Upgrade the schedulers by linking the latest native library / jar / egg (if necessary).</li>
<li>Restart the schedulers.</li>
<li>Upgrade the executors by linking the latest native library / jar / egg (if necessary).</li>
</ol>
<h2 id="upgrading-from-023x-to-024x"><a class="header" href="#upgrading-from-023x-to-024x">Upgrading from 0.23.x to 0.24.x</a></h2>
<ul>
<li>
<p>Support for live upgrading a driver based scheduler to HTTP based (experimental) scheduler has been added.</p>
</li>
<li>
<p>Master now publishes its information in ZooKeeper in JSON (instead of protobuf). Make sure schedulers are linked against &gt;= 0.23.0 libmesos before upgrading the master.</p>
</li>
</ul>
<p>In order to upgrade a running cluster:</p>
<ol>
<li>Rebuild and install any modules so that upgraded masters/agents can use them.</li>
<li>Install the new master binaries and restart the masters.</li>
<li>Install the new agent binaries and restart the agents.</li>
<li>Upgrade the schedulers by linking the latest native library / jar / egg (if necessary).</li>
<li>Restart the schedulers.</li>
<li>Upgrade the executors by linking the latest native library / jar / egg (if necessary).</li>
</ol>
<h2 id="upgrading-from-022x-to-023x"><a class="header" href="#upgrading-from-022x-to-023x">Upgrading from 0.22.x to 0.23.x</a></h2>
<ul>
<li>
<p>The 'stats.json' endpoints for masters and agents have been removed. Please use the 'metrics/snapshot' endpoints instead.</p>
</li>
<li>
<p>The '/master/shutdown' endpoint is deprecated in favor of the new '/master/teardown' endpoint.</p>
</li>
<li>
<p>In order to enable decorator modules to remove metadata (environment variables or labels), we changed the meaning of the return value for decorator hooks in Mesos 0.23.0. Please refer to the modules documentation for more details.</p>
</li>
<li>
<p>Agent ping timeouts are now configurable on the master via <code>--slave_ping_timeout</code> and <code>--max_slave_ping_timeouts</code>. Agents should be upgraded to 0.23.x before changing these flags.</p>
</li>
<li>
<p>A new scheduler driver API, <code>acceptOffers</code>, has been introduced. This is a more general version of the <code>launchTasks</code> API, which allows the scheduler to accept an offer and specify a list of operations (Offer.Operation) to perform using the resources in the offer. Currently, the supported operations include LAUNCH (launching tasks), RESERVE (making dynamic reservations), UNRESERVE (releasing dynamic reservations), CREATE (creating persistent volumes) and DESTROY (releasing persistent volumes). Similar to the <code>launchTasks</code> API, any unused resources will be considered declined, and the specified filters will be applied on all unused resources.</p>
</li>
<li>
<p>The Resource protobuf has been extended to include more metadata for supporting persistence (DiskInfo), dynamic reservations (ReservationInfo) and oversubscription (RevocableInfo). You must not combine two Resource objects if they have different metadata.</p>
</li>
</ul>
<p>In order to upgrade a running cluster:</p>
<ol>
<li>Rebuild and install any modules so that upgraded masters/agents can use them.</li>
<li>Install the new master binaries and restart the masters.</li>
<li>Install the new agent binaries and restart the agents.</li>
<li>Upgrade the schedulers by linking the latest native library / jar / egg (if necessary).</li>
<li>Restart the schedulers.</li>
<li>Upgrade the executors by linking the latest native library / jar / egg (if necessary).</li>
</ol>
<h2 id="upgrading-from-021x-to-022x"><a class="header" href="#upgrading-from-021x-to-022x">Upgrading from 0.21.x to 0.22.x</a></h2>
<ul>
<li>
<p>Agent checkpoint flag has been removed as it will be enabled for all
agents. Frameworks must still enable checkpointing during registration to take advantage
of checkpointing their tasks.</p>
</li>
<li>
<p>The stats.json endpoints for masters and agents have been deprecated.
Please refer to the metrics/snapshot endpoint.</p>
</li>
<li>
<p>The C++/Java/Python scheduler bindings have been updated. In particular, the driver can be constructed with an additional argument that specifies whether to use implicit driver acknowledgements. In <code>statusUpdate</code>, the <code>TaskStatus</code> now includes a UUID to make explicit acknowledgements possible.</p>
</li>
<li>
<p>The Authentication API has changed slightly in this release to support additional authentication mechanisms. The change from 'string' to 'bytes' for AuthenticationStartMessage.data has no impact on C++ or the over-the-wire representation, so it only impacts pure language bindings for languages like Java and Python that use different types for UTF-8 strings vs. byte arrays.</p>
<p>message AuthenticationStartMessage {
required string mechanism = 1;
optional bytes data = 2;
}</p>
</li>
<li>
<p>All Mesos arguments can now be passed using file:// to read them out of a file (either an absolute or relative path). The --credentials, --whitelist, and any flags that expect JSON backed arguments (such as --modules) behave as before, although support for just passing an absolute path for any JSON flags rather than file:// has been deprecated and will produce a warning (and the absolute path behavior will be removed in a future release).</p>
</li>
</ul>
<p>In order to upgrade a running cluster:</p>
<ol>
<li>Install the new master binaries and restart the masters.</li>
<li>Install the new agent binaries and restart the agents.</li>
<li>Upgrade the schedulers:</li>
</ol>
<ul>
<li>For Java schedulers, link the new native library against the new JAR. The JAR contains API above changes. A 0.21.0 JAR will work with a 0.22.0 libmesos. A 0.22.0 JAR will work with a 0.21.0 libmesos if explicit acks are not being used. 0.22.0 and 0.21.0 are inter-operable at the protocol level between the master and the scheduler.</li>
<li>For Python schedulers, upgrade to use a 0.22.0 egg. If constructing <code>MesosSchedulerDriverImpl</code> with <code>Credentials</code>, your code must be updated to pass the <code>implicitAcknowledgements</code> argument before <code>Credentials</code>. You may run a 0.21.0 Python scheduler against a 0.22.0 master, and vice versa.</li>
</ul>
<ol start="4">
<li>Restart the schedulers.</li>
<li>Upgrade the executors by linking the latest native library / jar / egg.</li>
</ol>
<h2 id="upgrading-from-020x-to-021x"><a class="header" href="#upgrading-from-020x-to-021x">Upgrading from 0.20.x to 0.21.x</a></h2>
<ul>
<li>Disabling agent checkpointing has been deprecated; the agent --checkpoint flag has been deprecated and will be removed in a future release.</li>
</ul>
<p>In order to upgrade a running cluster:</p>
<ol>
<li>Install the new master binaries and restart the masters.</li>
<li>Install the new agent binaries and restart the agents.</li>
<li>Upgrade the schedulers by linking the latest native library (mesos jar upgrade not necessary).</li>
<li>Restart the schedulers.</li>
<li>Upgrade the executors by linking the latest native library and mesos jar (if necessary).</li>
</ol>
<h2 id="upgrading-from-019x-to-020x"><a class="header" href="#upgrading-from-019x-to-020x">Upgrading from 0.19.x to 0.20.x.</a></h2>
<ul>
<li>
<p>The Mesos API has been changed slightly in this release. The CommandInfo has been changed (see below), which makes launching a command more flexible. The 'value' field has been changed from <em>required</em> to <em>optional</em>. However, it will not cause any issue during the upgrade (since the existing schedulers always set this field).</p>
<pre><code>  message CommandInfo {
    ...
    // There are two ways to specify the command:
    // 1) If 'shell == true', the command will be launched via shell
    //    (i.e., /bin/sh -c 'value'). The 'value' specified will be
    //    treated as the shell command. The 'arguments' will be ignored.
    // 2) If 'shell == false', the command will be launched by passing
    //    arguments to an executable. The 'value' specified will be
    //    treated as the filename of the executable. The 'arguments'
    //    will be treated as the arguments to the executable. This is
    //    similar to how POSIX exec families launch processes (i.e.,
    //    execlp(value, arguments(0), arguments(1), ...)).
    optional bool shell = 6 [default = true];
    optional string value = 3;
    repeated string arguments = 7;
    ...
  }
</code></pre>
</li>
<li>
<p>The Python bindings are also changing in this release. There are now sub-modules which allow you to use either the interfaces and/or the native driver.</p>
<ul>
<li><code>import mesos.native</code> for the native drivers</li>
<li><code>import mesos.interface</code> for the stub implementations and protobufs</li>
</ul>
<p>To ensure a smooth upgrade, we recommend to upgrade your python framework and executor first. You will be able to either import using the new configuration or the old. Replace the existing imports with something like the following:</p>
<p>try:
from mesos.native import MesosExecutorDriver, MesosSchedulerDriver
from mesos.interface import Executor, Scheduler
from mesos.interface import mesos_pb2
except ImportError:
from mesos import Executor, MesosExecutorDriver, MesosSchedulerDriver, Scheduler
import mesos_pb2</p>
</li>
<li>
<p>If you're using a pure language binding, please ensure that it sends status update acknowledgements through the master before upgrading.</p>
</li>
</ul>
<p>In order to upgrade a running cluster:</p>
<ol>
<li>Install the new master binaries and restart the masters.</li>
<li>Install the new agent binaries and restart the agents.</li>
<li>Upgrade the schedulers by linking the latest native library (install the latest mesos jar and python egg if necessary).</li>
<li>Restart the schedulers.</li>
<li>Upgrade the executors by linking the latest native library (install the latest mesos jar and python egg if necessary).</li>
</ol>
<h2 id="upgrading-from-018x-to-019x"><a class="header" href="#upgrading-from-018x-to-019x">Upgrading from 0.18.x to 0.19.x.</a></h2>
<ul>
<li>
<p>There are new required flags on the master (<code>--work_dir</code> and <code>--quorum</code>) to support the <em>Registrar</em> feature, which adds replicated state on the masters.</p>
</li>
<li>
<p>No required upgrade ordering across components.</p>
</li>
</ul>
<p>In order to upgrade a running cluster:</p>
<ol>
<li>Install the new master binaries and restart the masters.</li>
<li>Install the new agent binaries and restart the agents.</li>
<li>Upgrade the schedulers by linking the latest native library (mesos jar upgrade not necessary).</li>
<li>Restart the schedulers.</li>
<li>Upgrade the executors by linking the latest native library and mesos jar (if necessary).</li>
</ol>
<h2 id="upgrading-from-0170-to-018x"><a class="header" href="#upgrading-from-0170-to-018x">Upgrading from 0.17.0 to 0.18.x.</a></h2>
<ul>
<li>This upgrade requires a system reboot for agents that use Linux cgroups for isolation.</li>
</ul>
<p>In order to upgrade a running cluster:</p>
<ol>
<li>Install the new master binaries and restart the masters.</li>
<li>Upgrade the schedulers by linking the latest native library and mesos jar (if necessary).</li>
<li>Restart the schedulers.</li>
<li>Install the new agent binaries then perform one of the following two steps, depending on if cgroups isolation is used:</li>
</ol>
<ul>
<li>[no cgroups]
<ul>
<li>Restart the agents. The &quot;--isolation&quot; flag has changed and &quot;process&quot; has been deprecated in favor of &quot;posix/cpu,posix/mem&quot;.</li>
</ul>
</li>
<li>[cgroups]
<ul>
<li>Change from a single mountpoint for all controllers to separate mountpoints for each controller, e.g., /sys/fs/cgroup/memory/ and /sys/fs/cgroup/cpu/.</li>
<li>The suggested configuration is to mount a tmpfs filesystem to /sys/fs/cgroup and to let the agent mount the required controllers. However, the agent will also use previously mounted controllers if they are appropriately mounted under &quot;--cgroups_hierarchy&quot;.</li>
<li>It has been observed that unmounting and remounting of cgroups from the single to separate configuration is unreliable and a reboot into the new configuration is strongly advised. Restart the agents after reboot.</li>
<li>The &quot;--cgroups_hierarchy&quot; now defaults to &quot;/sys/fs/cgroup&quot;. The &quot;--cgroups_root&quot; flag default remains &quot;mesos&quot;.</li>
<li>The &quot;--isolation&quot; flag has changed and &quot;cgroups&quot; has been deprecated in favor of &quot;cgroups/cpu,cgroups/mem&quot;.</li>
<li>The &quot;--cgroup_subsystems&quot; flag is no longer required and will be ignored.</li>
</ul>
</li>
</ul>
<ol start="5">
<li>Upgrade the executors by linking the latest native library and mesos jar (if necessary).</li>
</ol>
<h2 id="upgrading-from-0160-to-0170"><a class="header" href="#upgrading-from-0160-to-0170">Upgrading from 0.16.0 to 0.17.0.</a></h2>
<p>In order to upgrade a running cluster:</p>
<ol>
<li>Install the new master binaries and restart the masters.</li>
<li>Upgrade the schedulers by linking the latest native library and mesos jar (if necessary).</li>
<li>Restart the schedulers.</li>
<li>Install the new agent binaries and restart the agents.</li>
<li>Upgrade the executors by linking the latest native library and mesos jar (if necessary).</li>
</ol>
<h2 id="upgrading-from-0150-to-0160"><a class="header" href="#upgrading-from-0150-to-0160">Upgrading from 0.15.0 to 0.16.0.</a></h2>
<p>In order to upgrade a running cluster:</p>
<ol>
<li>Install the new master binaries and restart the masters.</li>
<li>Upgrade the schedulers by linking the latest native library and mesos jar (if necessary).</li>
<li>Restart the schedulers.</li>
<li>Install the new agent binaries and restart the agents.</li>
<li>Upgrade the executors by linking the latest native library and mesos jar (if necessary).</li>
</ol>
<h2 id="upgrading-from-0140-to-0150"><a class="header" href="#upgrading-from-0140-to-0150">Upgrading from 0.14.0 to 0.15.0.</a></h2>
<ul>
<li>Schedulers should implement the new <code>reconcileTasks</code> driver method.</li>
<li>Schedulers should call the new <code>MesosSchedulerDriver</code> constructor that takes <code>Credential</code> to authenticate.</li>
<li>--authentication=false (default) allows both authenticated and unauthenticated frameworks to register.</li>
</ul>
<p>In order to upgrade a running cluster:</p>
<ol>
<li>Install the new master binaries.</li>
<li>Restart the masters with --credentials pointing to credentials of the framework(s).</li>
<li>Install the new agent binaries and restart the agents.</li>
<li>Upgrade the executors by linking the latest native library and mesos jar (if necessary).</li>
<li>Upgrade the schedulers by linking the latest native library and mesos jar (if necessary).</li>
<li>Restart the schedulers.
Restart the masters with --authentication=true.</li>
</ol>
<p>NOTE: After the restart unauthenticated frameworks <em>will not</em> be allowed to register.</p>
<h2 id="upgrading-from-0130-to-0140"><a class="header" href="#upgrading-from-0130-to-0140">Upgrading from 0.13.0 to 0.14.0.</a></h2>
<ul>
<li>/vars endpoint has been removed.</li>
</ul>
<p>In order to upgrade a running cluster:</p>
<ol>
<li>Install the new master binaries and restart the masters.</li>
<li>Upgrade the executors by linking the latest native library and mesos jar (if necessary).</li>
<li>Install the new agent binaries.</li>
<li>Restart the agents after adding --checkpoint flag to enable checkpointing.</li>
<li>Upgrade the schedulers by linking the latest native library and mesos jar (if necessary).</li>
<li>Set FrameworkInfo.checkpoint in the scheduler if checkpointing is desired (recommended).</li>
<li>Restart the schedulers.</li>
<li>Restart the masters (to get rid of the cached FrameworkInfo).</li>
<li>Restart the agents (to get rid of the cached FrameworkInfo).</li>
</ol>
<h2 id="upgrading-from-0120-to-0130"><a class="header" href="#upgrading-from-0120-to-0130">Upgrading from 0.12.0 to 0.13.0.</a></h2>
<ul>
<li>cgroups_hierarchy_root agent flag is renamed as cgroups_hierarchy</li>
</ul>
<p>In order to upgrade a running cluster:</p>
<ol>
<li>Install the new master binaries and restart the masters.</li>
<li>Upgrade the schedulers by linking the latest native library and mesos jar (if necessary).</li>
<li>Restart the schedulers.</li>
<li>Install the new agent binaries.</li>
<li>Restart the agents.</li>
<li>Upgrade the executors by linking the latest native library and mesos jar (if necessary).</li>
</ol>
<h2 id="upgrading-from-0110-to-0120"><a class="header" href="#upgrading-from-0110-to-0120">Upgrading from 0.11.0 to 0.12.0.</a></h2>
<ul>
<li>If you are a framework developer, you will want to examine the new 'source' field in the ExecutorInfo protobuf. This will allow you to take further advantage of the resource monitoring.</li>
</ul>
<p>In order to upgrade a running cluster:</p>
<ol>
<li>Install the new agent binaries and restart the agents.</li>
<li>Install the new master binaries and restart the masters.</li>
</ol>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        

                        

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                

                
            </nav>

        </div>

        

        

        

        
        <script type="text/javascript">
            window.playground_copyable = true;
        </script>
        

        

        
        <script src="elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="searcher.js" type="text/javascript" charset="utf-8"></script>
        

        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        

        
        
        <script type="text/javascript">
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>
        
        

    </body>
</html>
